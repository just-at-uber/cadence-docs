(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(e){function t(t){for(var o,a,s=t[0],l=t[1],c=t[2],d=0,h=[];d<s.length;d++)a=s[d],Object.prototype.hasOwnProperty.call(i,a)&&i[a]&&h.push(i[a][0]),i[a]=0;for(o in l)Object.prototype.hasOwnProperty.call(l,o)&&(e[o]=l[o]);for(u&&u(t);h.length;)h.shift()();return r.push.apply(r,c||[]),n()}function n(){for(var e,t=0;t<r.length;t++){for(var n=r[t],o=!0,s=1;s<n.length;s++){var l=n[s];0!==i[l]&&(o=!1)}o&&(r.splice(t--,1),e=a(a.s=n[0]))}return e}var o={},i={1:0},r=[];function a(t){if(o[t])return o[t].exports;var n=o[t]={i:t,l:!1,exports:{}};return e[t].call(n.exports,n,n.exports,a),n.l=!0,n.exports}a.e=function(e){var t=[],n=i[e];if(0!==n)if(n)t.push(n[2]);else{var o=new Promise((function(t,o){n=i[e]=[t,o]}));t.push(n[2]=o);var r,s=document.createElement("script");s.charset="utf-8",s.timeout=120,a.nc&&s.setAttribute("nonce",a.nc),s.src=function(e){return a.p+"assets/js/"+({}[e]||e)+"."+{2:"c128029e",3:"f88d0b61",4:"46ddc725",5:"07ba0faf",6:"95f58db5",7:"f07d7603",8:"7d2da622",9:"28c0067a",10:"30b5447b",11:"47ae175e",12:"b4d7f468",13:"8b64c914",14:"01dd8e31",15:"7b5687e1",16:"a5c2ce30",17:"4ea48d0a",18:"e8e54a6c",19:"fcc79c14",20:"fa5f27ec",21:"ee86c958",22:"d0938de1",23:"9264618b",24:"5a7ccd27",25:"d3e44829",26:"beece79f",27:"1c73c41f",28:"12a7cb1a",29:"e66ecd28",30:"4eec28ba",31:"e0977a54",32:"2175df0f",33:"3e318b8b",34:"cff14c31",35:"a3b4bbf3",36:"1bf1b56b",37:"d96cf0b8",38:"05b6b7bc",39:"df30cdfc",40:"bb14ba11",41:"041cc46b",42:"b2309be2",43:"bfc4c38b",44:"689ed3eb",45:"25bbcb3a",46:"feec4067",47:"28dab6d4",48:"af5026ee",49:"5827aece",50:"adefba21",51:"50448ee0",52:"12446120",53:"b866aa81",54:"096cecbd",55:"67b645a4",56:"10bd0c93",57:"92c53833",58:"0b140704",59:"c16cfdff",60:"228776da",61:"61c5cac3",62:"09ae72f8",63:"01f8ccb2",64:"ad3956b9",65:"09552f63",66:"d3fd8232"}[e]+".js"}(e);var l=new Error;r=function(t){s.onerror=s.onload=null,clearTimeout(c);var n=i[e];if(0!==n){if(n){var o=t&&("load"===t.type?"missing":t.type),r=t&&t.target&&t.target.src;l.message="Loading chunk "+e+" failed.\n("+o+": "+r+")",l.name="ChunkLoadError",l.type=o,l.request=r,n[1](l)}i[e]=void 0}};var c=setTimeout((function(){r({type:"timeout",target:s})}),12e4);s.onerror=s.onload=r,document.head.appendChild(s)}return Promise.all(t)},a.m=e,a.c=o,a.d=function(e,t,n){a.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:n})},a.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},a.t=function(e,t){if(1&t&&(e=a(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var n=Object.create(null);if(a.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)a.d(n,o,function(t){return e[t]}.bind(null,o));return n},a.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return a.d(t,"a",t),t},a.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},a.p="/",a.oe=function(e){throw console.error(e),e};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=t,s=s.slice();for(var c=0;c<s.length;c++)t(s[c]);var u=l;r.push([200,0]),n()}([function(e,t,n){var o=n(2),i=n(22).f,r=n(15),a=n(11),s=n(78),l=n(133),c=n(76);e.exports=function(e,t){var n,u,d,h,f,p=e.target,m=e.global,g=e.stat;if(n=m?o:g?o[p]||s(p,{}):(o[p]||{}).prototype)for(u in t){if(h=t[u],d=e.noTargetGet?(f=i(n,u))&&f.value:n[u],!c(m?u:p+(g?".":"#")+u,e.forced)&&void 0!==d){if(typeof h==typeof d)continue;l(h,d)}(e.sham||d&&d.sham)&&r(h,"sham",!0),a(n,u,h,e)}}},function(e,t){e.exports=function(e){try{return!!e()}catch(e){return!0}}},function(e,t){var n=function(e){return e&&e.Math==Math&&e};e.exports=n("object"==typeof globalThis&&globalThis)||n("object"==typeof window&&window)||n("object"==typeof self&&self)||n("object"==typeof global&&global)||Function("return this")()},function(e,t,n){var o=n(2),i=n(77),r=n(7),a=n(56),s=n(80),l=n(127),c=i("wks"),u=o.Symbol,d=l?u:u&&u.withoutSetter||a;e.exports=function(e){return r(c,e)||(s&&r(u,e)?c[e]=u[e]:c[e]=d("Symbol."+e)),c[e]}},function(e,t){e.exports=function(e){return"object"==typeof e?null!==e:"function"==typeof e}},function(e,t,n){var o=n(1);e.exports=!o((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(e,t,n){var o=n(4);e.exports=function(e){if(!o(e))throw TypeError(String(e)+" is not an object");return e}},function(e,t){var n={}.hasOwnProperty;e.exports=function(e,t){return n.call(e,t)}},function(e,t,n){"use strict";function o(e,t,n,o,i,r,a,s){var l,c="function"==typeof e?e.options:e;if(t&&(c.render=t,c.staticRenderFns=n,c._compiled=!0),o&&(c.functional=!0),r&&(c._scopeId="data-v-"+r),a?(l=function(e){(e=e||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(e=__VUE_SSR_CONTEXT__),i&&i.call(this,e),e&&e._registeredComponents&&e._registeredComponents.add(a)},c._ssrRegister=l):i&&(l=s?function(){i.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:i),l)if(c.functional){c._injectStyles=l;var u=c.render;c.render=function(e,t){return l.call(t),u(e,t)}}else{var d=c.beforeCreate;c.beforeCreate=d?[].concat(d,l):[l]}return{exports:e,options:c}}n.d(t,"a",(function(){return o}))},function(e,t,n){var o=n(5),i=n(126),r=n(6),a=n(39),s=Object.defineProperty;t.f=o?s:function(e,t,n){if(r(e),t=a(t,!0),r(n),i)try{return s(e,t,n)}catch(e){}if("get"in n||"set"in n)throw TypeError("Accessors not supported");return"value"in n&&(e[t]=n.value),e}},function(e,t,n){var o=n(88),i=n(11),r=n(210);o||i(Object.prototype,"toString",r,{unsafe:!0})},function(e,t,n){var o=n(2),i=n(15),r=n(7),a=n(78),s=n(83),l=n(32),c=l.get,u=l.enforce,d=String(String).split("String");(e.exports=function(e,t,n,s){var l=!!s&&!!s.unsafe,c=!!s&&!!s.enumerable,h=!!s&&!!s.noTargetGet;"function"==typeof n&&("string"!=typeof t||r(n,"name")||i(n,"name",t),u(n).source=d.join("string"==typeof t?t:"")),e!==o?(l?!h&&e[t]&&(c=!0):delete e[t],c?e[t]=n:i(e,t,n)):c?e[t]=n:a(t,n)})(Function.prototype,"toString",(function(){return"function"==typeof this&&c(this).source||s(this)}))},function(e,t,n){var o=n(47),i=Math.min;e.exports=function(e){return e>0?i(o(e),9007199254740991):0}},function(e,t,n){var o=n(38),i=n(20);e.exports=function(e){return o(i(e))}},function(e,t,n){var o=n(20);e.exports=function(e){return Object(o(e))}},function(e,t,n){var o=n(5),i=n(9),r=n(35);e.exports=o?function(e,t,n){return i.f(e,t,r(1,n))}:function(e,t,n){return e[t]=n,e}},function(e,t,n){var o=n(5),i=n(1),r=n(7),a=Object.defineProperty,s={},l=function(e){throw e};e.exports=function(e,t){if(r(s,e))return s[e];t||(t={});var n=[][e],c=!!r(t,"ACCESSORS")&&t.ACCESSORS,u=r(t,0)?t[0]:l,d=r(t,1)?t[1]:void 0;return s[e]=!!n&&!i((function(){if(c&&!o)return!0;var e={length:-1};c?a(e,1,{enumerable:!0,get:l}):e[1]=1,n.call(e,u,d)}))}},function(e,t){var n=Array.isArray;e.exports=n},function(e,t){var n={}.toString;e.exports=function(e){return n.call(e).slice(8,-1)}},function(e,t,n){var o=n(157),i="object"==typeof self&&self&&self.Object===Object&&self,r=o||i||Function("return this")();e.exports=r},function(e,t){e.exports=function(e){if(null==e)throw TypeError("Can't call method on "+e);return e}},function(e,t,n){var o=n(131),i=n(2),r=function(e){return"function"==typeof e?e:void 0};e.exports=function(e,t){return arguments.length<2?r(o[e])||r(i[e]):o[e]&&o[e][t]||i[e]&&i[e][t]}},function(e,t,n){var o=n(5),i=n(84),r=n(35),a=n(13),s=n(39),l=n(7),c=n(126),u=Object.getOwnPropertyDescriptor;t.f=o?u:function(e,t){if(e=a(e),t=s(t,!0),c)try{return u(e,t)}catch(e){}if(l(e,t))return r(!i.f.call(e,t),e[t])}},function(e,t,n){"use strict";var o=n(0),i=n(62);o({target:"RegExp",proto:!0,forced:/./.exec!==i},{exec:i})},function(e,t,n){"use strict";var o=n(0),i=n(30).filter,r=n(59),a=n(16),s=r("filter"),l=a("filter");o({target:"Array",proto:!0,forced:!s||!l},{filter:function(e){return i(this,e,arguments.length>1?arguments[1]:void 0)}})},function(e,t){e.exports=!1},function(e,t){e.exports=function(e){if("function"!=typeof e)throw TypeError(String(e)+" is not a function");return e}},function(e,t,n){var o=n(235),i=n(238);e.exports=function(e,t){var n=i(e,t);return o(n)?n:void 0}},function(e,t,n){"use strict";var o=n(116).charAt,i=n(32),r=n(132),a=i.set,s=i.getterFor("String Iterator");r(String,"String",(function(e){a(this,{type:"String Iterator",string:String(e),index:0})}),(function(){var e,t=s(this),n=t.string,i=t.index;return i>=n.length?{value:void 0,done:!0}:(e=o(n,i),t.index+=e.length,{value:e,done:!1})}))},function(e,t,n){var o,i=n(6),r=n(113),a=n(82),s=n(40),l=n(130),c=n(79),u=n(58),d=u("IE_PROTO"),h=function(){},f=function(e){return"<script>"+e+"<\/script>"},p=function(){try{o=document.domain&&new ActiveXObject("htmlfile")}catch(e){}var e,t;p=o?function(e){e.write(f("")),e.close();var t=e.parentWindow.Object;return e=null,t}(o):((t=c("iframe")).style.display="none",l.appendChild(t),t.src=String("javascript:"),(e=t.contentWindow.document).open(),e.write(f("document.F=Object")),e.close(),e.F);for(var n=a.length;n--;)delete p.prototype[a[n]];return p()};s[d]=!0,e.exports=Object.create||function(e,t){var n;return null!==e?(h.prototype=i(e),n=new h,h.prototype=null,n[d]=e):n=p(),void 0===t?n:r(n,t)}},function(e,t,n){var o=n(49),i=n(38),r=n(14),a=n(12),s=n(115),l=[].push,c=function(e){var t=1==e,n=2==e,c=3==e,u=4==e,d=6==e,h=5==e||d;return function(f,p,m,g){for(var w,v,y=r(f),b=i(y),k=o(p,m,3),x=a(b.length),S=0,T=g||s,C=t?T(f,x):n?T(f,0):void 0;x>S;S++)if((h||S in b)&&(v=k(w=b[S],S,y),e))if(t)C[S]=v;else if(v)switch(e){case 3:return!0;case 5:return w;case 6:return S;case 2:l.call(C,w)}else if(u)return!1;return d?-1:c||u?u:C}};e.exports={forEach:c(0),map:c(1),filter:c(2),some:c(3),every:c(4),find:c(5),findIndex:c(6)}},function(e,t){e.exports=function(e){return null!=e&&"object"==typeof e}},function(e,t,n){var o,i,r,a=n(201),s=n(2),l=n(4),c=n(15),u=n(7),d=n(58),h=n(40),f=s.WeakMap;if(a){var p=new f,m=p.get,g=p.has,w=p.set;o=function(e,t){return w.call(p,e,t),t},i=function(e){return m.call(p,e)||{}},r=function(e){return g.call(p,e)}}else{var v=d("state");h[v]=!0,o=function(e,t){return c(e,v,t),t},i=function(e){return u(e,v)?e[v]:{}},r=function(e){return u(e,v)}}e.exports={set:o,get:i,has:r,enforce:function(e){return r(e)?i(e):o(e,{})},getterFor:function(e){return function(t){var n;if(!l(t)||(n=i(t)).type!==e)throw TypeError("Incompatible receiver, "+e+" required");return n}}}},function(e,t,n){var o=n(2),i=n(145),r=n(112),a=n(15),s=n(3),l=s("iterator"),c=s("toStringTag"),u=r.values;for(var d in i){var h=o[d],f=h&&h.prototype;if(f){if(f[l]!==u)try{a(f,l,u)}catch(e){f[l]=u}if(f[c]||a(f,c,d),i[d])for(var p in r)if(f[p]!==r[p])try{a(f,p,r[p])}catch(e){f[p]=r[p]}}}},function(e,t,n){"use strict";var o=n(1);e.exports=function(e,t){var n=[][e];return!!n&&o((function(){n.call(null,t||function(){throw 1},1)}))}},function(e,t){e.exports=function(e,t){return{enumerable:!(1&e),configurable:!(2&e),writable:!(4&e),value:t}}},function(e,t,n){var o=n(18);e.exports=Array.isArray||function(e){return"Array"==o(e)}},function(e,t,n){var o=n(43),i=n(220),r=n(221),a=o?o.toStringTag:void 0;e.exports=function(e){return null==e?void 0===e?"[object Undefined]":"[object Null]":a&&a in Object(e)?i(e):r(e)}},function(e,t,n){var o=n(1),i=n(18),r="".split;e.exports=o((function(){return!Object("z").propertyIsEnumerable(0)}))?function(e){return"String"==i(e)?r.call(e,""):Object(e)}:Object},function(e,t,n){var o=n(4);e.exports=function(e,t){if(!o(e))return e;var n,i;if(t&&"function"==typeof(n=e.toString)&&!o(i=n.call(e)))return i;if("function"==typeof(n=e.valueOf)&&!o(i=n.call(e)))return i;if(!t&&"function"==typeof(n=e.toString)&&!o(i=n.call(e)))return i;throw TypeError("Can't convert object to primitive value")}},function(e,t){e.exports={}},function(e,t){e.exports={}},function(e,t,n){"use strict";var o=n(0),i=n(2),r=n(21),a=n(25),s=n(5),l=n(80),c=n(127),u=n(1),d=n(7),h=n(36),f=n(4),p=n(6),m=n(14),g=n(13),w=n(39),v=n(35),y=n(29),b=n(57),k=n(54),x=n(216),S=n(85),T=n(22),C=n(9),I=n(84),_=n(15),A=n(11),E=n(77),O=n(58),j=n(40),P=n(56),W=n(3),q=n(153),D=n(154),N=n(48),R=n(32),L=n(30).forEach,F=O("hidden"),z=W("toPrimitive"),H=R.set,$=R.getterFor("Symbol"),M=Object.prototype,G=i.Symbol,U=r("JSON","stringify"),B=T.f,V=C.f,Y=x.f,K=I.f,Q=E("symbols"),J=E("op-symbols"),X=E("string-to-symbol-registry"),Z=E("symbol-to-string-registry"),ee=E("wks"),te=i.QObject,ne=!te||!te.prototype||!te.prototype.findChild,oe=s&&u((function(){return 7!=y(V({},"a",{get:function(){return V(this,"a",{value:7}).a}})).a}))?function(e,t,n){var o=B(M,t);o&&delete M[t],V(e,t,n),o&&e!==M&&V(M,t,o)}:V,ie=function(e,t){var n=Q[e]=y(G.prototype);return H(n,{type:"Symbol",tag:e,description:t}),s||(n.description=t),n},re=c?function(e){return"symbol"==typeof e}:function(e){return Object(e)instanceof G},ae=function(e,t,n){e===M&&ae(J,t,n),p(e);var o=w(t,!0);return p(n),d(Q,o)?(n.enumerable?(d(e,F)&&e[F][o]&&(e[F][o]=!1),n=y(n,{enumerable:v(0,!1)})):(d(e,F)||V(e,F,v(1,{})),e[F][o]=!0),oe(e,o,n)):V(e,o,n)},se=function(e,t){p(e);var n=g(t),o=b(n).concat(de(n));return L(o,(function(t){s&&!le.call(n,t)||ae(e,t,n[t])})),e},le=function(e){var t=w(e,!0),n=K.call(this,t);return!(this===M&&d(Q,t)&&!d(J,t))&&(!(n||!d(this,t)||!d(Q,t)||d(this,F)&&this[F][t])||n)},ce=function(e,t){var n=g(e),o=w(t,!0);if(n!==M||!d(Q,o)||d(J,o)){var i=B(n,o);return!i||!d(Q,o)||d(n,F)&&n[F][o]||(i.enumerable=!0),i}},ue=function(e){var t=Y(g(e)),n=[];return L(t,(function(e){d(Q,e)||d(j,e)||n.push(e)})),n},de=function(e){var t=e===M,n=Y(t?J:g(e)),o=[];return L(n,(function(e){!d(Q,e)||t&&!d(M,e)||o.push(Q[e])})),o};(l||(A((G=function(){if(this instanceof G)throw TypeError("Symbol is not a constructor");var e=arguments.length&&void 0!==arguments[0]?String(arguments[0]):void 0,t=P(e),n=function(e){this===M&&n.call(J,e),d(this,F)&&d(this[F],t)&&(this[F][t]=!1),oe(this,t,v(1,e))};return s&&ne&&oe(M,t,{configurable:!0,set:n}),ie(t,e)}).prototype,"toString",(function(){return $(this).tag})),A(G,"withoutSetter",(function(e){return ie(P(e),e)})),I.f=le,C.f=ae,T.f=ce,k.f=x.f=ue,S.f=de,q.f=function(e){return ie(W(e),e)},s&&(V(G.prototype,"description",{configurable:!0,get:function(){return $(this).description}}),a||A(M,"propertyIsEnumerable",le,{unsafe:!0}))),o({global:!0,wrap:!0,forced:!l,sham:!l},{Symbol:G}),L(b(ee),(function(e){D(e)})),o({target:"Symbol",stat:!0,forced:!l},{for:function(e){var t=String(e);if(d(X,t))return X[t];var n=G(t);return X[t]=n,Z[n]=t,n},keyFor:function(e){if(!re(e))throw TypeError(e+" is not a symbol");if(d(Z,e))return Z[e]},useSetter:function(){ne=!0},useSimple:function(){ne=!1}}),o({target:"Object",stat:!0,forced:!l,sham:!s},{create:function(e,t){return void 0===t?y(e):se(y(e),t)},defineProperty:ae,defineProperties:se,getOwnPropertyDescriptor:ce}),o({target:"Object",stat:!0,forced:!l},{getOwnPropertyNames:ue,getOwnPropertySymbols:de}),o({target:"Object",stat:!0,forced:u((function(){S.f(1)}))},{getOwnPropertySymbols:function(e){return S.f(m(e))}}),U)&&o({target:"JSON",stat:!0,forced:!l||u((function(){var e=G();return"[null]"!=U([e])||"{}"!=U({a:e})||"{}"!=U(Object(e))}))},{stringify:function(e,t,n){for(var o,i=[e],r=1;arguments.length>r;)i.push(arguments[r++]);if(o=t,(f(t)||void 0!==e)&&!re(e))return h(t)||(t=function(e,t){if("function"==typeof o&&(t=o.call(this,e,t)),!re(t))return t}),i[1]=t,U.apply(null,i)}});G.prototype[z]||_(G.prototype,z,G.prototype.valueOf),N(G,"Symbol"),j[F]=!0},function(e,t,n){var o=n(19).Symbol;e.exports=o},function(e,t,n){"use strict";n.d(t,"a",(function(){return r}));n(109);var o=n(45);n(42),n(63),n(92),n(155),n(10),n(28),n(33);var i=n(69);function r(e){return function(e){if(Array.isArray(e))return Object(o.a)(e)}(e)||function(e){if("undefined"!=typeof Symbol&&Symbol.iterator in Object(e))return Array.from(e)}(e)||Object(i.a)(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}},function(e,t,n){"use strict";function o(e,t){(null==t||t>e.length)&&(t=e.length);for(var n=0,o=new Array(t);n<t;n++)o[n]=e[n];return o}n.d(t,"a",(function(){return o}))},function(e,t,n){"use strict";var o=n(107),i=n(6),r=n(14),a=n(12),s=n(47),l=n(20),c=n(119),u=n(108),d=Math.max,h=Math.min,f=Math.floor,p=/\$([$&'`]|\d\d?|<[^>]*>)/g,m=/\$([$&'`]|\d\d?)/g;o("replace",2,(function(e,t,n,o){var g=o.REGEXP_REPLACE_SUBSTITUTES_UNDEFINED_CAPTURE,w=o.REPLACE_KEEPS_$0,v=g?"$":"$0";return[function(n,o){var i=l(this),r=null==n?void 0:n[e];return void 0!==r?r.call(n,i,o):t.call(String(i),n,o)},function(e,o){if(!g&&w||"string"==typeof o&&-1===o.indexOf(v)){var r=n(t,e,this,o);if(r.done)return r.value}var l=i(e),f=String(this),p="function"==typeof o;p||(o=String(o));var m=l.global;if(m){var b=l.unicode;l.lastIndex=0}for(var k=[];;){var x=u(l,f);if(null===x)break;if(k.push(x),!m)break;""===String(x[0])&&(l.lastIndex=c(f,a(l.lastIndex),b))}for(var S,T="",C=0,I=0;I<k.length;I++){x=k[I];for(var _=String(x[0]),A=d(h(s(x.index),f.length),0),E=[],O=1;O<x.length;O++)E.push(void 0===(S=x[O])?S:String(S));var j=x.groups;if(p){var P=[_].concat(E,A,f);void 0!==j&&P.push(j);var W=String(o.apply(void 0,P))}else W=y(_,f,A,E,j,o);A>=C&&(T+=f.slice(C,A)+W,C=A+_.length)}return T+f.slice(C)}];function y(e,n,o,i,a,s){var l=o+e.length,c=i.length,u=m;return void 0!==a&&(a=r(a),u=p),t.call(s,u,(function(t,r){var s;switch(r.charAt(0)){case"$":return"$";case"&":return e;case"`":return n.slice(0,o);case"'":return n.slice(l);case"<":s=a[r.slice(1,-1)];break;default:var u=+r;if(0===u)return t;if(u>c){var d=f(u/10);return 0===d?t:d<=c?void 0===i[d-1]?r.charAt(1):i[d-1]+r.charAt(1):t}s=i[u-1]}return void 0===s?"":s}))}}))},function(e,t){var n=Math.ceil,o=Math.floor;e.exports=function(e){return isNaN(e=+e)?0:(e>0?o:n)(e)}},function(e,t,n){var o=n(9).f,i=n(7),r=n(3)("toStringTag");e.exports=function(e,t,n){e&&!i(e=n?e:e.prototype,r)&&o(e,r,{configurable:!0,value:t})}},function(e,t,n){var o=n(26);e.exports=function(e,t,n){if(o(e),void 0===t)return e;switch(n){case 0:return function(){return e.call(t)};case 1:return function(n){return e.call(t,n)};case 2:return function(n,o){return e.call(t,n,o)};case 3:return function(n,o,i){return e.call(t,n,o,i)}}return function(){return e.apply(t,arguments)}}},function(e,t,n){"use strict";var o=n(0),i=n(4),r=n(36),a=n(129),s=n(12),l=n(13),c=n(60),u=n(3),d=n(59),h=n(16),f=d("slice"),p=h("slice",{ACCESSORS:!0,0:0,1:2}),m=u("species"),g=[].slice,w=Math.max;o({target:"Array",proto:!0,forced:!f||!p},{slice:function(e,t){var n,o,u,d=l(this),h=s(d.length),f=a(e,h),p=a(void 0===t?h:t,h);if(r(d)&&("function"!=typeof(n=d.constructor)||n!==Array&&!r(n.prototype)?i(n)&&null===(n=n[m])&&(n=void 0):n=void 0,n===Array||void 0===n))return g.call(d,f,p);for(o=new(void 0===n?Array:n)(w(p-f,0)),u=0;f<p;f++,u++)f in d&&c(o,u,d[f]);return o.length=u,o}})},function(e,t,n){"use strict";var o=n(0),i=n(146);o({target:"Array",proto:!0,forced:[].forEach!=i},{forEach:i})},function(e,t,n){var o=n(2),i=n(145),r=n(146),a=n(15);for(var s in i){var l=o[s],c=l&&l.prototype;if(c&&c.forEach!==r)try{a(c,"forEach",r)}catch(e){c.forEach=r}}},function(e,t,n){"use strict";var o=n(0),i=n(1),r=n(36),a=n(4),s=n(14),l=n(12),c=n(60),u=n(115),d=n(59),h=n(3),f=n(91),p=h("isConcatSpreadable"),m=f>=51||!i((function(){var e=[];return e[p]=!1,e.concat()[0]!==e})),g=d("concat"),w=function(e){if(!a(e))return!1;var t=e[p];return void 0!==t?!!t:r(e)};o({target:"Array",proto:!0,forced:!m||!g},{concat:function(e){var t,n,o,i,r,a=s(this),d=u(a,0),h=0;for(t=-1,o=arguments.length;t<o;t++)if(w(r=-1===t?a:arguments[t])){if(h+(i=l(r.length))>9007199254740991)throw TypeError("Maximum allowed index exceeded");for(n=0;n<i;n++,h++)n in r&&c(d,h,r[n])}else{if(h>=9007199254740991)throw TypeError("Maximum allowed index exceeded");c(d,h++,r)}return d.length=h,d}})},function(e,t,n){var o=n(128),i=n(82).concat("length","prototype");t.f=Object.getOwnPropertyNames||function(e){return o(e,i)}},function(e,t,n){var o=n(5),i=n(9).f,r=Function.prototype,a=r.toString,s=/^\s*function ([^ (]*)/;o&&!("name"in r)&&i(r,"name",{configurable:!0,get:function(){try{return a.call(this).match(s)[1]}catch(e){return""}}})},function(e,t){var n=0,o=Math.random();e.exports=function(e){return"Symbol("+String(void 0===e?"":e)+")_"+(++n+o).toString(36)}},function(e,t,n){var o=n(128),i=n(82);e.exports=Object.keys||function(e){return o(e,i)}},function(e,t,n){var o=n(77),i=n(56),r=o("keys");e.exports=function(e){return r[e]||(r[e]=i(e))}},function(e,t,n){var o=n(1),i=n(3),r=n(91),a=i("species");e.exports=function(e){return r>=51||!o((function(){var t=[];return(t.constructor={})[a]=function(){return{foo:1}},1!==t[e](Boolean).foo}))}},function(e,t,n){"use strict";var o=n(39),i=n(9),r=n(35);e.exports=function(e,t,n){var a=o(t);a in e?i.f(e,a,r(0,n)):e[a]=n}},function(e,t,n){"use strict";n.d(t,"a",(function(){return i}));n(10);function o(e,t,n,o,i,r,a){try{var s=e[r](a),l=s.value}catch(e){return void n(e)}s.done?t(l):Promise.resolve(l).then(o,i)}function i(e){return function(){var t=this,n=arguments;return new Promise((function(i,r){var a=e.apply(t,n);function s(e){o(a,i,r,s,l,"next",e)}function l(e){o(a,i,r,s,l,"throw",e)}s(void 0)}))}}},function(e,t,n){"use strict";var o,i,r=n(118),a=n(194),s=RegExp.prototype.exec,l=String.prototype.replace,c=s,u=(o=/a/,i=/b*/g,s.call(o,"a"),s.call(i,"a"),0!==o.lastIndex||0!==i.lastIndex),d=a.UNSUPPORTED_Y||a.BROKEN_CARET,h=void 0!==/()??/.exec("")[1];(u||h||d)&&(c=function(e){var t,n,o,i,a=this,c=d&&a.sticky,f=r.call(a),p=a.source,m=0,g=e;return c&&(-1===(f=f.replace("y","")).indexOf("g")&&(f+="g"),g=String(e).slice(a.lastIndex),a.lastIndex>0&&(!a.multiline||a.multiline&&"\n"!==e[a.lastIndex-1])&&(p="(?: "+p+")",g=" "+g,m++),n=new RegExp("^(?:"+p+")",f)),h&&(n=new RegExp("^"+p+"$(?!\\s)",f)),u&&(t=a.lastIndex),o=s.call(c?n:a,g),c?o?(o.input=o.input.slice(m),o[0]=o[0].slice(m),o.index=a.lastIndex,a.lastIndex+=o[0].length):a.lastIndex=0:u&&o&&(a.lastIndex=a.global?o.index+o[0].length:t),h&&o&&o.length>1&&l.call(o[0],n,(function(){for(i=1;i<arguments.length-2;i++)void 0===arguments[i]&&(o[i]=void 0)})),o}),e.exports=c},function(e,t,n){"use strict";var o=n(0),i=n(5),r=n(2),a=n(7),s=n(4),l=n(9).f,c=n(133),u=r.Symbol;if(i&&"function"==typeof u&&(!("description"in u.prototype)||void 0!==u().description)){var d={},h=function(){var e=arguments.length<1||void 0===arguments[0]?void 0:String(arguments[0]),t=this instanceof h?new u(e):void 0===e?u():u(e);return""===e&&(d[t]=!0),t};c(h,u);var f=h.prototype=u.prototype;f.constructor=h;var p=f.toString,m="Symbol(test)"==String(u("test")),g=/^Symbol\((.*)\)[^)]+$/;l(f,"description",{configurable:!0,get:function(){var e=s(this)?this.valueOf():this,t=p.call(e);if(a(d,e))return"";var n=m?t.slice(7,-1):t.replace(g,"$1");return""===n?void 0:n}}),o({global:!0,forced:!0},{Symbol:h})}},function(e,t,n){var o=n(225),i=n(226),r=n(227),a=n(228),s=n(229);function l(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var o=e[t];this.set(o[0],o[1])}}l.prototype.clear=o,l.prototype.delete=i,l.prototype.get=r,l.prototype.has=a,l.prototype.set=s,e.exports=l},function(e,t,n){var o=n(159);e.exports=function(e,t){for(var n=e.length;n--;)if(o(e[n][0],t))return n;return-1}},function(e,t,n){var o=n(27)(Object,"create");e.exports=o},function(e,t,n){var o=n(247);e.exports=function(e,t){var n=e.__data__;return o(t)?n["string"==typeof t?"string":"hash"]:n.map}},function(e,t,n){var o=n(100);e.exports=function(e){if("string"==typeof e||o(e))return e;var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(e,t,n){"use strict";n.d(t,"a",(function(){return i}));n(155),n(50),n(120),n(55),n(10),n(110),n(28);var o=n(45);function i(e,t){if(e){if("string"==typeof e)return Object(o.a)(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);return"Object"===n&&e.constructor&&(n=e.constructor.name),"Map"===n||"Set"===n?Array.from(e):"Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?Object(o.a)(e,t):void 0}}},function(e,t){var n=/^\s+|\s+$/g,o=/^[-+]0x[0-9a-f]+$/i,i=/^0b[01]+$/i,r=/^0o[0-7]+$/i,a=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=s||l||Function("return this")(),u=Object.prototype.toString,d=Math.max,h=Math.min,f=function(){return c.Date.now()};function p(e){var t=typeof e;return!!e&&("object"==t||"function"==t)}function m(e){if("number"==typeof e)return e;if(function(e){return"symbol"==typeof e||function(e){return!!e&&"object"==typeof e}(e)&&"[object Symbol]"==u.call(e)}(e))return NaN;if(p(e)){var t="function"==typeof e.valueOf?e.valueOf():e;e=p(t)?t+"":t}if("string"!=typeof e)return 0===e?e:+e;e=e.replace(n,"");var s=i.test(e);return s||r.test(e)?a(e.slice(2),s?2:8):o.test(e)?NaN:+e}e.exports=function(e,t,n){var o,i,r,a,s,l,c=0,u=!1,g=!1,w=!0;if("function"!=typeof e)throw new TypeError("Expected a function");function v(t){var n=o,r=i;return o=i=void 0,c=t,a=e.apply(r,n)}function y(e){return c=e,s=setTimeout(k,t),u?v(e):a}function b(e){var n=e-l;return void 0===l||n>=t||n<0||g&&e-c>=r}function k(){var e=f();if(b(e))return x(e);s=setTimeout(k,function(e){var n=t-(e-l);return g?h(n,r-(e-c)):n}(e))}function x(e){return s=void 0,w&&o?v(e):(o=i=void 0,a)}function S(){var e=f(),n=b(e);if(o=arguments,i=this,l=e,n){if(void 0===s)return y(l);if(g)return s=setTimeout(k,t),v(l)}return void 0===s&&(s=setTimeout(k,t)),a}return t=m(t)||0,p(n)&&(u=!!n.leading,r=(g="maxWait"in n)?d(m(n.maxWait)||0,t):r,w="trailing"in n?!!n.trailing:w),S.cancel=function(){void 0!==s&&clearTimeout(s),c=0,o=l=i=s=void 0},S.flush=function(){return void 0===s?a:x(f())},S}},function(e,t,n){var o,i;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(i="function"==typeof(o=function(){var e,t,n={version:"0.2.0"},o=n.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function i(e,t,n){return e<t?t:e>n?n:e}function r(e){return 100*(-1+e)}n.configure=function(e){var t,n;for(t in e)void 0!==(n=e[t])&&e.hasOwnProperty(t)&&(o[t]=n);return this},n.status=null,n.set=function(e){var t=n.isStarted();e=i(e,o.minimum,1),n.status=1===e?null:e;var l=n.render(!t),c=l.querySelector(o.barSelector),u=o.speed,d=o.easing;return l.offsetWidth,a((function(t){""===o.positionUsing&&(o.positionUsing=n.getPositioningCSS()),s(c,function(e,t,n){var i;return(i="translate3d"===o.positionUsing?{transform:"translate3d("+r(e)+"%,0,0)"}:"translate"===o.positionUsing?{transform:"translate("+r(e)+"%,0)"}:{"margin-left":r(e)+"%"}).transition="all "+t+"ms "+n,i}(e,u,d)),1===e?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+u+"ms linear",opacity:0}),setTimeout((function(){n.remove(),t()}),u)}),u)):setTimeout(t,u)})),this},n.isStarted=function(){return"number"==typeof n.status},n.start=function(){n.status||n.set(0);var e=function(){setTimeout((function(){n.status&&(n.trickle(),e())}),o.trickleSpeed)};return o.trickle&&e(),this},n.done=function(e){return e||n.status?n.inc(.3+.5*Math.random()).set(1):this},n.inc=function(e){var t=n.status;return t?("number"!=typeof e&&(e=(1-t)*i(Math.random()*t,.1,.95)),t=i(t+e,0,.994),n.set(t)):n.start()},n.trickle=function(){return n.inc(Math.random()*o.trickleRate)},e=0,t=0,n.promise=function(o){return o&&"resolved"!==o.state()?(0===t&&n.start(),e++,t++,o.always((function(){0==--t?(e=0,n.done()):n.set((e-t)/e)})),this):this},n.render=function(e){if(n.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var t=document.createElement("div");t.id="nprogress",t.innerHTML=o.template;var i,a=t.querySelector(o.barSelector),l=e?"-100":r(n.status||0),u=document.querySelector(o.parent);return s(a,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),o.showSpinner||(i=t.querySelector(o.spinnerSelector))&&h(i),u!=document.body&&c(u,"nprogress-custom-parent"),u.appendChild(t),t},n.remove=function(){u(document.documentElement,"nprogress-busy"),u(document.querySelector(o.parent),"nprogress-custom-parent");var e=document.getElementById("nprogress");e&&h(e)},n.isRendered=function(){return!!document.getElementById("nprogress")},n.getPositioningCSS=function(){var e=document.body.style,t="WebkitTransform"in e?"Webkit":"MozTransform"in e?"Moz":"msTransform"in e?"ms":"OTransform"in e?"O":"";return t+"Perspective"in e?"translate3d":t+"Transform"in e?"translate":"margin"};var a=function(){var e=[];function t(){var n=e.shift();n&&n(t)}return function(n){e.push(n),1==e.length&&t()}}(),s=function(){var e=["Webkit","O","Moz","ms"],t={};function n(n){return n=n.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(e,t){return t.toUpperCase()})),t[n]||(t[n]=function(t){var n=document.body.style;if(t in n)return t;for(var o,i=e.length,r=t.charAt(0).toUpperCase()+t.slice(1);i--;)if((o=e[i]+r)in n)return o;return t}(n))}function o(e,t,o){t=n(t),e.style[t]=o}return function(e,t){var n,i,r=arguments;if(2==r.length)for(n in t)void 0!==(i=t[n])&&t.hasOwnProperty(n)&&o(e,n,i);else o(e,r[1],r[2])}}();function l(e,t){return("string"==typeof e?e:d(e)).indexOf(" "+t+" ")>=0}function c(e,t){var n=d(e),o=n+t;l(n,t)||(e.className=o.substring(1))}function u(e,t){var n,o=d(e);l(e,t)&&(n=o.replace(" "+t+" "," "),e.className=n.substring(1,n.length-1))}function d(e){return(" "+(e.className||"")+" ").replace(/\s+/gi," ")}function h(e){e&&e.parentNode&&e.parentNode.removeChild(e)}return n})?o.call(t,n,t,e):o)||(e.exports=i)},function(e,t,n){"use strict";var o=n(0),i=n(30).map,r=n(59),a=n(16),s=r("map"),l=a("map");o({target:"Array",proto:!0,forced:!s||!l},{map:function(e){return i(this,e,arguments.length>1?arguments[1]:void 0)}})},function(e,t,n){var o=n(0),i=n(14),r=n(57);o({target:"Object",stat:!0,forced:n(1)((function(){r(1)}))},{keys:function(e){return r(i(e))}})},function(e,t,n){"use strict";var o=n(0),i=n(38),r=n(13),a=n(34),s=[].join,l=i!=Object,c=a("join",",");o({target:"Array",proto:!0,forced:l||!c},{join:function(e){return s.call(r(this),void 0===e?",":e)}})},function(e,t,n){var o=n(3),i=n(29),r=n(9),a=o("unscopables"),s=Array.prototype;null==s[a]&&r.f(s,a,{configurable:!0,value:i(null)}),e.exports=function(e){s[a][e]=!0}},function(e,t,n){var o=n(1),i=/#|\.prototype\./,r=function(e,t){var n=s[a(e)];return n==c||n!=l&&("function"==typeof t?o(t):!!t)},a=r.normalize=function(e){return String(e).replace(i,".").toLowerCase()},s=r.data={},l=r.NATIVE="N",c=r.POLYFILL="P";e.exports=r},function(e,t,n){var o=n(25),i=n(125);(e.exports=function(e,t){return i[e]||(i[e]=void 0!==t?t:{})})("versions",[]).push({version:"3.6.5",mode:o?"pure":"global",copyright:"© 2020 Denis Pushkarev (zloirock.ru)"})},function(e,t,n){var o=n(2),i=n(15);e.exports=function(e,t){try{i(o,e,t)}catch(n){o[e]=t}return t}},function(e,t,n){var o=n(2),i=n(4),r=o.document,a=i(r)&&i(r.createElement);e.exports=function(e){return a?r.createElement(e):{}}},function(e,t,n){var o=n(1);e.exports=!!Object.getOwnPropertySymbols&&!o((function(){return!String(Symbol())}))},function(e,t,n){var o=n(13),i=n(12),r=n(129),a=function(e){return function(t,n,a){var s,l=o(t),c=i(l.length),u=r(a,c);if(e&&n!=n){for(;c>u;)if((s=l[u++])!=s)return!0}else for(;c>u;u++)if((e||u in l)&&l[u]===n)return e||u||0;return!e&&-1}};e.exports={includes:a(!0),indexOf:a(!1)}},function(e,t){e.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(e,t,n){var o=n(125),i=Function.toString;"function"!=typeof o.inspectSource&&(o.inspectSource=function(e){return i.call(e)}),e.exports=o.inspectSource},function(e,t,n){"use strict";var o={}.propertyIsEnumerable,i=Object.getOwnPropertyDescriptor,r=i&&!o.call({1:2},1);t.f=r?function(e){var t=i(this,e);return!!t&&t.enumerable}:o},function(e,t){t.f=Object.getOwnPropertySymbols},function(e,t,n){var o=n(7),i=n(14),r=n(58),a=n(136),s=r("IE_PROTO"),l=Object.prototype;e.exports=a?Object.getPrototypeOf:function(e){return e=i(e),o(e,s)?e[s]:"function"==typeof e.constructor&&e instanceof e.constructor?e.constructor.prototype:e instanceof Object?l:null}},function(e,t,n){var o=n(6),i=n(202);e.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var e,t=!1,n={};try{(e=Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set).call(n,[]),t=n instanceof Array}catch(e){}return function(n,r){return o(n),i(r),t?e.call(n,r):n.__proto__=r,n}}():void 0)},function(e,t,n){var o={};o[n(3)("toStringTag")]="z",e.exports="[object z]"===String(o)},function(e,t,n){var o=n(6),i=n(26),r=n(3)("species");e.exports=function(e,t){var n,a=o(e).constructor;return void 0===a||null==(n=o(a)[r])?t:i(n)}},function(e,t,n){var o=n(21);e.exports=o("navigator","userAgent")||""},function(e,t,n){var o,i,r=n(2),a=n(90),s=r.process,l=s&&s.versions,c=l&&l.v8;c?i=(o=c.split("."))[0]+o[1]:a&&(!(o=a.match(/Edge\/(\d+)/))||o[1]>=74)&&(o=a.match(/Chrome\/(\d+)/))&&(i=o[1]),e.exports=i&&+i},function(e,t,n){n(154)("iterator")},function(e,t,n){var o=n(219),i=n(31),r=Object.prototype,a=r.hasOwnProperty,s=r.propertyIsEnumerable,l=o(function(){return arguments}())?o:function(e){return i(e)&&a.call(e,"callee")&&!s.call(e,"callee")};e.exports=l},function(e,t,n){var o=n(27)(n(19),"Map");e.exports=o},function(e,t){e.exports=function(e){var t=typeof e;return null!=e&&("object"==t||"function"==t)}},function(e,t,n){var o=n(239),i=n(246),r=n(248),a=n(249),s=n(250);function l(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var o=e[t];this.set(o[0],o[1])}}l.prototype.clear=o,l.prototype.delete=i,l.prototype.get=r,l.prototype.has=a,l.prototype.set=s,e.exports=l},function(e,t){e.exports=function(e){var t=-1,n=Array(e.size);return e.forEach((function(e){n[++t]=e})),n}},function(e,t){e.exports=function(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=9007199254740991}},function(e,t,n){var o=n(17),i=n(100),r=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,a=/^\w*$/;e.exports=function(e,t){if(o(e))return!1;var n=typeof e;return!("number"!=n&&"symbol"!=n&&"boolean"!=n&&null!=e&&!i(e))||(a.test(e)||!r.test(e)||null!=t&&e in Object(t))}},function(e,t,n){var o=n(37),i=n(31);e.exports=function(e){return"symbol"==typeof e||i(e)&&"[object Symbol]"==o(e)}},function(e,t){e.exports=function(e){return e}},function(e,t,n){var o=n(0),i=n(5);o({target:"Object",stat:!0,forced:!i,sham:!i},{defineProperty:n(9).f})},function(e,t,n){"use strict";n.d(t,"a",(function(){return i}));n(109);n(42),n(63),n(92),n(10),n(28),n(33);var o=n(69);function i(e,t){return function(e){if(Array.isArray(e))return e}(e)||function(e,t){if("undefined"!=typeof Symbol&&Symbol.iterator in Object(e)){var n=[],o=!0,i=!1,r=void 0;try{for(var a,s=e[Symbol.iterator]();!(o=(a=s.next()).done)&&(n.push(a.value),!t||n.length!==t);o=!0);}catch(e){i=!0,r=e}finally{try{o||null==s.return||s.return()}finally{if(i)throw r}}return n}}(e,t)||Object(o.a)(e,t)||function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}},function(e,t,n){"use strict";var o=n(107),i=n(117),r=n(6),a=n(20),s=n(89),l=n(119),c=n(12),u=n(108),d=n(62),h=n(1),f=[].push,p=Math.min,m=!h((function(){return!RegExp(4294967295,"y")}));o("split",2,(function(e,t,n){var o;return o="c"=="abbc".split(/(b)*/)[1]||4!="test".split(/(?:)/,-1).length||2!="ab".split(/(?:ab)*/).length||4!=".".split(/(.?)(.?)/).length||".".split(/()()/).length>1||"".split(/.?/).length?function(e,n){var o=String(a(this)),r=void 0===n?4294967295:n>>>0;if(0===r)return[];if(void 0===e)return[o];if(!i(e))return t.call(o,e,r);for(var s,l,c,u=[],h=(e.ignoreCase?"i":"")+(e.multiline?"m":"")+(e.unicode?"u":"")+(e.sticky?"y":""),p=0,m=new RegExp(e.source,h+"g");(s=d.call(m,o))&&!((l=m.lastIndex)>p&&(u.push(o.slice(p,s.index)),s.length>1&&s.index<o.length&&f.apply(u,s.slice(1)),c=s[0].length,p=l,u.length>=r));)m.lastIndex===s.index&&m.lastIndex++;return p===o.length?!c&&m.test("")||u.push(""):u.push(o.slice(p)),u.length>r?u.slice(0,r):u}:"0".split(void 0,0).length?function(e,n){return void 0===e&&0===n?[]:t.call(this,e,n)}:t,[function(t,n){var i=a(this),r=null==t?void 0:t[e];return void 0!==r?r.call(t,i,n):o.call(String(i),t,n)},function(e,i){var a=n(o,e,this,i,o!==t);if(a.done)return a.value;var d=r(e),h=String(this),f=s(d,RegExp),g=d.unicode,w=(d.ignoreCase?"i":"")+(d.multiline?"m":"")+(d.unicode?"u":"")+(m?"y":"g"),v=new f(m?d:"^(?:"+d.source+")",w),y=void 0===i?4294967295:i>>>0;if(0===y)return[];if(0===h.length)return null===u(v,h)?[h]:[];for(var b=0,k=0,x=[];k<h.length;){v.lastIndex=m?k:0;var S,T=u(v,m?h:h.slice(k));if(null===T||(S=p(c(v.lastIndex+(m?0:k)),h.length))===b)k=l(h,k,g);else{if(x.push(h.slice(b,k)),x.length===y)return x;for(var C=1;C<=T.length-1;C++)if(x.push(T[C]),x.length===y)return x;k=b=S}}return x.push(h.slice(b)),x}]}),!m)},function(e,t,n){var o=n(114),i=n(41),r=n(3)("iterator");e.exports=function(e){if(null!=e)return e[r]||e["@@iterator"]||i[o(e)]}},function(e,t,n){var o=function(e){"use strict";var t=Object.prototype,n=t.hasOwnProperty,o="function"==typeof Symbol?Symbol:{},i=o.iterator||"@@iterator",r=o.asyncIterator||"@@asyncIterator",a=o.toStringTag||"@@toStringTag";function s(e,t,n){return Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}),e[t]}try{s({},"")}catch(e){s=function(e,t,n){return e[t]=n}}function l(e,t,n,o){var i=t&&t.prototype instanceof d?t:d,r=Object.create(i.prototype),a=new S(o||[]);return r._invoke=function(e,t,n){var o="suspendedStart";return function(i,r){if("executing"===o)throw new Error("Generator is already running");if("completed"===o){if("throw"===i)throw r;return C()}for(n.method=i,n.arg=r;;){var a=n.delegate;if(a){var s=b(a,n);if(s){if(s===u)continue;return s}}if("next"===n.method)n.sent=n._sent=n.arg;else if("throw"===n.method){if("suspendedStart"===o)throw o="completed",n.arg;n.dispatchException(n.arg)}else"return"===n.method&&n.abrupt("return",n.arg);o="executing";var l=c(e,t,n);if("normal"===l.type){if(o=n.done?"completed":"suspendedYield",l.arg===u)continue;return{value:l.arg,done:n.done}}"throw"===l.type&&(o="completed",n.method="throw",n.arg=l.arg)}}}(e,n,a),r}function c(e,t,n){try{return{type:"normal",arg:e.call(t,n)}}catch(e){return{type:"throw",arg:e}}}e.wrap=l;var u={};function d(){}function h(){}function f(){}var p={};p[i]=function(){return this};var m=Object.getPrototypeOf,g=m&&m(m(T([])));g&&g!==t&&n.call(g,i)&&(p=g);var w=f.prototype=d.prototype=Object.create(p);function v(e){["next","throw","return"].forEach((function(t){s(e,t,(function(e){return this._invoke(t,e)}))}))}function y(e,t){var o;this._invoke=function(i,r){function a(){return new t((function(o,a){!function o(i,r,a,s){var l=c(e[i],e,r);if("throw"!==l.type){var u=l.arg,d=u.value;return d&&"object"==typeof d&&n.call(d,"__await")?t.resolve(d.__await).then((function(e){o("next",e,a,s)}),(function(e){o("throw",e,a,s)})):t.resolve(d).then((function(e){u.value=e,a(u)}),(function(e){return o("throw",e,a,s)}))}s(l.arg)}(i,r,o,a)}))}return o=o?o.then(a,a):a()}}function b(e,t){var n=e.iterator[t.method];if(void 0===n){if(t.delegate=null,"throw"===t.method){if(e.iterator.return&&(t.method="return",t.arg=void 0,b(e,t),"throw"===t.method))return u;t.method="throw",t.arg=new TypeError("The iterator does not provide a 'throw' method")}return u}var o=c(n,e.iterator,t.arg);if("throw"===o.type)return t.method="throw",t.arg=o.arg,t.delegate=null,u;var i=o.arg;return i?i.done?(t[e.resultName]=i.value,t.next=e.nextLoc,"return"!==t.method&&(t.method="next",t.arg=void 0),t.delegate=null,u):i:(t.method="throw",t.arg=new TypeError("iterator result is not an object"),t.delegate=null,u)}function k(e){var t={tryLoc:e[0]};1 in e&&(t.catchLoc=e[1]),2 in e&&(t.finallyLoc=e[2],t.afterLoc=e[3]),this.tryEntries.push(t)}function x(e){var t=e.completion||{};t.type="normal",delete t.arg,e.completion=t}function S(e){this.tryEntries=[{tryLoc:"root"}],e.forEach(k,this),this.reset(!0)}function T(e){if(e){var t=e[i];if(t)return t.call(e);if("function"==typeof e.next)return e;if(!isNaN(e.length)){var o=-1,r=function t(){for(;++o<e.length;)if(n.call(e,o))return t.value=e[o],t.done=!1,t;return t.value=void 0,t.done=!0,t};return r.next=r}}return{next:C}}function C(){return{value:void 0,done:!0}}return h.prototype=w.constructor=f,f.constructor=h,h.displayName=s(f,a,"GeneratorFunction"),e.isGeneratorFunction=function(e){var t="function"==typeof e&&e.constructor;return!!t&&(t===h||"GeneratorFunction"===(t.displayName||t.name))},e.mark=function(e){return Object.setPrototypeOf?Object.setPrototypeOf(e,f):(e.__proto__=f,s(e,a,"GeneratorFunction")),e.prototype=Object.create(w),e},e.awrap=function(e){return{__await:e}},v(y.prototype),y.prototype[r]=function(){return this},e.AsyncIterator=y,e.async=function(t,n,o,i,r){void 0===r&&(r=Promise);var a=new y(l(t,n,o,i),r);return e.isGeneratorFunction(n)?a:a.next().then((function(e){return e.done?e.value:a.next()}))},v(w),s(w,a,"Generator"),w[i]=function(){return this},w.toString=function(){return"[object Generator]"},e.keys=function(e){var t=[];for(var n in e)t.push(n);return t.reverse(),function n(){for(;t.length;){var o=t.pop();if(o in e)return n.value=o,n.done=!1,n}return n.done=!0,n}},e.values=T,S.prototype={constructor:S,reset:function(e){if(this.prev=0,this.next=0,this.sent=this._sent=void 0,this.done=!1,this.delegate=null,this.method="next",this.arg=void 0,this.tryEntries.forEach(x),!e)for(var t in this)"t"===t.charAt(0)&&n.call(this,t)&&!isNaN(+t.slice(1))&&(this[t]=void 0)},stop:function(){this.done=!0;var e=this.tryEntries[0].completion;if("throw"===e.type)throw e.arg;return this.rval},dispatchException:function(e){if(this.done)throw e;var t=this;function o(n,o){return a.type="throw",a.arg=e,t.next=n,o&&(t.method="next",t.arg=void 0),!!o}for(var i=this.tryEntries.length-1;i>=0;--i){var r=this.tryEntries[i],a=r.completion;if("root"===r.tryLoc)return o("end");if(r.tryLoc<=this.prev){var s=n.call(r,"catchLoc"),l=n.call(r,"finallyLoc");if(s&&l){if(this.prev<r.catchLoc)return o(r.catchLoc,!0);if(this.prev<r.finallyLoc)return o(r.finallyLoc)}else if(s){if(this.prev<r.catchLoc)return o(r.catchLoc,!0)}else{if(!l)throw new Error("try statement without catch or finally");if(this.prev<r.finallyLoc)return o(r.finallyLoc)}}}},abrupt:function(e,t){for(var o=this.tryEntries.length-1;o>=0;--o){var i=this.tryEntries[o];if(i.tryLoc<=this.prev&&n.call(i,"finallyLoc")&&this.prev<i.finallyLoc){var r=i;break}}r&&("break"===e||"continue"===e)&&r.tryLoc<=t&&t<=r.finallyLoc&&(r=null);var a=r?r.completion:{};return a.type=e,a.arg=t,r?(this.method="next",this.next=r.finallyLoc,u):this.complete(a)},complete:function(e,t){if("throw"===e.type)throw e.arg;return"break"===e.type||"continue"===e.type?this.next=e.arg:"return"===e.type?(this.rval=this.arg=e.arg,this.method="return",this.next="end"):"normal"===e.type&&t&&(this.next=t),u},finish:function(e){for(var t=this.tryEntries.length-1;t>=0;--t){var n=this.tryEntries[t];if(n.finallyLoc===e)return this.complete(n.completion,n.afterLoc),x(n),u}},catch:function(e){for(var t=this.tryEntries.length-1;t>=0;--t){var n=this.tryEntries[t];if(n.tryLoc===e){var o=n.completion;if("throw"===o.type){var i=o.arg;x(n)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(e,t,n){return this.delegate={iterator:T(e),resultName:t,nextLoc:n},"next"===this.method&&(this.arg=void 0),u}},e}(e.exports);try{regeneratorRuntime=o}catch(e){Function("r","regeneratorRuntime = r")(o)}},function(e,t,n){"use strict";n(23);var o=n(11),i=n(1),r=n(3),a=n(62),s=n(15),l=r("species"),c=!i((function(){var e=/./;return e.exec=function(){var e=[];return e.groups={a:"7"},e},"7"!=="".replace(e,"$<a>")})),u="$0"==="a".replace(/./,"$0"),d=r("replace"),h=!!/./[d]&&""===/./[d]("a","$0"),f=!i((function(){var e=/(?:)/,t=e.exec;e.exec=function(){return t.apply(this,arguments)};var n="ab".split(e);return 2!==n.length||"a"!==n[0]||"b"!==n[1]}));e.exports=function(e,t,n,d){var p=r(e),m=!i((function(){var t={};return t[p]=function(){return 7},7!=""[e](t)})),g=m&&!i((function(){var t=!1,n=/a/;return"split"===e&&((n={}).constructor={},n.constructor[l]=function(){return n},n.flags="",n[p]=/./[p]),n.exec=function(){return t=!0,null},n[p](""),!t}));if(!m||!g||"replace"===e&&(!c||!u||h)||"split"===e&&!f){var w=/./[p],v=n(p,""[e],(function(e,t,n,o,i){return t.exec===a?m&&!i?{done:!0,value:w.call(t,n,o)}:{done:!0,value:e.call(n,t,o)}:{done:!1}}),{REPLACE_KEEPS_$0:u,REGEXP_REPLACE_SUBSTITUTES_UNDEFINED_CAPTURE:h}),y=v[0],b=v[1];o(String.prototype,e,y),o(RegExp.prototype,p,2==t?function(e,t){return b.call(e,this,t)}:function(e){return b.call(e,this)})}d&&s(RegExp.prototype[p],"sham",!0)}},function(e,t,n){var o=n(18),i=n(62);e.exports=function(e,t){var n=e.exec;if("function"==typeof n){var r=n.call(e,t);if("object"!=typeof r)throw TypeError("RegExp exec method returned something other than an Object or null");return r}if("RegExp"!==o(e))throw TypeError("RegExp#exec called on incompatible receiver");return i.call(e,t)}},function(e,t,n){n(0)({target:"Array",stat:!0},{isArray:n(36)})},function(e,t,n){"use strict";var o=n(11),i=n(6),r=n(1),a=n(118),s=RegExp.prototype,l=s.toString,c=r((function(){return"/a/b"!=l.call({source:"a",flags:"b"})})),u="toString"!=l.name;(c||u)&&o(RegExp.prototype,"toString",(function(){var e=i(this),t=String(e.source),n=e.flags;return"/"+t+"/"+String(void 0===n&&e instanceof RegExp&&!("flags"in s)?a.call(e):n)}),{unsafe:!0})},function(e,t,n){"use strict";var o=n(0),i=n(30).find,r=n(75),a=n(16),s=!0,l=a("find");"find"in[]&&Array(1).find((function(){s=!1})),o({target:"Array",proto:!0,forced:s||!l},{find:function(e){return i(this,e,arguments.length>1?arguments[1]:void 0)}}),r("find")},function(e,t,n){"use strict";var o=n(13),i=n(75),r=n(41),a=n(32),s=n(132),l=a.set,c=a.getterFor("Array Iterator");e.exports=s(Array,"Array",(function(e,t){l(this,{type:"Array Iterator",target:o(e),index:0,kind:t})}),(function(){var e=c(this),t=e.target,n=e.kind,o=e.index++;return!t||o>=t.length?(e.target=void 0,{value:void 0,done:!0}):"keys"==n?{value:o,done:!1}:"values"==n?{value:t[o],done:!1}:{value:[o,t[o]],done:!1}}),"values"),r.Arguments=r.Array,i("keys"),i("values"),i("entries")},function(e,t,n){var o=n(5),i=n(9),r=n(6),a=n(57);e.exports=o?Object.defineProperties:function(e,t){r(e);for(var n,o=a(t),s=o.length,l=0;s>l;)i.f(e,n=o[l++],t[n]);return e}},function(e,t,n){var o=n(88),i=n(18),r=n(3)("toStringTag"),a="Arguments"==i(function(){return arguments}());e.exports=o?i:function(e){var t,n,o;return void 0===e?"Undefined":null===e?"Null":"string"==typeof(n=function(e,t){try{return e[t]}catch(e){}}(t=Object(e),r))?n:a?i(t):"Object"==(o=i(t))&&"function"==typeof t.callee?"Arguments":o}},function(e,t,n){var o=n(4),i=n(36),r=n(3)("species");e.exports=function(e,t){var n;return i(e)&&("function"!=typeof(n=e.constructor)||n!==Array&&!i(n.prototype)?o(n)&&null===(n=n[r])&&(n=void 0):n=void 0),new(void 0===n?Array:n)(0===t?0:t)}},function(e,t,n){var o=n(47),i=n(20),r=function(e){return function(t,n){var r,a,s=String(i(t)),l=o(n),c=s.length;return l<0||l>=c?e?"":void 0:(r=s.charCodeAt(l))<55296||r>56319||l+1===c||(a=s.charCodeAt(l+1))<56320||a>57343?e?s.charAt(l):r:e?s.slice(l,l+2):a-56320+(r-55296<<10)+65536}};e.exports={codeAt:r(!1),charAt:r(!0)}},function(e,t,n){var o=n(4),i=n(18),r=n(3)("match");e.exports=function(e){var t;return o(e)&&(void 0!==(t=e[r])?!!t:"RegExp"==i(e))}},function(e,t,n){"use strict";var o=n(6);e.exports=function(){var e=o(this),t="";return e.global&&(t+="g"),e.ignoreCase&&(t+="i"),e.multiline&&(t+="m"),e.dotAll&&(t+="s"),e.unicode&&(t+="u"),e.sticky&&(t+="y"),t}},function(e,t,n){"use strict";var o=n(116).charAt;e.exports=function(e,t,n){return t+(n?o(e,t).length:1)}},function(e,t,n){var o=n(11),i=Date.prototype,r=i.toString,a=i.getTime;new Date(NaN)+""!="Invalid Date"&&o(i,"toString",(function(){var e=a.call(this);return e==e?r.call(this):"Invalid Date"}))},function(e,t){e.exports=function(e){return e.webpackPolyfill||(e.deprecate=function(){},e.paths=[],e.children||(e.children=[]),Object.defineProperty(e,"loaded",{enumerable:!0,get:function(){return e.l}}),Object.defineProperty(e,"id",{enumerable:!0,get:function(){return e.i}}),e.webpackPolyfill=1),e}},function(e,t,n){var o=n(20),i="["+n(123)+"]",r=RegExp("^"+i+i+"*"),a=RegExp(i+i+"*$"),s=function(e){return function(t){var n=String(o(t));return 1&e&&(n=n.replace(r,"")),2&e&&(n=n.replace(a,"")),n}};e.exports={start:s(1),end:s(2),trim:s(3)}},function(e,t){e.exports="\t\n\v\f\r                　\u2028\u2029\ufeff"},function(e,t,n){"use strict";n.d(t,"a",(function(){return r}));n(42),n(24),n(51),n(311),n(102),n(312),n(148),n(73),n(52);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}},function(e,t,n){var o=n(2),i=n(78),r=o["__core-js_shared__"]||i("__core-js_shared__",{});e.exports=r},function(e,t,n){var o=n(5),i=n(1),r=n(79);e.exports=!o&&!i((function(){return 7!=Object.defineProperty(r("div"),"a",{get:function(){return 7}}).a}))},function(e,t,n){var o=n(80);e.exports=o&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(e,t,n){var o=n(7),i=n(13),r=n(81).indexOf,a=n(40);e.exports=function(e,t){var n,s=i(e),l=0,c=[];for(n in s)!o(a,n)&&o(s,n)&&c.push(n);for(;t.length>l;)o(s,n=t[l++])&&(~r(c,n)||c.push(n));return c}},function(e,t,n){var o=n(47),i=Math.max,r=Math.min;e.exports=function(e,t){var n=o(e);return n<0?i(n+t,0):r(n,t)}},function(e,t,n){var o=n(21);e.exports=o("document","documentElement")},function(e,t,n){var o=n(2);e.exports=o},function(e,t,n){"use strict";var o=n(0),i=n(189),r=n(86),a=n(87),s=n(48),l=n(15),c=n(11),u=n(3),d=n(25),h=n(41),f=n(135),p=f.IteratorPrototype,m=f.BUGGY_SAFARI_ITERATORS,g=u("iterator"),w=function(){return this};e.exports=function(e,t,n,u,f,v,y){i(n,t,u);var b,k,x,S=function(e){if(e===f&&A)return A;if(!m&&e in I)return I[e];switch(e){case"keys":case"values":case"entries":return function(){return new n(this,e)}}return function(){return new n(this)}},T=t+" Iterator",C=!1,I=e.prototype,_=I[g]||I["@@iterator"]||f&&I[f],A=!m&&_||S(f),E="Array"==t&&I.entries||_;if(E&&(b=r(E.call(new e)),p!==Object.prototype&&b.next&&(d||r(b)===p||(a?a(b,p):"function"!=typeof b[g]&&l(b,g,w)),s(b,T,!0,!0),d&&(h[T]=w))),"values"==f&&_&&"values"!==_.name&&(C=!0,A=function(){return _.call(this)}),d&&!y||I[g]===A||l(I,g,A),h[t]=A,f)if(k={values:S("values"),keys:v?A:S("keys"),entries:S("entries")},y)for(x in k)(m||C||!(x in I))&&c(I,x,k[x]);else o({target:t,proto:!0,forced:m||C},k);return k}},function(e,t,n){var o=n(7),i=n(134),r=n(22),a=n(9);e.exports=function(e,t){for(var n=i(t),s=a.f,l=r.f,c=0;c<n.length;c++){var u=n[c];o(e,u)||s(e,u,l(t,u))}}},function(e,t,n){var o=n(21),i=n(54),r=n(85),a=n(6);e.exports=o("Reflect","ownKeys")||function(e){var t=i.f(a(e)),n=r.f;return n?t.concat(n(e)):t}},function(e,t,n){"use strict";var o,i,r,a=n(86),s=n(15),l=n(7),c=n(3),u=n(25),d=c("iterator"),h=!1;[].keys&&("next"in(r=[].keys())?(i=a(a(r)))!==Object.prototype&&(o=i):h=!0),null==o&&(o={}),u||l(o,d)||s(o,d,(function(){return this})),e.exports={IteratorPrototype:o,BUGGY_SAFARI_ITERATORS:h}},function(e,t,n){var o=n(1);e.exports=!o((function(){function e(){}return e.prototype.constructor=null,Object.getPrototypeOf(new e)!==e.prototype}))},function(e,t,n){var o=n(2);e.exports=o.Promise},function(e,t,n){var o=n(3),i=n(41),r=o("iterator"),a=Array.prototype;e.exports=function(e){return void 0!==e&&(i.Array===e||a[r]===e)}},function(e,t,n){var o=n(6);e.exports=function(e,t,n,i){try{return i?t(o(n)[0],n[1]):t(n)}catch(t){var r=e.return;throw void 0!==r&&o(r.call(e)),t}}},function(e,t,n){var o=n(3)("iterator"),i=!1;try{var r=0,a={next:function(){return{done:!!r++}},return:function(){i=!0}};a[o]=function(){return this},Array.from(a,(function(){throw 2}))}catch(e){}e.exports=function(e,t){if(!t&&!i)return!1;var n=!1;try{var r={};r[o]=function(){return{next:function(){return{done:n=!0}}}},e(r)}catch(e){}return n}},function(e,t,n){var o,i,r,a=n(2),s=n(1),l=n(18),c=n(49),u=n(130),d=n(79),h=n(142),f=a.location,p=a.setImmediate,m=a.clearImmediate,g=a.process,w=a.MessageChannel,v=a.Dispatch,y=0,b={},k=function(e){if(b.hasOwnProperty(e)){var t=b[e];delete b[e],t()}},x=function(e){return function(){k(e)}},S=function(e){k(e.data)},T=function(e){a.postMessage(e+"",f.protocol+"//"+f.host)};p&&m||(p=function(e){for(var t=[],n=1;arguments.length>n;)t.push(arguments[n++]);return b[++y]=function(){("function"==typeof e?e:Function(e)).apply(void 0,t)},o(y),y},m=function(e){delete b[e]},"process"==l(g)?o=function(e){g.nextTick(x(e))}:v&&v.now?o=function(e){v.now(x(e))}:w&&!h?(r=(i=new w).port2,i.port1.onmessage=S,o=c(r.postMessage,r,1)):!a.addEventListener||"function"!=typeof postMessage||a.importScripts||s(T)||"file:"===f.protocol?o="onreadystatechange"in d("script")?function(e){u.appendChild(d("script")).onreadystatechange=function(){u.removeChild(this),k(e)}}:function(e){setTimeout(x(e),0)}:(o=T,a.addEventListener("message",S,!1))),e.exports={set:p,clear:m}},function(e,t,n){var o=n(90);e.exports=/(iphone|ipod|ipad).*applewebkit/i.test(o)},function(e,t,n){var o=n(6),i=n(4),r=n(144);e.exports=function(e,t){if(o(e),i(t)&&t.constructor===e)return t;var n=r.f(e);return(0,n.resolve)(t),n.promise}},function(e,t,n){"use strict";var o=n(26),i=function(e){var t,n;this.promise=new e((function(e,o){if(void 0!==t||void 0!==n)throw TypeError("Bad Promise constructor");t=e,n=o})),this.resolve=o(t),this.reject=o(n)};e.exports.f=function(e){return new i(e)}},function(e,t){e.exports={CSSRuleList:0,CSSStyleDeclaration:0,CSSValueList:0,ClientRectList:0,DOMRectList:0,DOMStringList:0,DOMTokenList:1,DataTransferItemList:0,FileList:0,HTMLAllCollection:0,HTMLCollection:0,HTMLFormElement:0,HTMLSelectElement:0,MediaList:0,MimeTypeArray:0,NamedNodeMap:0,NodeList:1,PaintRequestList:0,Plugin:0,PluginArray:0,SVGLengthList:0,SVGNumberList:0,SVGPathSegList:0,SVGPointList:0,SVGStringList:0,SVGTransformList:0,SourceBufferList:0,StyleSheetList:0,TextTrackCueList:0,TextTrackList:0,TouchList:0}},function(e,t,n){"use strict";var o=n(30).forEach,i=n(34),r=n(16),a=i("forEach"),s=r("forEach");e.exports=a&&s?[].forEach:function(e){return o(this,e,arguments.length>1?arguments[1]:void 0)}},function(e,t,n){var o=n(1);e.exports=!o((function(){return Object.isExtensible(Object.preventExtensions({}))}))},function(e,t,n){var o=n(0),i=n(5),r=n(134),a=n(13),s=n(22),l=n(60);o({target:"Object",stat:!0,sham:!i},{getOwnPropertyDescriptors:function(e){for(var t,n,o=a(e),i=s.f,c=r(o),u={},d=0;c.length>d;)void 0!==(n=i(o,t=c[d++]))&&l(u,t,n);return u}})},function(e,t,n){var o=n(0),i=n(1),r=n(14),a=n(86),s=n(136);o({target:"Object",stat:!0,forced:i((function(){a(1)})),sham:!s},{getPrototypeOf:function(e){return a(r(e))}})},function(e,t,n){var o=n(117);e.exports=function(e){if(o(e))throw TypeError("The method doesn't accept regular expressions");return e}},function(e,t,n){var o=n(3)("match");e.exports=function(e){var t=/./;try{"/./"[e](t)}catch(n){try{return t[o]=!1,"/./"[e](t)}catch(e){}}return!1}},function(e,t,n){n(0)({target:"Object",stat:!0,sham:!n(5)},{create:n(29)})},function(e,t,n){var o=n(3);t.f=o},function(e,t,n){var o=n(131),i=n(7),r=n(153),a=n(9).f;e.exports=function(e){var t=o.Symbol||(o.Symbol={});i(t,e)||a(t,e,{value:r.f(e)})}},function(e,t,n){var o=n(0),i=n(196);o({target:"Array",stat:!0,forced:!n(140)((function(e){Array.from(e)}))},{from:i})},function(e,t){e.exports=function(e,t){for(var n=-1,o=t.length,i=e.length;++n<o;)e[i+n]=t[n];return e}},function(e,t){var n="object"==typeof global&&global&&global.Object===Object&&global;e.exports=n},function(e,t,n){var o=n(64),i=n(230),r=n(231),a=n(232),s=n(233),l=n(234);function c(e){var t=this.__data__=new o(e);this.size=t.size}c.prototype.clear=i,c.prototype.delete=r,c.prototype.get=a,c.prototype.has=s,c.prototype.set=l,e.exports=c},function(e,t){e.exports=function(e,t){return e===t||e!=e&&t!=t}},function(e,t,n){var o=n(37),i=n(95);e.exports=function(e){if(!i(e))return!1;var t=o(e);return"[object Function]"==t||"[object GeneratorFunction]"==t||"[object AsyncFunction]"==t||"[object Proxy]"==t}},function(e,t){var n=Function.prototype.toString;e.exports=function(e){if(null!=e){try{return n.call(e)}catch(e){}try{return e+""}catch(e){}}return""}},function(e,t,n){var o=n(251),i=n(31);e.exports=function e(t,n,r,a,s){return t===n||(null==t||null==n||!i(t)&&!i(n)?t!=t&&n!=n:o(t,n,r,a,e,s))}},function(e,t,n){var o=n(164),i=n(254),r=n(165);e.exports=function(e,t,n,a,s,l){var c=1&n,u=e.length,d=t.length;if(u!=d&&!(c&&d>u))return!1;var h=l.get(e),f=l.get(t);if(h&&f)return h==t&&f==e;var p=-1,m=!0,g=2&n?new o:void 0;for(l.set(e,t),l.set(t,e);++p<u;){var w=e[p],v=t[p];if(a)var y=c?a(v,w,p,t,e,l):a(w,v,p,e,t,l);if(void 0!==y){if(y)continue;m=!1;break}if(g){if(!i(t,(function(e,t){if(!r(g,t)&&(w===e||s(w,e,n,a,l)))return g.push(t)}))){m=!1;break}}else if(w!==v&&!s(w,v,n,a,l)){m=!1;break}}return l.delete(e),l.delete(t),m}},function(e,t,n){var o=n(96),i=n(252),r=n(253);function a(e){var t=-1,n=null==e?0:e.length;for(this.__data__=new o;++t<n;)this.add(e[t])}a.prototype.add=a.prototype.push=i,a.prototype.has=r,e.exports=a},function(e,t){e.exports=function(e,t){return e.has(t)}},function(e,t,n){var o=n(264),i=n(270),r=n(170);e.exports=function(e){return r(e)?o(e):i(e)}},function(e,t,n){(function(e){var o=n(19),i=n(266),r=t&&!t.nodeType&&t,a=r&&"object"==typeof e&&e&&!e.nodeType&&e,s=a&&a.exports===r?o.Buffer:void 0,l=(s?s.isBuffer:void 0)||i;e.exports=l}).call(this,n(121)(e))},function(e,t){var n=/^(?:0|[1-9]\d*)$/;e.exports=function(e,t){var o=typeof e;return!!(t=null==t?9007199254740991:t)&&("number"==o||"symbol"!=o&&n.test(e))&&e>-1&&e%1==0&&e<t}},function(e,t,n){var o=n(267),i=n(268),r=n(269),a=r&&r.isTypedArray,s=a?i(a):o;e.exports=s},function(e,t,n){var o=n(160),i=n(98);e.exports=function(e){return null!=e&&i(e.length)&&!o(e)}},function(e,t,n){var o=n(27)(n(19),"Set");e.exports=o},function(e,t,n){var o=n(95);e.exports=function(e){return e==e&&!o(e)}},function(e,t){e.exports=function(e,t){return function(n){return null!=n&&(n[e]===t&&(void 0!==t||e in Object(n)))}}},function(e,t,n){var o=n(175),i=n(68);e.exports=function(e,t){for(var n=0,r=(t=o(t,e)).length;null!=e&&n<r;)e=e[i(t[n++])];return n&&n==r?e:void 0}},function(e,t,n){var o=n(17),i=n(99),r=n(281),a=n(284);e.exports=function(e,t){return o(e)?e:i(e,t)?[e]:r(a(e))}},function(e,t,n){var o=n(0),i=n(2),r=n(90),a=[].slice,s=function(e){return function(t,n){var o=arguments.length>2,i=o?a.call(arguments,2):void 0;return e(o?function(){("function"==typeof t?t:Function(t)).apply(this,i)}:t,n)}};o({global:!0,bind:!0,forced:/MSIE .\./.test(r)},{setTimeout:s(i.setTimeout),setInterval:s(i.setInterval)})},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){n(0)({target:"Object",stat:!0},{setPrototypeOf:n(87)})},function(e,t,n){var o=n(0),i=n(21),r=n(26),a=n(6),s=n(4),l=n(29),c=n(323),u=n(1),d=i("Reflect","construct"),h=u((function(){function e(){}return!(d((function(){}),[],e)instanceof e)})),f=!u((function(){d((function(){}))})),p=h||f;o({target:"Reflect",stat:!0,forced:p,sham:p},{construct:function(e,t){r(e),a(t);var n=arguments.length<3?e:r(arguments[2]);if(f&&!h)return d(e,t,n);if(e==n){switch(t.length){case 0:return new e;case 1:return new e(t[0]);case 2:return new e(t[0],t[1]);case 3:return new e(t[0],t[1],t[2]);case 4:return new e(t[0],t[1],t[2],t[3])}var o=[null];return o.push.apply(o,t),new(c.apply(e,o))}var i=n.prototype,u=l(s(i)?i:Object.prototype),p=Function.apply.call(e,u,t);return s(p)?p:u}})},function(e,t,n){},function(e,t,n){},function(e,t,n){var o=n(217),i=n(222),r=n(293),a=n(301),s=n(310),l=n(197),c=r((function(e){var t=l(e);return s(t)&&(t=void 0),a(o(e,1,s,!0),i(t,2))}));e.exports=c},function(e,t,n){"use strict";var o=n(0),i=n(30).some,r=n(34),a=n(16),s=r("some"),l=a("some");o({target:"Array",proto:!0,forced:!s||!l},{some:function(e){return i(this,e,arguments.length>1?arguments[1]:void 0)}})},function(e,t,n){"use strict";var o=n(0),i=n(81).indexOf,r=n(34),a=n(16),s=[].indexOf,l=!!s&&1/[1].indexOf(1,-0)<0,c=r("indexOf"),u=a("indexOf",{ACCESSORS:!0,1:0});o({target:"Array",proto:!0,forced:l||!c||!u},{indexOf:function(e){return l?s.apply(this,arguments)||0:i(this,e,arguments.length>1?arguments[1]:void 0)}})},function(e,t){e.exports=function(e,t,n){if(!(e instanceof t))throw TypeError("Incorrect "+(n?n+" ":"")+"invocation");return e}},function(e,t,n){"use strict";var o=n(135).IteratorPrototype,i=n(29),r=n(35),a=n(48),s=n(41),l=function(){return this};e.exports=function(e,t,n){var c=t+" Iterator";return e.prototype=i(o,{next:r(1,n)}),a(e,c,!1,!0),s[c]=l,e}},function(e,t,n){var o=n(11);e.exports=function(e,t,n){for(var i in t)o(e,i,t[i],n);return e}},function(e,t,n){"use strict";var o=n(21),i=n(9),r=n(3),a=n(5),s=r("species");e.exports=function(e){var t=o(e),n=i.f;a&&t&&!t[s]&&n(t,s,{configurable:!0,get:function(){return this}})}},function(e,t,n){"use strict";var o=n(5),i=n(1),r=n(57),a=n(85),s=n(84),l=n(14),c=n(38),u=Object.assign,d=Object.defineProperty;e.exports=!u||i((function(){if(o&&1!==u({b:1},u(d({},"a",{enumerable:!0,get:function(){d(this,"b",{value:3,enumerable:!1})}}),{b:2})).b)return!0;var e={},t={},n=Symbol();return e[n]=7,"abcdefghijklmnopqrst".split("").forEach((function(e){t[e]=e})),7!=u({},e)[n]||"abcdefghijklmnopqrst"!=r(u({},t)).join("")}))?function(e,t){for(var n=l(e),i=arguments.length,u=1,d=a.f,h=s.f;i>u;)for(var f,p=c(arguments[u++]),m=d?r(p).concat(d(p)):r(p),g=m.length,w=0;g>w;)f=m[w++],o&&!h.call(p,f)||(n[f]=p[f]);return n}:u},function(e,t,n){"use strict";var o=n(0),i=n(81).includes,r=n(75);o({target:"Array",proto:!0,forced:!n(16)("indexOf",{ACCESSORS:!0,1:0})},{includes:function(e){return i(this,e,arguments.length>1?arguments[1]:void 0)}}),r("includes")},function(e,t,n){"use strict";var o=n(1);function i(e,t){return RegExp(e,t)}t.UNSUPPORTED_Y=o((function(){var e=i("a","y");return e.lastIndex=2,null!=e.exec("abcd")})),t.BROKEN_CARET=o((function(){var e=i("^r","gy");return e.lastIndex=2,null!=e.exec("str")}))},function(e,t,n){"use strict";var o=n(0),i=n(150),r=n(20);o({target:"String",proto:!0,forced:!n(151)("includes")},{includes:function(e){return!!~String(r(this)).indexOf(i(e),arguments.length>1?arguments[1]:void 0)}})},function(e,t,n){"use strict";var o=n(49),i=n(14),r=n(139),a=n(138),s=n(12),l=n(60),c=n(105);e.exports=function(e){var t,n,u,d,h,f,p=i(e),m="function"==typeof this?this:Array,g=arguments.length,w=g>1?arguments[1]:void 0,v=void 0!==w,y=c(p),b=0;if(v&&(w=o(w,g>2?arguments[2]:void 0,2)),null==y||m==Array&&a(y))for(n=new m(t=s(p.length));t>b;b++)f=v?w(p[b],b):p[b],l(n,b,f);else for(h=(d=y.call(p)).next,n=new m;!(u=h.call(d)).done;b++)f=v?r(d,w,[u.value,b],!0):u.value,l(n,b,f);return n.length=b,n}},function(e,t){e.exports=function(e){var t=null==e?0:e.length;return t?e[t-1]:void 0}},function(e,t,n){var o=n(0),i=n(313);o({global:!0,forced:parseInt!=i},{parseInt:i})},function(e,t,n){var o=n(4),i=n(87);e.exports=function(e,t,n){var r,a;return i&&"function"==typeof(r=t.constructor)&&r!==n&&o(a=r.prototype)&&a!==n.prototype&&i(e,a),e}},function(e,t,n){e.exports=n(326)},function(e,t,n){var o=n(2),i=n(83),r=o.WeakMap;e.exports="function"==typeof r&&/native code/.test(i(r))},function(e,t,n){var o=n(4);e.exports=function(e){if(!o(e)&&null!==e)throw TypeError("Can't set "+String(e)+" as a prototype");return e}},function(e,t,n){"use strict";var o,i,r,a,s=n(0),l=n(25),c=n(2),u=n(21),d=n(137),h=n(11),f=n(190),p=n(48),m=n(191),g=n(4),w=n(26),v=n(188),y=n(18),b=n(83),k=n(204),x=n(140),S=n(89),T=n(141).set,C=n(205),I=n(143),_=n(206),A=n(144),E=n(207),O=n(32),j=n(76),P=n(3),W=n(91),q=P("species"),D="Promise",N=O.get,R=O.set,L=O.getterFor(D),F=d,z=c.TypeError,H=c.document,$=c.process,M=u("fetch"),G=A.f,U=G,B="process"==y($),V=!!(H&&H.createEvent&&c.dispatchEvent),Y=j(D,(function(){if(!(b(F)!==String(F))){if(66===W)return!0;if(!B&&"function"!=typeof PromiseRejectionEvent)return!0}if(l&&!F.prototype.finally)return!0;if(W>=51&&/native code/.test(F))return!1;var e=F.resolve(1),t=function(e){e((function(){}),(function(){}))};return(e.constructor={})[q]=t,!(e.then((function(){}))instanceof t)})),K=Y||!x((function(e){F.all(e).catch((function(){}))})),Q=function(e){var t;return!(!g(e)||"function"!=typeof(t=e.then))&&t},J=function(e,t,n){if(!t.notified){t.notified=!0;var o=t.reactions;C((function(){for(var i=t.value,r=1==t.state,a=0;o.length>a;){var s,l,c,u=o[a++],d=r?u.ok:u.fail,h=u.resolve,f=u.reject,p=u.domain;try{d?(r||(2===t.rejection&&te(e,t),t.rejection=1),!0===d?s=i:(p&&p.enter(),s=d(i),p&&(p.exit(),c=!0)),s===u.promise?f(z("Promise-chain cycle")):(l=Q(s))?l.call(s,h,f):h(s)):f(i)}catch(e){p&&!c&&p.exit(),f(e)}}t.reactions=[],t.notified=!1,n&&!t.rejection&&Z(e,t)}))}},X=function(e,t,n){var o,i;V?((o=H.createEvent("Event")).promise=t,o.reason=n,o.initEvent(e,!1,!0),c.dispatchEvent(o)):o={promise:t,reason:n},(i=c["on"+e])?i(o):"unhandledrejection"===e&&_("Unhandled promise rejection",n)},Z=function(e,t){T.call(c,(function(){var n,o=t.value;if(ee(t)&&(n=E((function(){B?$.emit("unhandledRejection",o,e):X("unhandledrejection",e,o)})),t.rejection=B||ee(t)?2:1,n.error))throw n.value}))},ee=function(e){return 1!==e.rejection&&!e.parent},te=function(e,t){T.call(c,(function(){B?$.emit("rejectionHandled",e):X("rejectionhandled",e,t.value)}))},ne=function(e,t,n,o){return function(i){e(t,n,i,o)}},oe=function(e,t,n,o){t.done||(t.done=!0,o&&(t=o),t.value=n,t.state=2,J(e,t,!0))},ie=function(e,t,n,o){if(!t.done){t.done=!0,o&&(t=o);try{if(e===n)throw z("Promise can't be resolved itself");var i=Q(n);i?C((function(){var o={done:!1};try{i.call(n,ne(ie,e,o,t),ne(oe,e,o,t))}catch(n){oe(e,o,n,t)}})):(t.value=n,t.state=1,J(e,t,!1))}catch(n){oe(e,{done:!1},n,t)}}};Y&&(F=function(e){v(this,F,D),w(e),o.call(this);var t=N(this);try{e(ne(ie,this,t),ne(oe,this,t))}catch(e){oe(this,t,e)}},(o=function(e){R(this,{type:D,done:!1,notified:!1,parent:!1,reactions:[],rejection:!1,state:0,value:void 0})}).prototype=f(F.prototype,{then:function(e,t){var n=L(this),o=G(S(this,F));return o.ok="function"!=typeof e||e,o.fail="function"==typeof t&&t,o.domain=B?$.domain:void 0,n.parent=!0,n.reactions.push(o),0!=n.state&&J(this,n,!1),o.promise},catch:function(e){return this.then(void 0,e)}}),i=function(){var e=new o,t=N(e);this.promise=e,this.resolve=ne(ie,e,t),this.reject=ne(oe,e,t)},A.f=G=function(e){return e===F||e===r?new i(e):U(e)},l||"function"!=typeof d||(a=d.prototype.then,h(d.prototype,"then",(function(e,t){var n=this;return new F((function(e,t){a.call(n,e,t)})).then(e,t)}),{unsafe:!0}),"function"==typeof M&&s({global:!0,enumerable:!0,forced:!0},{fetch:function(e){return I(F,M.apply(c,arguments))}}))),s({global:!0,wrap:!0,forced:Y},{Promise:F}),p(F,D,!1,!0),m(D),r=u(D),s({target:D,stat:!0,forced:Y},{reject:function(e){var t=G(this);return t.reject.call(void 0,e),t.promise}}),s({target:D,stat:!0,forced:l||Y},{resolve:function(e){return I(l&&this===r?F:this,e)}}),s({target:D,stat:!0,forced:K},{all:function(e){var t=this,n=G(t),o=n.resolve,i=n.reject,r=E((function(){var n=w(t.resolve),r=[],a=0,s=1;k(e,(function(e){var l=a++,c=!1;r.push(void 0),s++,n.call(t,e).then((function(e){c||(c=!0,r[l]=e,--s||o(r))}),i)})),--s||o(r)}));return r.error&&i(r.value),n.promise},race:function(e){var t=this,n=G(t),o=n.reject,i=E((function(){var i=w(t.resolve);k(e,(function(e){i.call(t,e).then(n.resolve,o)}))}));return i.error&&o(i.value),n.promise}})},function(e,t,n){var o=n(6),i=n(138),r=n(12),a=n(49),s=n(105),l=n(139),c=function(e,t){this.stopped=e,this.result=t};(e.exports=function(e,t,n,u,d){var h,f,p,m,g,w,v,y=a(t,n,u?2:1);if(d)h=e;else{if("function"!=typeof(f=s(e)))throw TypeError("Target is not iterable");if(i(f)){for(p=0,m=r(e.length);m>p;p++)if((g=u?y(o(v=e[p])[0],v[1]):y(e[p]))&&g instanceof c)return g;return new c(!1)}h=f.call(e)}for(w=h.next;!(v=w.call(h)).done;)if("object"==typeof(g=l(h,y,v.value,u))&&g&&g instanceof c)return g;return new c(!1)}).stop=function(e){return new c(!0,e)}},function(e,t,n){var o,i,r,a,s,l,c,u,d=n(2),h=n(22).f,f=n(18),p=n(141).set,m=n(142),g=d.MutationObserver||d.WebKitMutationObserver,w=d.process,v=d.Promise,y="process"==f(w),b=h(d,"queueMicrotask"),k=b&&b.value;k||(o=function(){var e,t;for(y&&(e=w.domain)&&e.exit();i;){t=i.fn,i=i.next;try{t()}catch(e){throw i?a():r=void 0,e}}r=void 0,e&&e.enter()},y?a=function(){w.nextTick(o)}:g&&!m?(s=!0,l=document.createTextNode(""),new g(o).observe(l,{characterData:!0}),a=function(){l.data=s=!s}):v&&v.resolve?(c=v.resolve(void 0),u=c.then,a=function(){u.call(c,o)}):a=function(){p.call(d,o)}),e.exports=k||function(e){var t={fn:e,next:void 0};r&&(r.next=t),i||(i=t,a()),r=t}},function(e,t,n){var o=n(2);e.exports=function(e,t){var n=o.console;n&&n.error&&(1===arguments.length?n.error(e):n.error(e,t))}},function(e,t){e.exports=function(e){try{return{error:!1,value:e()}}catch(e){return{error:!0,value:e}}}},function(e,t,n){var o=n(0),i=n(192);o({target:"Object",stat:!0,forced:Object.assign!==i},{assign:i})},function(e,t,n){"use strict";var o=n(0),i=n(25),r=n(137),a=n(1),s=n(21),l=n(89),c=n(143),u=n(11);o({target:"Promise",proto:!0,real:!0,forced:!!r&&a((function(){r.prototype.finally.call({then:function(){}},(function(){}))}))},{finally:function(e){var t=l(this,s("Promise")),n="function"==typeof e;return this.then(n?function(n){return c(t,e()).then((function(){return n}))}:e,n?function(n){return c(t,e()).then((function(){throw n}))}:e)}}),i||"function"!=typeof r||r.prototype.finally||u(r.prototype,"finally",s("Promise").prototype.finally)},function(e,t,n){"use strict";var o=n(88),i=n(114);e.exports=o?{}.toString:function(){return"[object "+i(this)+"]"}},function(e,t,n){"use strict";var o=n(0),i=n(212).left,r=n(34),a=n(16),s=r("reduce"),l=a("reduce",{1:0});o({target:"Array",proto:!0,forced:!s||!l},{reduce:function(e){return i(this,e,arguments.length,arguments.length>1?arguments[1]:void 0)}})},function(e,t,n){var o=n(26),i=n(14),r=n(38),a=n(12),s=function(e){return function(t,n,s,l){o(n);var c=i(t),u=r(c),d=a(c.length),h=e?d-1:0,f=e?-1:1;if(s<2)for(;;){if(h in u){l=u[h],h+=f;break}if(h+=f,e?h<0:d<=h)throw TypeError("Reduce of empty array with no initial value")}for(;e?h>=0:d>h;h+=f)h in u&&(l=n(l,u[h],h,c));return l}};e.exports={left:s(!1),right:s(!0)}},function(e,t,n){var o=n(0),i=n(147),r=n(1),a=n(4),s=n(214).onFreeze,l=Object.freeze;o({target:"Object",stat:!0,forced:r((function(){l(1)})),sham:!i},{freeze:function(e){return l&&a(e)?l(s(e)):e}})},function(e,t,n){var o=n(40),i=n(4),r=n(7),a=n(9).f,s=n(56),l=n(147),c=s("meta"),u=0,d=Object.isExtensible||function(){return!0},h=function(e){a(e,c,{value:{objectID:"O"+ ++u,weakData:{}}})},f=e.exports={REQUIRED:!1,fastKey:function(e,t){if(!i(e))return"symbol"==typeof e?e:("string"==typeof e?"S":"P")+e;if(!r(e,c)){if(!d(e))return"F";if(!t)return"E";h(e)}return e[c].objectID},getWeakData:function(e,t){if(!r(e,c)){if(!d(e))return!0;if(!t)return!1;h(e)}return e[c].weakData},onFreeze:function(e){return l&&f.REQUIRED&&d(e)&&!r(e,c)&&h(e),e}};o[c]=!0},function(e,t,n){"use strict";var o,i=n(0),r=n(22).f,a=n(12),s=n(150),l=n(20),c=n(151),u=n(25),d="".startsWith,h=Math.min,f=c("startsWith");i({target:"String",proto:!0,forced:!!(u||f||(o=r(String.prototype,"startsWith"),!o||o.writable))&&!f},{startsWith:function(e){var t=String(l(this));s(e);var n=a(h(arguments.length>1?arguments[1]:void 0,t.length)),o=String(e);return d?d.call(t,o,n):t.slice(n,n+o.length)===o}})},function(e,t,n){var o=n(13),i=n(54).f,r={}.toString,a="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[];e.exports.f=function(e){return a&&"[object Window]"==r.call(e)?function(e){try{return i(e)}catch(e){return a.slice()}}(e):i(o(e))}},function(e,t,n){var o=n(156),i=n(218);e.exports=function e(t,n,r,a,s){var l=-1,c=t.length;for(r||(r=i),s||(s=[]);++l<c;){var u=t[l];n>0&&r(u)?n>1?e(u,n-1,r,a,s):o(s,u):a||(s[s.length]=u)}return s}},function(e,t,n){var o=n(43),i=n(93),r=n(17),a=o?o.isConcatSpreadable:void 0;e.exports=function(e){return r(e)||i(e)||!!(a&&e&&e[a])}},function(e,t,n){var o=n(37),i=n(31);e.exports=function(e){return i(e)&&"[object Arguments]"==o(e)}},function(e,t,n){var o=n(43),i=Object.prototype,r=i.hasOwnProperty,a=i.toString,s=o?o.toStringTag:void 0;e.exports=function(e){var t=r.call(e,s),n=e[s];try{e[s]=void 0;var o=!0}catch(e){}var i=a.call(e);return o&&(t?e[s]=n:delete e[s]),i}},function(e,t){var n=Object.prototype.toString;e.exports=function(e){return n.call(e)}},function(e,t,n){var o=n(223),i=n(279),r=n(101),a=n(17),s=n(290);e.exports=function(e){return"function"==typeof e?e:null==e?r:"object"==typeof e?a(e)?i(e[0],e[1]):o(e):s(e)}},function(e,t,n){var o=n(224),i=n(278),r=n(173);e.exports=function(e){var t=i(e);return 1==t.length&&t[0][2]?r(t[0][0],t[0][1]):function(n){return n===e||o(n,e,t)}}},function(e,t,n){var o=n(158),i=n(162);e.exports=function(e,t,n,r){var a=n.length,s=a,l=!r;if(null==e)return!s;for(e=Object(e);a--;){var c=n[a];if(l&&c[2]?c[1]!==e[c[0]]:!(c[0]in e))return!1}for(;++a<s;){var u=(c=n[a])[0],d=e[u],h=c[1];if(l&&c[2]){if(void 0===d&&!(u in e))return!1}else{var f=new o;if(r)var p=r(d,h,u,e,t,f);if(!(void 0===p?i(h,d,3,r,f):p))return!1}}return!0}},function(e,t){e.exports=function(){this.__data__=[],this.size=0}},function(e,t,n){var o=n(65),i=Array.prototype.splice;e.exports=function(e){var t=this.__data__,n=o(t,e);return!(n<0)&&(n==t.length-1?t.pop():i.call(t,n,1),--this.size,!0)}},function(e,t,n){var o=n(65);e.exports=function(e){var t=this.__data__,n=o(t,e);return n<0?void 0:t[n][1]}},function(e,t,n){var o=n(65);e.exports=function(e){return o(this.__data__,e)>-1}},function(e,t,n){var o=n(65);e.exports=function(e,t){var n=this.__data__,i=o(n,e);return i<0?(++this.size,n.push([e,t])):n[i][1]=t,this}},function(e,t,n){var o=n(64);e.exports=function(){this.__data__=new o,this.size=0}},function(e,t){e.exports=function(e){var t=this.__data__,n=t.delete(e);return this.size=t.size,n}},function(e,t){e.exports=function(e){return this.__data__.get(e)}},function(e,t){e.exports=function(e){return this.__data__.has(e)}},function(e,t,n){var o=n(64),i=n(94),r=n(96);e.exports=function(e,t){var n=this.__data__;if(n instanceof o){var a=n.__data__;if(!i||a.length<199)return a.push([e,t]),this.size=++n.size,this;n=this.__data__=new r(a)}return n.set(e,t),this.size=n.size,this}},function(e,t,n){var o=n(160),i=n(236),r=n(95),a=n(161),s=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,u=l.toString,d=c.hasOwnProperty,h=RegExp("^"+u.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");e.exports=function(e){return!(!r(e)||i(e))&&(o(e)?h:s).test(a(e))}},function(e,t,n){var o,i=n(237),r=(o=/[^.]+$/.exec(i&&i.keys&&i.keys.IE_PROTO||""))?"Symbol(src)_1."+o:"";e.exports=function(e){return!!r&&r in e}},function(e,t,n){var o=n(19)["__core-js_shared__"];e.exports=o},function(e,t){e.exports=function(e,t){return null==e?void 0:e[t]}},function(e,t,n){var o=n(240),i=n(64),r=n(94);e.exports=function(){this.size=0,this.__data__={hash:new o,map:new(r||i),string:new o}}},function(e,t,n){var o=n(241),i=n(242),r=n(243),a=n(244),s=n(245);function l(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var o=e[t];this.set(o[0],o[1])}}l.prototype.clear=o,l.prototype.delete=i,l.prototype.get=r,l.prototype.has=a,l.prototype.set=s,e.exports=l},function(e,t,n){var o=n(66);e.exports=function(){this.__data__=o?o(null):{},this.size=0}},function(e,t){e.exports=function(e){var t=this.has(e)&&delete this.__data__[e];return this.size-=t?1:0,t}},function(e,t,n){var o=n(66),i=Object.prototype.hasOwnProperty;e.exports=function(e){var t=this.__data__;if(o){var n=t[e];return"__lodash_hash_undefined__"===n?void 0:n}return i.call(t,e)?t[e]:void 0}},function(e,t,n){var o=n(66),i=Object.prototype.hasOwnProperty;e.exports=function(e){var t=this.__data__;return o?void 0!==t[e]:i.call(t,e)}},function(e,t,n){var o=n(66);e.exports=function(e,t){var n=this.__data__;return this.size+=this.has(e)?0:1,n[e]=o&&void 0===t?"__lodash_hash_undefined__":t,this}},function(e,t,n){var o=n(67);e.exports=function(e){var t=o(this,e).delete(e);return this.size-=t?1:0,t}},function(e,t){e.exports=function(e){var t=typeof e;return"string"==t||"number"==t||"symbol"==t||"boolean"==t?"__proto__"!==e:null===e}},function(e,t,n){var o=n(67);e.exports=function(e){return o(this,e).get(e)}},function(e,t,n){var o=n(67);e.exports=function(e){return o(this,e).has(e)}},function(e,t,n){var o=n(67);e.exports=function(e,t){var n=o(this,e),i=n.size;return n.set(e,t),this.size+=n.size==i?0:1,this}},function(e,t,n){var o=n(158),i=n(163),r=n(255),a=n(258),s=n(274),l=n(17),c=n(167),u=n(169),d="[object Object]",h=Object.prototype.hasOwnProperty;e.exports=function(e,t,n,f,p,m){var g=l(e),w=l(t),v=g?"[object Array]":s(e),y=w?"[object Array]":s(t),b=(v="[object Arguments]"==v?d:v)==d,k=(y="[object Arguments]"==y?d:y)==d,x=v==y;if(x&&c(e)){if(!c(t))return!1;g=!0,b=!1}if(x&&!b)return m||(m=new o),g||u(e)?i(e,t,n,f,p,m):r(e,t,v,n,f,p,m);if(!(1&n)){var S=b&&h.call(e,"__wrapped__"),T=k&&h.call(t,"__wrapped__");if(S||T){var C=S?e.value():e,I=T?t.value():t;return m||(m=new o),p(C,I,n,f,m)}}return!!x&&(m||(m=new o),a(e,t,n,f,p,m))}},function(e,t){e.exports=function(e){return this.__data__.set(e,"__lodash_hash_undefined__"),this}},function(e,t){e.exports=function(e){return this.__data__.has(e)}},function(e,t){e.exports=function(e,t){for(var n=-1,o=null==e?0:e.length;++n<o;)if(t(e[n],n,e))return!0;return!1}},function(e,t,n){var o=n(43),i=n(256),r=n(159),a=n(163),s=n(257),l=n(97),c=o?o.prototype:void 0,u=c?c.valueOf:void 0;e.exports=function(e,t,n,o,c,d,h){switch(n){case"[object DataView]":if(e.byteLength!=t.byteLength||e.byteOffset!=t.byteOffset)return!1;e=e.buffer,t=t.buffer;case"[object ArrayBuffer]":return!(e.byteLength!=t.byteLength||!d(new i(e),new i(t)));case"[object Boolean]":case"[object Date]":case"[object Number]":return r(+e,+t);case"[object Error]":return e.name==t.name&&e.message==t.message;case"[object RegExp]":case"[object String]":return e==t+"";case"[object Map]":var f=s;case"[object Set]":var p=1&o;if(f||(f=l),e.size!=t.size&&!p)return!1;var m=h.get(e);if(m)return m==t;o|=2,h.set(e,t);var g=a(f(e),f(t),o,c,d,h);return h.delete(e),g;case"[object Symbol]":if(u)return u.call(e)==u.call(t)}return!1}},function(e,t,n){var o=n(19).Uint8Array;e.exports=o},function(e,t){e.exports=function(e){var t=-1,n=Array(e.size);return e.forEach((function(e,o){n[++t]=[o,e]})),n}},function(e,t,n){var o=n(259),i=Object.prototype.hasOwnProperty;e.exports=function(e,t,n,r,a,s){var l=1&n,c=o(e),u=c.length;if(u!=o(t).length&&!l)return!1;for(var d=u;d--;){var h=c[d];if(!(l?h in t:i.call(t,h)))return!1}var f=s.get(e),p=s.get(t);if(f&&p)return f==t&&p==e;var m=!0;s.set(e,t),s.set(t,e);for(var g=l;++d<u;){var w=e[h=c[d]],v=t[h];if(r)var y=l?r(v,w,h,t,e,s):r(w,v,h,e,t,s);if(!(void 0===y?w===v||a(w,v,n,r,s):y)){m=!1;break}g||(g="constructor"==h)}if(m&&!g){var b=e.constructor,k=t.constructor;b==k||!("constructor"in e)||!("constructor"in t)||"function"==typeof b&&b instanceof b&&"function"==typeof k&&k instanceof k||(m=!1)}return s.delete(e),s.delete(t),m}},function(e,t,n){var o=n(260),i=n(261),r=n(166);e.exports=function(e){return o(e,r,i)}},function(e,t,n){var o=n(156),i=n(17);e.exports=function(e,t,n){var r=t(e);return i(e)?r:o(r,n(e))}},function(e,t,n){var o=n(262),i=n(263),r=Object.prototype.propertyIsEnumerable,a=Object.getOwnPropertySymbols,s=a?function(e){return null==e?[]:(e=Object(e),o(a(e),(function(t){return r.call(e,t)})))}:i;e.exports=s},function(e,t){e.exports=function(e,t){for(var n=-1,o=null==e?0:e.length,i=0,r=[];++n<o;){var a=e[n];t(a,n,e)&&(r[i++]=a)}return r}},function(e,t){e.exports=function(){return[]}},function(e,t,n){var o=n(265),i=n(93),r=n(17),a=n(167),s=n(168),l=n(169),c=Object.prototype.hasOwnProperty;e.exports=function(e,t){var n=r(e),u=!n&&i(e),d=!n&&!u&&a(e),h=!n&&!u&&!d&&l(e),f=n||u||d||h,p=f?o(e.length,String):[],m=p.length;for(var g in e)!t&&!c.call(e,g)||f&&("length"==g||d&&("offset"==g||"parent"==g)||h&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,m))||p.push(g);return p}},function(e,t){e.exports=function(e,t){for(var n=-1,o=Array(e);++n<e;)o[n]=t(n);return o}},function(e,t){e.exports=function(){return!1}},function(e,t,n){var o=n(37),i=n(98),r=n(31),a={};a["[object Float32Array]"]=a["[object Float64Array]"]=a["[object Int8Array]"]=a["[object Int16Array]"]=a["[object Int32Array]"]=a["[object Uint8Array]"]=a["[object Uint8ClampedArray]"]=a["[object Uint16Array]"]=a["[object Uint32Array]"]=!0,a["[object Arguments]"]=a["[object Array]"]=a["[object ArrayBuffer]"]=a["[object Boolean]"]=a["[object DataView]"]=a["[object Date]"]=a["[object Error]"]=a["[object Function]"]=a["[object Map]"]=a["[object Number]"]=a["[object Object]"]=a["[object RegExp]"]=a["[object Set]"]=a["[object String]"]=a["[object WeakMap]"]=!1,e.exports=function(e){return r(e)&&i(e.length)&&!!a[o(e)]}},function(e,t){e.exports=function(e){return function(t){return e(t)}}},function(e,t,n){(function(e){var o=n(157),i=t&&!t.nodeType&&t,r=i&&"object"==typeof e&&e&&!e.nodeType&&e,a=r&&r.exports===i&&o.process,s=function(){try{var e=r&&r.require&&r.require("util").types;return e||a&&a.binding&&a.binding("util")}catch(e){}}();e.exports=s}).call(this,n(121)(e))},function(e,t,n){var o=n(271),i=n(272),r=Object.prototype.hasOwnProperty;e.exports=function(e){if(!o(e))return i(e);var t=[];for(var n in Object(e))r.call(e,n)&&"constructor"!=n&&t.push(n);return t}},function(e,t){var n=Object.prototype;e.exports=function(e){var t=e&&e.constructor;return e===("function"==typeof t&&t.prototype||n)}},function(e,t,n){var o=n(273)(Object.keys,Object);e.exports=o},function(e,t){e.exports=function(e,t){return function(n){return e(t(n))}}},function(e,t,n){var o=n(275),i=n(94),r=n(276),a=n(171),s=n(277),l=n(37),c=n(161),u=c(o),d=c(i),h=c(r),f=c(a),p=c(s),m=l;(o&&"[object DataView]"!=m(new o(new ArrayBuffer(1)))||i&&"[object Map]"!=m(new i)||r&&"[object Promise]"!=m(r.resolve())||a&&"[object Set]"!=m(new a)||s&&"[object WeakMap]"!=m(new s))&&(m=function(e){var t=l(e),n="[object Object]"==t?e.constructor:void 0,o=n?c(n):"";if(o)switch(o){case u:return"[object DataView]";case d:return"[object Map]";case h:return"[object Promise]";case f:return"[object Set]";case p:return"[object WeakMap]"}return t}),e.exports=m},function(e,t,n){var o=n(27)(n(19),"DataView");e.exports=o},function(e,t,n){var o=n(27)(n(19),"Promise");e.exports=o},function(e,t,n){var o=n(27)(n(19),"WeakMap");e.exports=o},function(e,t,n){var o=n(172),i=n(166);e.exports=function(e){for(var t=i(e),n=t.length;n--;){var r=t[n],a=e[r];t[n]=[r,a,o(a)]}return t}},function(e,t,n){var o=n(162),i=n(280),r=n(287),a=n(99),s=n(172),l=n(173),c=n(68);e.exports=function(e,t){return a(e)&&s(t)?l(c(e),t):function(n){var a=i(n,e);return void 0===a&&a===t?r(n,e):o(t,a,3)}}},function(e,t,n){var o=n(174);e.exports=function(e,t,n){var i=null==e?void 0:o(e,t);return void 0===i?n:i}},function(e,t,n){var o=n(282),i=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,r=/\\(\\)?/g,a=o((function(e){var t=[];return 46===e.charCodeAt(0)&&t.push(""),e.replace(i,(function(e,n,o,i){t.push(o?i.replace(r,"$1"):n||e)})),t}));e.exports=a},function(e,t,n){var o=n(283);e.exports=function(e){var t=o(e,(function(e){return 500===n.size&&n.clear(),e})),n=t.cache;return t}},function(e,t,n){var o=n(96);function i(e,t){if("function"!=typeof e||null!=t&&"function"!=typeof t)throw new TypeError("Expected a function");var n=function(){var o=arguments,i=t?t.apply(this,o):o[0],r=n.cache;if(r.has(i))return r.get(i);var a=e.apply(this,o);return n.cache=r.set(i,a)||r,a};return n.cache=new(i.Cache||o),n}i.Cache=o,e.exports=i},function(e,t,n){var o=n(285);e.exports=function(e){return null==e?"":o(e)}},function(e,t,n){var o=n(43),i=n(286),r=n(17),a=n(100),s=o?o.prototype:void 0,l=s?s.toString:void 0;e.exports=function e(t){if("string"==typeof t)return t;if(r(t))return i(t,e)+"";if(a(t))return l?l.call(t):"";var n=t+"";return"0"==n&&1/t==-1/0?"-0":n}},function(e,t){e.exports=function(e,t){for(var n=-1,o=null==e?0:e.length,i=Array(o);++n<o;)i[n]=t(e[n],n,e);return i}},function(e,t,n){var o=n(288),i=n(289);e.exports=function(e,t){return null!=e&&i(e,t,o)}},function(e,t){e.exports=function(e,t){return null!=e&&t in Object(e)}},function(e,t,n){var o=n(175),i=n(93),r=n(17),a=n(168),s=n(98),l=n(68);e.exports=function(e,t,n){for(var c=-1,u=(t=o(t,e)).length,d=!1;++c<u;){var h=l(t[c]);if(!(d=null!=e&&n(e,h)))break;e=e[h]}return d||++c!=u?d:!!(u=null==e?0:e.length)&&s(u)&&a(h,u)&&(r(e)||i(e))}},function(e,t,n){var o=n(291),i=n(292),r=n(99),a=n(68);e.exports=function(e){return r(e)?o(a(e)):i(e)}},function(e,t){e.exports=function(e){return function(t){return null==t?void 0:t[e]}}},function(e,t,n){var o=n(174);e.exports=function(e){return function(t){return o(t,e)}}},function(e,t,n){var o=n(101),i=n(294),r=n(296);e.exports=function(e,t){return r(i(e,t,o),e+"")}},function(e,t,n){var o=n(295),i=Math.max;e.exports=function(e,t,n){return t=i(void 0===t?e.length-1:t,0),function(){for(var r=arguments,a=-1,s=i(r.length-t,0),l=Array(s);++a<s;)l[a]=r[t+a];a=-1;for(var c=Array(t+1);++a<t;)c[a]=r[a];return c[t]=n(l),o(e,this,c)}}},function(e,t){e.exports=function(e,t,n){switch(n.length){case 0:return e.call(t);case 1:return e.call(t,n[0]);case 2:return e.call(t,n[0],n[1]);case 3:return e.call(t,n[0],n[1],n[2])}return e.apply(t,n)}},function(e,t,n){var o=n(297),i=n(300)(o);e.exports=i},function(e,t,n){var o=n(298),i=n(299),r=n(101),a=i?function(e,t){return i(e,"toString",{configurable:!0,enumerable:!1,value:o(t),writable:!0})}:r;e.exports=a},function(e,t){e.exports=function(e){return function(){return e}}},function(e,t,n){var o=n(27),i=function(){try{var e=o(Object,"defineProperty");return e({},"",{}),e}catch(e){}}();e.exports=i},function(e,t){var n=Date.now;e.exports=function(e){var t=0,o=0;return function(){var i=n(),r=16-(i-o);if(o=i,r>0){if(++t>=800)return arguments[0]}else t=0;return e.apply(void 0,arguments)}}},function(e,t,n){var o=n(164),i=n(302),r=n(307),a=n(165),s=n(308),l=n(97);e.exports=function(e,t,n){var c=-1,u=i,d=e.length,h=!0,f=[],p=f;if(n)h=!1,u=r;else if(d>=200){var m=t?null:s(e);if(m)return l(m);h=!1,u=a,p=new o}else p=t?[]:f;e:for(;++c<d;){var g=e[c],w=t?t(g):g;if(g=n||0!==g?g:0,h&&w==w){for(var v=p.length;v--;)if(p[v]===w)continue e;t&&p.push(w),f.push(g)}else u(p,w,n)||(p!==f&&p.push(w),f.push(g))}return f}},function(e,t,n){var o=n(303);e.exports=function(e,t){return!!(null==e?0:e.length)&&o(e,t,0)>-1}},function(e,t,n){var o=n(304),i=n(305),r=n(306);e.exports=function(e,t,n){return t==t?r(e,t,n):o(e,i,n)}},function(e,t){e.exports=function(e,t,n,o){for(var i=e.length,r=n+(o?1:-1);o?r--:++r<i;)if(t(e[r],r,e))return r;return-1}},function(e,t){e.exports=function(e){return e!=e}},function(e,t){e.exports=function(e,t,n){for(var o=n-1,i=e.length;++o<i;)if(e[o]===t)return o;return-1}},function(e,t){e.exports=function(e,t,n){for(var o=-1,i=null==e?0:e.length;++o<i;)if(n(t,e[o]))return!0;return!1}},function(e,t,n){var o=n(171),i=n(309),r=n(97),a=o&&1/r(new o([,-0]))[1]==1/0?function(e){return new o(e)}:i;e.exports=a},function(e,t){e.exports=function(){}},function(e,t,n){var o=n(170),i=n(31);e.exports=function(e){return i(e)&&o(e)}},function(e,t,n){var o=n(0),i=n(5);o({target:"Object",stat:!0,forced:!i,sham:!i},{defineProperties:n(113)})},function(e,t,n){var o=n(0),i=n(1),r=n(13),a=n(22).f,s=n(5),l=i((function(){a(1)}));o({target:"Object",stat:!0,forced:!s||l,sham:!s},{getOwnPropertyDescriptor:function(e,t){return a(r(e),t)}})},function(e,t,n){var o=n(2),i=n(122).trim,r=n(123),a=o.parseInt,s=/^[+-]?0[Xx]/,l=8!==a(r+"08")||22!==a(r+"0x16");e.exports=l?function(e,t){var n=i(String(e));return a(n,t>>>0||(s.test(n)?16:10))}:a},function(e,t,n){"use strict";n(177)},function(e,t,n){},function(e,t,n){},function(e,t,n){},function(e,t,n){"use strict";var o=n(5),i=n(2),r=n(76),a=n(11),s=n(7),l=n(18),c=n(199),u=n(39),d=n(1),h=n(29),f=n(54).f,p=n(22).f,m=n(9).f,g=n(122).trim,w=i.Number,v=w.prototype,y="Number"==l(h(v)),b=function(e){var t,n,o,i,r,a,s,l,c=u(e,!1);if("string"==typeof c&&c.length>2)if(43===(t=(c=g(c)).charCodeAt(0))||45===t){if(88===(n=c.charCodeAt(2))||120===n)return NaN}else if(48===t){switch(c.charCodeAt(1)){case 66:case 98:o=2,i=49;break;case 79:case 111:o=8,i=55;break;default:return+c}for(a=(r=c.slice(2)).length,s=0;s<a;s++)if((l=r.charCodeAt(s))<48||l>i)return NaN;return parseInt(r,o)}return+c};if(r("Number",!w(" 0o1")||!w("0b1")||w("+0x1"))){for(var k,x=function(e){var t=arguments.length<1?0:e,n=this;return n instanceof x&&(y?d((function(){v.valueOf.call(n)})):"Number"!=l(n))?c(new w(b(t)),n,x):b(t)},S=o?f(w):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),T=0;S.length>T;T++)s(w,k=S[T])&&!s(x,k)&&m(x,k,p(w,k));x.prototype=v,v.constructor=x,a(i,"Number",x)}},function(e,t,n){"use strict";n(178)},function(e,t,n){},function(e,t,n){"use strict";n(179)},function(e,t,n){"use strict";n(180)},function(e,t,n){"use strict";var o=n(26),i=n(4),r=[].slice,a={},s=function(e,t,n){if(!(t in a)){for(var o=[],i=0;i<t;i++)o[i]="a["+i+"]";a[t]=Function("C,a","return new C("+o.join(",")+")")}return a[t](e,n)};e.exports=Function.bind||function(e){var t=o(this),n=r.call(arguments,1),a=function(){var o=n.concat(r.call(arguments));return this instanceof a?s(t,o.length,o):t.apply(e,o)};return i(t.prototype)&&(a.prototype=t.prototype),a}},function(e,t,n){"use strict";n(183)},function(e,t,n){"use strict";n(184)},function(e,t,n){"use strict";n.r(t);n(112),n(203),n(208),n(209),n(24),n(72),n(50),n(10),n(28),n(33),n(106);var o=n(61),i=Object.freeze({});function r(e){return null==e}function a(e){return null!=e}function s(e){return!0===e}function l(e){return"string"==typeof e||"number"==typeof e||"symbol"==typeof e||"boolean"==typeof e}function c(e){return null!==e&&"object"==typeof e}var u=Object.prototype.toString;function d(e){return"[object Object]"===u.call(e)}function h(e){return"[object RegExp]"===u.call(e)}function f(e){var t=parseFloat(String(e));return t>=0&&Math.floor(t)===t&&isFinite(e)}function p(e){return a(e)&&"function"==typeof e.then&&"function"==typeof e.catch}function m(e){return null==e?"":Array.isArray(e)||d(e)&&e.toString===u?JSON.stringify(e,null,2):String(e)}function g(e){var t=parseFloat(e);return isNaN(t)?e:t}function w(e,t){for(var n=Object.create(null),o=e.split(","),i=0;i<o.length;i++)n[o[i]]=!0;return t?function(e){return n[e.toLowerCase()]}:function(e){return n[e]}}w("slot,component",!0);var v=w("key,ref,slot,slot-scope,is");function y(e,t){if(e.length){var n=e.indexOf(t);if(n>-1)return e.splice(n,1)}}var b=Object.prototype.hasOwnProperty;function k(e,t){return b.call(e,t)}function x(e){var t=Object.create(null);return function(n){return t[n]||(t[n]=e(n))}}var S=/-(\w)/g,T=x((function(e){return e.replace(S,(function(e,t){return t?t.toUpperCase():""}))})),C=x((function(e){return e.charAt(0).toUpperCase()+e.slice(1)})),I=/\B([A-Z])/g,_=x((function(e){return e.replace(I,"-$1").toLowerCase()}));var A=Function.prototype.bind?function(e,t){return e.bind(t)}:function(e,t){function n(n){var o=arguments.length;return o?o>1?e.apply(t,arguments):e.call(t,n):e.call(t)}return n._length=e.length,n};function E(e,t){t=t||0;for(var n=e.length-t,o=new Array(n);n--;)o[n]=e[n+t];return o}function O(e,t){for(var n in t)e[n]=t[n];return e}function j(e){for(var t={},n=0;n<e.length;n++)e[n]&&O(t,e[n]);return t}function P(e,t,n){}var W=function(e,t,n){return!1},q=function(e){return e};function D(e,t){if(e===t)return!0;var n=c(e),o=c(t);if(!n||!o)return!n&&!o&&String(e)===String(t);try{var i=Array.isArray(e),r=Array.isArray(t);if(i&&r)return e.length===t.length&&e.every((function(e,n){return D(e,t[n])}));if(e instanceof Date&&t instanceof Date)return e.getTime()===t.getTime();if(i||r)return!1;var a=Object.keys(e),s=Object.keys(t);return a.length===s.length&&a.every((function(n){return D(e[n],t[n])}))}catch(e){return!1}}function N(e,t){for(var n=0;n<e.length;n++)if(D(e[n],t))return n;return-1}function R(e){var t=!1;return function(){t||(t=!0,e.apply(this,arguments))}}var L=["component","directive","filter"],F=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch"],z={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:W,isReservedAttr:W,isUnknownElement:W,getTagNamespace:P,parsePlatformTagName:q,mustUseProp:W,async:!0,_lifecycleHooks:F},H=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function $(e,t,n,o){Object.defineProperty(e,t,{value:n,enumerable:!!o,writable:!0,configurable:!0})}var M=new RegExp("[^"+H.source+".$_\\d]");var G,U="__proto__"in{},B="undefined"!=typeof window,V="undefined"!=typeof WXEnvironment&&!!WXEnvironment.platform,Y=V&&WXEnvironment.platform.toLowerCase(),K=B&&window.navigator.userAgent.toLowerCase(),Q=K&&/msie|trident/.test(K),J=K&&K.indexOf("msie 9.0")>0,X=K&&K.indexOf("edge/")>0,Z=(K&&K.indexOf("android"),K&&/iphone|ipad|ipod|ios/.test(K)||"ios"===Y),ee=(K&&/chrome\/\d+/.test(K),K&&/phantomjs/.test(K),K&&K.match(/firefox\/(\d+)/)),te={}.watch,ne=!1;if(B)try{var oe={};Object.defineProperty(oe,"passive",{get:function(){ne=!0}}),window.addEventListener("test-passive",null,oe)}catch(e){}var ie=function(){return void 0===G&&(G=!B&&!V&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),G},re=B&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function ae(e){return"function"==typeof e&&/native code/.test(e.toString())}var se,le="undefined"!=typeof Symbol&&ae(Symbol)&&"undefined"!=typeof Reflect&&ae(Reflect.ownKeys);se="undefined"!=typeof Set&&ae(Set)?Set:function(){function e(){this.set=Object.create(null)}return e.prototype.has=function(e){return!0===this.set[e]},e.prototype.add=function(e){this.set[e]=!0},e.prototype.clear=function(){this.set=Object.create(null)},e}();var ce=P,ue=0,de=function(){this.id=ue++,this.subs=[]};de.prototype.addSub=function(e){this.subs.push(e)},de.prototype.removeSub=function(e){y(this.subs,e)},de.prototype.depend=function(){de.target&&de.target.addDep(this)},de.prototype.notify=function(){var e=this.subs.slice();for(var t=0,n=e.length;t<n;t++)e[t].update()},de.target=null;var he=[];function fe(e){he.push(e),de.target=e}function pe(){he.pop(),de.target=he[he.length-1]}var me=function(e,t,n,o,i,r,a,s){this.tag=e,this.data=t,this.children=n,this.text=o,this.elm=i,this.ns=void 0,this.context=r,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=t&&t.key,this.componentOptions=a,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1},ge={child:{configurable:!0}};ge.child.get=function(){return this.componentInstance},Object.defineProperties(me.prototype,ge);var we=function(e){void 0===e&&(e="");var t=new me;return t.text=e,t.isComment=!0,t};function ve(e){return new me(void 0,void 0,void 0,String(e))}function ye(e){var t=new me(e.tag,e.data,e.children&&e.children.slice(),e.text,e.elm,e.context,e.componentOptions,e.asyncFactory);return t.ns=e.ns,t.isStatic=e.isStatic,t.key=e.key,t.isComment=e.isComment,t.fnContext=e.fnContext,t.fnOptions=e.fnOptions,t.fnScopeId=e.fnScopeId,t.asyncMeta=e.asyncMeta,t.isCloned=!0,t}var be=Array.prototype,ke=Object.create(be);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(e){var t=be[e];$(ke,e,(function(){for(var n=[],o=arguments.length;o--;)n[o]=arguments[o];var i,r=t.apply(this,n),a=this.__ob__;switch(e){case"push":case"unshift":i=n;break;case"splice":i=n.slice(2)}return i&&a.observeArray(i),a.dep.notify(),r}))}));var xe=Object.getOwnPropertyNames(ke),Se=!0;function Te(e){Se=e}var Ce=function(e){this.value=e,this.dep=new de,this.vmCount=0,$(e,"__ob__",this),Array.isArray(e)?(U?function(e,t){e.__proto__=t}(e,ke):function(e,t,n){for(var o=0,i=n.length;o<i;o++){var r=n[o];$(e,r,t[r])}}(e,ke,xe),this.observeArray(e)):this.walk(e)};function Ie(e,t){var n;if(c(e)&&!(e instanceof me))return k(e,"__ob__")&&e.__ob__ instanceof Ce?n=e.__ob__:Se&&!ie()&&(Array.isArray(e)||d(e))&&Object.isExtensible(e)&&!e._isVue&&(n=new Ce(e)),t&&n&&n.vmCount++,n}function _e(e,t,n,o,i){var r=new de,a=Object.getOwnPropertyDescriptor(e,t);if(!a||!1!==a.configurable){var s=a&&a.get,l=a&&a.set;s&&!l||2!==arguments.length||(n=e[t]);var c=!i&&Ie(n);Object.defineProperty(e,t,{enumerable:!0,configurable:!0,get:function(){var t=s?s.call(e):n;return de.target&&(r.depend(),c&&(c.dep.depend(),Array.isArray(t)&&Oe(t))),t},set:function(t){var o=s?s.call(e):n;t===o||t!=t&&o!=o||s&&!l||(l?l.call(e,t):n=t,c=!i&&Ie(t),r.notify())}})}}function Ae(e,t,n){if(Array.isArray(e)&&f(t))return e.length=Math.max(e.length,t),e.splice(t,1,n),n;if(t in e&&!(t in Object.prototype))return e[t]=n,n;var o=e.__ob__;return e._isVue||o&&o.vmCount?n:o?(_e(o.value,t,n),o.dep.notify(),n):(e[t]=n,n)}function Ee(e,t){if(Array.isArray(e)&&f(t))e.splice(t,1);else{var n=e.__ob__;e._isVue||n&&n.vmCount||k(e,t)&&(delete e[t],n&&n.dep.notify())}}function Oe(e){for(var t=void 0,n=0,o=e.length;n<o;n++)(t=e[n])&&t.__ob__&&t.__ob__.dep.depend(),Array.isArray(t)&&Oe(t)}Ce.prototype.walk=function(e){for(var t=Object.keys(e),n=0;n<t.length;n++)_e(e,t[n])},Ce.prototype.observeArray=function(e){for(var t=0,n=e.length;t<n;t++)Ie(e[t])};var je=z.optionMergeStrategies;function Pe(e,t){if(!t)return e;for(var n,o,i,r=le?Reflect.ownKeys(t):Object.keys(t),a=0;a<r.length;a++)"__ob__"!==(n=r[a])&&(o=e[n],i=t[n],k(e,n)?o!==i&&d(o)&&d(i)&&Pe(o,i):Ae(e,n,i));return e}function We(e,t,n){return n?function(){var o="function"==typeof t?t.call(n,n):t,i="function"==typeof e?e.call(n,n):e;return o?Pe(o,i):i}:t?e?function(){return Pe("function"==typeof t?t.call(this,this):t,"function"==typeof e?e.call(this,this):e)}:t:e}function qe(e,t){var n=t?e?e.concat(t):Array.isArray(t)?t:[t]:e;return n?function(e){for(var t=[],n=0;n<e.length;n++)-1===t.indexOf(e[n])&&t.push(e[n]);return t}(n):n}function De(e,t,n,o){var i=Object.create(e||null);return t?O(i,t):i}je.data=function(e,t,n){return n?We(e,t,n):t&&"function"!=typeof t?e:We(e,t)},F.forEach((function(e){je[e]=qe})),L.forEach((function(e){je[e+"s"]=De})),je.watch=function(e,t,n,o){if(e===te&&(e=void 0),t===te&&(t=void 0),!t)return Object.create(e||null);if(!e)return t;var i={};for(var r in O(i,e),t){var a=i[r],s=t[r];a&&!Array.isArray(a)&&(a=[a]),i[r]=a?a.concat(s):Array.isArray(s)?s:[s]}return i},je.props=je.methods=je.inject=je.computed=function(e,t,n,o){if(!e)return t;var i=Object.create(null);return O(i,e),t&&O(i,t),i},je.provide=We;var Ne=function(e,t){return void 0===t?e:t};function Re(e,t,n){if("function"==typeof t&&(t=t.options),function(e,t){var n=e.props;if(n){var o,i,r={};if(Array.isArray(n))for(o=n.length;o--;)"string"==typeof(i=n[o])&&(r[T(i)]={type:null});else if(d(n))for(var a in n)i=n[a],r[T(a)]=d(i)?i:{type:i};else 0;e.props=r}}(t),function(e,t){var n=e.inject;if(n){var o=e.inject={};if(Array.isArray(n))for(var i=0;i<n.length;i++)o[n[i]]={from:n[i]};else if(d(n))for(var r in n){var a=n[r];o[r]=d(a)?O({from:r},a):{from:a}}else 0}}(t),function(e){var t=e.directives;if(t)for(var n in t){var o=t[n];"function"==typeof o&&(t[n]={bind:o,update:o})}}(t),!t._base&&(t.extends&&(e=Re(e,t.extends,n)),t.mixins))for(var o=0,i=t.mixins.length;o<i;o++)e=Re(e,t.mixins[o],n);var r,a={};for(r in e)s(r);for(r in t)k(e,r)||s(r);function s(o){var i=je[o]||Ne;a[o]=i(e[o],t[o],n,o)}return a}function Le(e,t,n,o){if("string"==typeof n){var i=e[t];if(k(i,n))return i[n];var r=T(n);if(k(i,r))return i[r];var a=C(r);return k(i,a)?i[a]:i[n]||i[r]||i[a]}}function Fe(e,t,n,o){var i=t[e],r=!k(n,e),a=n[e],s=$e(Boolean,i.type);if(s>-1)if(r&&!k(i,"default"))a=!1;else if(""===a||a===_(e)){var l=$e(String,i.type);(l<0||s<l)&&(a=!0)}if(void 0===a){a=function(e,t,n){if(!k(t,"default"))return;var o=t.default;0;if(e&&e.$options.propsData&&void 0===e.$options.propsData[n]&&void 0!==e._props[n])return e._props[n];return"function"==typeof o&&"Function"!==ze(t.type)?o.call(e):o}(o,i,e);var c=Se;Te(!0),Ie(a),Te(c)}return a}function ze(e){var t=e&&e.toString().match(/^\s*function (\w+)/);return t?t[1]:""}function He(e,t){return ze(e)===ze(t)}function $e(e,t){if(!Array.isArray(t))return He(t,e)?0:-1;for(var n=0,o=t.length;n<o;n++)if(He(t[n],e))return n;return-1}function Me(e,t,n){fe();try{if(t)for(var o=t;o=o.$parent;){var i=o.$options.errorCaptured;if(i)for(var r=0;r<i.length;r++)try{if(!1===i[r].call(o,e,t,n))return}catch(e){Ue(e,o,"errorCaptured hook")}}Ue(e,t,n)}finally{pe()}}function Ge(e,t,n,o,i){var r;try{(r=n?e.apply(t,n):e.call(t))&&!r._isVue&&p(r)&&!r._handled&&(r.catch((function(e){return Me(e,o,i+" (Promise/async)")})),r._handled=!0)}catch(e){Me(e,o,i)}return r}function Ue(e,t,n){if(z.errorHandler)try{return z.errorHandler.call(null,e,t,n)}catch(t){t!==e&&Be(t,null,"config.errorHandler")}Be(e,t,n)}function Be(e,t,n){if(!B&&!V||"undefined"==typeof console)throw e;console.error(e)}var Ve,Ye=!1,Ke=[],Qe=!1;function Je(){Qe=!1;var e=Ke.slice(0);Ke.length=0;for(var t=0;t<e.length;t++)e[t]()}if("undefined"!=typeof Promise&&ae(Promise)){var Xe=Promise.resolve();Ve=function(){Xe.then(Je),Z&&setTimeout(P)},Ye=!0}else if(Q||"undefined"==typeof MutationObserver||!ae(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Ve="undefined"!=typeof setImmediate&&ae(setImmediate)?function(){setImmediate(Je)}:function(){setTimeout(Je,0)};else{var Ze=1,et=new MutationObserver(Je),tt=document.createTextNode(String(Ze));et.observe(tt,{characterData:!0}),Ve=function(){Ze=(Ze+1)%2,tt.data=String(Ze)},Ye=!0}function nt(e,t){var n;if(Ke.push((function(){if(e)try{e.call(t)}catch(e){Me(e,t,"nextTick")}else n&&n(t)})),Qe||(Qe=!0,Ve()),!e&&"undefined"!=typeof Promise)return new Promise((function(e){n=e}))}var ot=new se;function it(e){!function e(t,n){var o,i,r=Array.isArray(t);if(!r&&!c(t)||Object.isFrozen(t)||t instanceof me)return;if(t.__ob__){var a=t.__ob__.dep.id;if(n.has(a))return;n.add(a)}if(r)for(o=t.length;o--;)e(t[o],n);else for(i=Object.keys(t),o=i.length;o--;)e(t[i[o]],n)}(e,ot),ot.clear()}var rt=x((function(e){var t="&"===e.charAt(0),n="~"===(e=t?e.slice(1):e).charAt(0),o="!"===(e=n?e.slice(1):e).charAt(0);return{name:e=o?e.slice(1):e,once:n,capture:o,passive:t}}));function at(e,t){function n(){var e=arguments,o=n.fns;if(!Array.isArray(o))return Ge(o,null,arguments,t,"v-on handler");for(var i=o.slice(),r=0;r<i.length;r++)Ge(i[r],null,e,t,"v-on handler")}return n.fns=e,n}function st(e,t,n,o,i,a){var l,c,u,d;for(l in e)c=e[l],u=t[l],d=rt(l),r(c)||(r(u)?(r(c.fns)&&(c=e[l]=at(c,a)),s(d.once)&&(c=e[l]=i(d.name,c,d.capture)),n(d.name,c,d.capture,d.passive,d.params)):c!==u&&(u.fns=c,e[l]=u));for(l in t)r(e[l])&&o((d=rt(l)).name,t[l],d.capture)}function lt(e,t,n){var o;e instanceof me&&(e=e.data.hook||(e.data.hook={}));var i=e[t];function l(){n.apply(this,arguments),y(o.fns,l)}r(i)?o=at([l]):a(i.fns)&&s(i.merged)?(o=i).fns.push(l):o=at([i,l]),o.merged=!0,e[t]=o}function ct(e,t,n,o,i){if(a(t)){if(k(t,n))return e[n]=t[n],i||delete t[n],!0;if(k(t,o))return e[n]=t[o],i||delete t[o],!0}return!1}function ut(e){return l(e)?[ve(e)]:Array.isArray(e)?function e(t,n){var o,i,c,u,d=[];for(o=0;o<t.length;o++)r(i=t[o])||"boolean"==typeof i||(c=d.length-1,u=d[c],Array.isArray(i)?i.length>0&&(dt((i=e(i,(n||"")+"_"+o))[0])&&dt(u)&&(d[c]=ve(u.text+i[0].text),i.shift()),d.push.apply(d,i)):l(i)?dt(u)?d[c]=ve(u.text+i):""!==i&&d.push(ve(i)):dt(i)&&dt(u)?d[c]=ve(u.text+i.text):(s(t._isVList)&&a(i.tag)&&r(i.key)&&a(n)&&(i.key="__vlist"+n+"_"+o+"__"),d.push(i)));return d}(e):void 0}function dt(e){return a(e)&&a(e.text)&&!1===e.isComment}function ht(e,t){if(e){for(var n=Object.create(null),o=le?Reflect.ownKeys(e):Object.keys(e),i=0;i<o.length;i++){var r=o[i];if("__ob__"!==r){for(var a=e[r].from,s=t;s;){if(s._provided&&k(s._provided,a)){n[r]=s._provided[a];break}s=s.$parent}if(!s)if("default"in e[r]){var l=e[r].default;n[r]="function"==typeof l?l.call(t):l}else 0}}return n}}function ft(e,t){if(!e||!e.length)return{};for(var n={},o=0,i=e.length;o<i;o++){var r=e[o],a=r.data;if(a&&a.attrs&&a.attrs.slot&&delete a.attrs.slot,r.context!==t&&r.fnContext!==t||!a||null==a.slot)(n.default||(n.default=[])).push(r);else{var s=a.slot,l=n[s]||(n[s]=[]);"template"===r.tag?l.push.apply(l,r.children||[]):l.push(r)}}for(var c in n)n[c].every(pt)&&delete n[c];return n}function pt(e){return e.isComment&&!e.asyncFactory||" "===e.text}function mt(e,t,n){var o,r=Object.keys(t).length>0,a=e?!!e.$stable:!r,s=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(a&&n&&n!==i&&s===n.$key&&!r&&!n.$hasNormal)return n;for(var l in o={},e)e[l]&&"$"!==l[0]&&(o[l]=gt(t,l,e[l]))}else o={};for(var c in t)c in o||(o[c]=wt(t,c));return e&&Object.isExtensible(e)&&(e._normalized=o),$(o,"$stable",a),$(o,"$key",s),$(o,"$hasNormal",r),o}function gt(e,t,n){var o=function(){var e=arguments.length?n.apply(null,arguments):n({});return(e=e&&"object"==typeof e&&!Array.isArray(e)?[e]:ut(e))&&(0===e.length||1===e.length&&e[0].isComment)?void 0:e};return n.proxy&&Object.defineProperty(e,t,{get:o,enumerable:!0,configurable:!0}),o}function wt(e,t){return function(){return e[t]}}function vt(e,t){var n,o,i,r,s;if(Array.isArray(e)||"string"==typeof e)for(n=new Array(e.length),o=0,i=e.length;o<i;o++)n[o]=t(e[o],o);else if("number"==typeof e)for(n=new Array(e),o=0;o<e;o++)n[o]=t(o+1,o);else if(c(e))if(le&&e[Symbol.iterator]){n=[];for(var l=e[Symbol.iterator](),u=l.next();!u.done;)n.push(t(u.value,n.length)),u=l.next()}else for(r=Object.keys(e),n=new Array(r.length),o=0,i=r.length;o<i;o++)s=r[o],n[o]=t(e[s],s,o);return a(n)||(n=[]),n._isVList=!0,n}function yt(e,t,n,o){var i,r=this.$scopedSlots[e];r?(n=n||{},o&&(n=O(O({},o),n)),i=r(n)||t):i=this.$slots[e]||t;var a=n&&n.slot;return a?this.$createElement("template",{slot:a},i):i}function bt(e){return Le(this.$options,"filters",e)||q}function kt(e,t){return Array.isArray(e)?-1===e.indexOf(t):e!==t}function xt(e,t,n,o,i){var r=z.keyCodes[t]||n;return i&&o&&!z.keyCodes[t]?kt(i,o):r?kt(r,e):o?_(o)!==t:void 0}function St(e,t,n,o,i){if(n)if(c(n)){var r;Array.isArray(n)&&(n=j(n));var a=function(a){if("class"===a||"style"===a||v(a))r=e;else{var s=e.attrs&&e.attrs.type;r=o||z.mustUseProp(t,s,a)?e.domProps||(e.domProps={}):e.attrs||(e.attrs={})}var l=T(a),c=_(a);l in r||c in r||(r[a]=n[a],i&&((e.on||(e.on={}))["update:"+a]=function(e){n[a]=e}))};for(var s in n)a(s)}else;return e}function Tt(e,t){var n=this._staticTrees||(this._staticTrees=[]),o=n[e];return o&&!t||It(o=n[e]=this.$options.staticRenderFns[e].call(this._renderProxy,null,this),"__static__"+e,!1),o}function Ct(e,t,n){return It(e,"__once__"+t+(n?"_"+n:""),!0),e}function It(e,t,n){if(Array.isArray(e))for(var o=0;o<e.length;o++)e[o]&&"string"!=typeof e[o]&&_t(e[o],t+"_"+o,n);else _t(e,t,n)}function _t(e,t,n){e.isStatic=!0,e.key=t,e.isOnce=n}function At(e,t){if(t)if(d(t)){var n=e.on=e.on?O({},e.on):{};for(var o in t){var i=n[o],r=t[o];n[o]=i?[].concat(i,r):r}}else;return e}function Et(e,t,n,o){t=t||{$stable:!n};for(var i=0;i<e.length;i++){var r=e[i];Array.isArray(r)?Et(r,t,n):r&&(r.proxy&&(r.fn.proxy=!0),t[r.key]=r.fn)}return o&&(t.$key=o),t}function Ot(e,t){for(var n=0;n<t.length;n+=2){var o=t[n];"string"==typeof o&&o&&(e[t[n]]=t[n+1])}return e}function jt(e,t){return"string"==typeof e?t+e:e}function Pt(e){e._o=Ct,e._n=g,e._s=m,e._l=vt,e._t=yt,e._q=D,e._i=N,e._m=Tt,e._f=bt,e._k=xt,e._b=St,e._v=ve,e._e=we,e._u=Et,e._g=At,e._d=Ot,e._p=jt}function Wt(e,t,n,o,r){var a,l=this,c=r.options;k(o,"_uid")?(a=Object.create(o))._original=o:(a=o,o=o._original);var u=s(c._compiled),d=!u;this.data=e,this.props=t,this.children=n,this.parent=o,this.listeners=e.on||i,this.injections=ht(c.inject,o),this.slots=function(){return l.$slots||mt(e.scopedSlots,l.$slots=ft(n,o)),l.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return mt(e.scopedSlots,this.slots())}}),u&&(this.$options=c,this.$slots=this.slots(),this.$scopedSlots=mt(e.scopedSlots,this.$slots)),c._scopeId?this._c=function(e,t,n,i){var r=zt(a,e,t,n,i,d);return r&&!Array.isArray(r)&&(r.fnScopeId=c._scopeId,r.fnContext=o),r}:this._c=function(e,t,n,o){return zt(a,e,t,n,o,d)}}function qt(e,t,n,o,i){var r=ye(e);return r.fnContext=n,r.fnOptions=o,t.slot&&((r.data||(r.data={})).slot=t.slot),r}function Dt(e,t){for(var n in t)e[T(n)]=t[n]}Pt(Wt.prototype);var Nt={init:function(e,t){if(e.componentInstance&&!e.componentInstance._isDestroyed&&e.data.keepAlive){var n=e;Nt.prepatch(n,n)}else{(e.componentInstance=function(e,t){var n={_isComponent:!0,_parentVnode:e,parent:t},o=e.data.inlineTemplate;a(o)&&(n.render=o.render,n.staticRenderFns=o.staticRenderFns);return new e.componentOptions.Ctor(n)}(e,Qt)).$mount(t?e.elm:void 0,t)}},prepatch:function(e,t){var n=t.componentOptions;!function(e,t,n,o,r){0;var a=o.data.scopedSlots,s=e.$scopedSlots,l=!!(a&&!a.$stable||s!==i&&!s.$stable||a&&e.$scopedSlots.$key!==a.$key),c=!!(r||e.$options._renderChildren||l);e.$options._parentVnode=o,e.$vnode=o,e._vnode&&(e._vnode.parent=o);if(e.$options._renderChildren=r,e.$attrs=o.data.attrs||i,e.$listeners=n||i,t&&e.$options.props){Te(!1);for(var u=e._props,d=e.$options._propKeys||[],h=0;h<d.length;h++){var f=d[h],p=e.$options.props;u[f]=Fe(f,p,t,e)}Te(!0),e.$options.propsData=t}n=n||i;var m=e.$options._parentListeners;e.$options._parentListeners=n,Kt(e,n,m),c&&(e.$slots=ft(r,o.context),e.$forceUpdate());0}(t.componentInstance=e.componentInstance,n.propsData,n.listeners,t,n.children)},insert:function(e){var t,n=e.context,o=e.componentInstance;o._isMounted||(o._isMounted=!0,en(o,"mounted")),e.data.keepAlive&&(n._isMounted?((t=o)._inactive=!1,nn.push(t)):Zt(o,!0))},destroy:function(e){var t=e.componentInstance;t._isDestroyed||(e.data.keepAlive?function e(t,n){if(n&&(t._directInactive=!0,Xt(t)))return;if(!t._inactive){t._inactive=!0;for(var o=0;o<t.$children.length;o++)e(t.$children[o]);en(t,"deactivated")}}(t,!0):t.$destroy())}},Rt=Object.keys(Nt);function Lt(e,t,n,o,l){if(!r(e)){var u=n.$options._base;if(c(e)&&(e=u.extend(e)),"function"==typeof e){var d;if(r(e.cid)&&void 0===(e=function(e,t){if(s(e.error)&&a(e.errorComp))return e.errorComp;if(a(e.resolved))return e.resolved;var n=$t;n&&a(e.owners)&&-1===e.owners.indexOf(n)&&e.owners.push(n);if(s(e.loading)&&a(e.loadingComp))return e.loadingComp;if(n&&!a(e.owners)){var o=e.owners=[n],i=!0,l=null,u=null;n.$on("hook:destroyed",(function(){return y(o,n)}));var d=function(e){for(var t=0,n=o.length;t<n;t++)o[t].$forceUpdate();e&&(o.length=0,null!==l&&(clearTimeout(l),l=null),null!==u&&(clearTimeout(u),u=null))},h=R((function(n){e.resolved=Mt(n,t),i?o.length=0:d(!0)})),f=R((function(t){a(e.errorComp)&&(e.error=!0,d(!0))})),m=e(h,f);return c(m)&&(p(m)?r(e.resolved)&&m.then(h,f):p(m.component)&&(m.component.then(h,f),a(m.error)&&(e.errorComp=Mt(m.error,t)),a(m.loading)&&(e.loadingComp=Mt(m.loading,t),0===m.delay?e.loading=!0:l=setTimeout((function(){l=null,r(e.resolved)&&r(e.error)&&(e.loading=!0,d(!1))}),m.delay||200)),a(m.timeout)&&(u=setTimeout((function(){u=null,r(e.resolved)&&f(null)}),m.timeout)))),i=!1,e.loading?e.loadingComp:e.resolved}}(d=e,u)))return function(e,t,n,o,i){var r=we();return r.asyncFactory=e,r.asyncMeta={data:t,context:n,children:o,tag:i},r}(d,t,n,o,l);t=t||{},Sn(e),a(t.model)&&function(e,t){var n=e.model&&e.model.prop||"value",o=e.model&&e.model.event||"input";(t.attrs||(t.attrs={}))[n]=t.model.value;var i=t.on||(t.on={}),r=i[o],s=t.model.callback;a(r)?(Array.isArray(r)?-1===r.indexOf(s):r!==s)&&(i[o]=[s].concat(r)):i[o]=s}(e.options,t);var h=function(e,t,n){var o=t.options.props;if(!r(o)){var i={},s=e.attrs,l=e.props;if(a(s)||a(l))for(var c in o){var u=_(c);ct(i,l,c,u,!0)||ct(i,s,c,u,!1)}return i}}(t,e);if(s(e.options.functional))return function(e,t,n,o,r){var s=e.options,l={},c=s.props;if(a(c))for(var u in c)l[u]=Fe(u,c,t||i);else a(n.attrs)&&Dt(l,n.attrs),a(n.props)&&Dt(l,n.props);var d=new Wt(n,l,r,o,e),h=s.render.call(null,d._c,d);if(h instanceof me)return qt(h,n,d.parent,s,d);if(Array.isArray(h)){for(var f=ut(h)||[],p=new Array(f.length),m=0;m<f.length;m++)p[m]=qt(f[m],n,d.parent,s,d);return p}}(e,h,t,n,o);var f=t.on;if(t.on=t.nativeOn,s(e.options.abstract)){var m=t.slot;t={},m&&(t.slot=m)}!function(e){for(var t=e.hook||(e.hook={}),n=0;n<Rt.length;n++){var o=Rt[n],i=t[o],r=Nt[o];i===r||i&&i._merged||(t[o]=i?Ft(r,i):r)}}(t);var g=e.options.name||l;return new me("vue-component-"+e.cid+(g?"-"+g:""),t,void 0,void 0,void 0,n,{Ctor:e,propsData:h,listeners:f,tag:l,children:o},d)}}}function Ft(e,t){var n=function(n,o){e(n,o),t(n,o)};return n._merged=!0,n}function zt(e,t,n,o,i,u){return(Array.isArray(n)||l(n))&&(i=o,o=n,n=void 0),s(u)&&(i=2),function(e,t,n,o,i){if(a(n)&&a(n.__ob__))return we();a(n)&&a(n.is)&&(t=n.is);if(!t)return we();0;Array.isArray(o)&&"function"==typeof o[0]&&((n=n||{}).scopedSlots={default:o[0]},o.length=0);2===i?o=ut(o):1===i&&(o=function(e){for(var t=0;t<e.length;t++)if(Array.isArray(e[t]))return Array.prototype.concat.apply([],e);return e}(o));var l,u;if("string"==typeof t){var d;u=e.$vnode&&e.$vnode.ns||z.getTagNamespace(t),l=z.isReservedTag(t)?new me(z.parsePlatformTagName(t),n,o,void 0,void 0,e):n&&n.pre||!a(d=Le(e.$options,"components",t))?new me(t,n,o,void 0,void 0,e):Lt(d,n,e,o,t)}else l=Lt(t,n,e,o);return Array.isArray(l)?l:a(l)?(a(u)&&function e(t,n,o){t.ns=n,"foreignObject"===t.tag&&(n=void 0,o=!0);if(a(t.children))for(var i=0,l=t.children.length;i<l;i++){var c=t.children[i];a(c.tag)&&(r(c.ns)||s(o)&&"svg"!==c.tag)&&e(c,n,o)}}(l,u),a(n)&&function(e){c(e.style)&&it(e.style);c(e.class)&&it(e.class)}(n),l):we()}(e,t,n,o,i)}var Ht,$t=null;function Mt(e,t){return(e.__esModule||le&&"Module"===e[Symbol.toStringTag])&&(e=e.default),c(e)?t.extend(e):e}function Gt(e){return e.isComment&&e.asyncFactory}function Ut(e){if(Array.isArray(e))for(var t=0;t<e.length;t++){var n=e[t];if(a(n)&&(a(n.componentOptions)||Gt(n)))return n}}function Bt(e,t){Ht.$on(e,t)}function Vt(e,t){Ht.$off(e,t)}function Yt(e,t){var n=Ht;return function o(){var i=t.apply(null,arguments);null!==i&&n.$off(e,o)}}function Kt(e,t,n){Ht=e,st(t,n||{},Bt,Vt,Yt,e),Ht=void 0}var Qt=null;function Jt(e){var t=Qt;return Qt=e,function(){Qt=t}}function Xt(e){for(;e&&(e=e.$parent);)if(e._inactive)return!0;return!1}function Zt(e,t){if(t){if(e._directInactive=!1,Xt(e))return}else if(e._directInactive)return;if(e._inactive||null===e._inactive){e._inactive=!1;for(var n=0;n<e.$children.length;n++)Zt(e.$children[n]);en(e,"activated")}}function en(e,t){fe();var n=e.$options[t],o=t+" hook";if(n)for(var i=0,r=n.length;i<r;i++)Ge(n[i],e,null,e,o);e._hasHookEvent&&e.$emit("hook:"+t),pe()}var tn=[],nn=[],on={},rn=!1,an=!1,sn=0;var ln=0,cn=Date.now;if(B&&!Q){var un=window.performance;un&&"function"==typeof un.now&&cn()>document.createEvent("Event").timeStamp&&(cn=function(){return un.now()})}function dn(){var e,t;for(ln=cn(),an=!0,tn.sort((function(e,t){return e.id-t.id})),sn=0;sn<tn.length;sn++)(e=tn[sn]).before&&e.before(),t=e.id,on[t]=null,e.run();var n=nn.slice(),o=tn.slice();sn=tn.length=nn.length=0,on={},rn=an=!1,function(e){for(var t=0;t<e.length;t++)e[t]._inactive=!0,Zt(e[t],!0)}(n),function(e){var t=e.length;for(;t--;){var n=e[t],o=n.vm;o._watcher===n&&o._isMounted&&!o._isDestroyed&&en(o,"updated")}}(o),re&&z.devtools&&re.emit("flush")}var hn=0,fn=function(e,t,n,o,i){this.vm=e,i&&(e._watcher=this),e._watchers.push(this),o?(this.deep=!!o.deep,this.user=!!o.user,this.lazy=!!o.lazy,this.sync=!!o.sync,this.before=o.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=n,this.id=++hn,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new se,this.newDepIds=new se,this.expression="","function"==typeof t?this.getter=t:(this.getter=function(e){if(!M.test(e)){var t=e.split(".");return function(e){for(var n=0;n<t.length;n++){if(!e)return;e=e[t[n]]}return e}}}(t),this.getter||(this.getter=P)),this.value=this.lazy?void 0:this.get()};fn.prototype.get=function(){var e;fe(this);var t=this.vm;try{e=this.getter.call(t,t)}catch(e){if(!this.user)throw e;Me(e,t,'getter for watcher "'+this.expression+'"')}finally{this.deep&&it(e),pe(),this.cleanupDeps()}return e},fn.prototype.addDep=function(e){var t=e.id;this.newDepIds.has(t)||(this.newDepIds.add(t),this.newDeps.push(e),this.depIds.has(t)||e.addSub(this))},fn.prototype.cleanupDeps=function(){for(var e=this.deps.length;e--;){var t=this.deps[e];this.newDepIds.has(t.id)||t.removeSub(this)}var n=this.depIds;this.depIds=this.newDepIds,this.newDepIds=n,this.newDepIds.clear(),n=this.deps,this.deps=this.newDeps,this.newDeps=n,this.newDeps.length=0},fn.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():function(e){var t=e.id;if(null==on[t]){if(on[t]=!0,an){for(var n=tn.length-1;n>sn&&tn[n].id>e.id;)n--;tn.splice(n+1,0,e)}else tn.push(e);rn||(rn=!0,nt(dn))}}(this)},fn.prototype.run=function(){if(this.active){var e=this.get();if(e!==this.value||c(e)||this.deep){var t=this.value;if(this.value=e,this.user)try{this.cb.call(this.vm,e,t)}catch(e){Me(e,this.vm,'callback for watcher "'+this.expression+'"')}else this.cb.call(this.vm,e,t)}}},fn.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},fn.prototype.depend=function(){for(var e=this.deps.length;e--;)this.deps[e].depend()},fn.prototype.teardown=function(){if(this.active){this.vm._isBeingDestroyed||y(this.vm._watchers,this);for(var e=this.deps.length;e--;)this.deps[e].removeSub(this);this.active=!1}};var pn={enumerable:!0,configurable:!0,get:P,set:P};function mn(e,t,n){pn.get=function(){return this[t][n]},pn.set=function(e){this[t][n]=e},Object.defineProperty(e,n,pn)}function gn(e){e._watchers=[];var t=e.$options;t.props&&function(e,t){var n=e.$options.propsData||{},o=e._props={},i=e.$options._propKeys=[];e.$parent&&Te(!1);var r=function(r){i.push(r);var a=Fe(r,t,n,e);_e(o,r,a),r in e||mn(e,"_props",r)};for(var a in t)r(a);Te(!0)}(e,t.props),t.methods&&function(e,t){e.$options.props;for(var n in t)e[n]="function"!=typeof t[n]?P:A(t[n],e)}(e,t.methods),t.data?function(e){var t=e.$options.data;d(t=e._data="function"==typeof t?function(e,t){fe();try{return e.call(t,t)}catch(e){return Me(e,t,"data()"),{}}finally{pe()}}(t,e):t||{})||(t={});var n=Object.keys(t),o=e.$options.props,i=(e.$options.methods,n.length);for(;i--;){var r=n[i];0,o&&k(o,r)||(a=void 0,36!==(a=(r+"").charCodeAt(0))&&95!==a&&mn(e,"_data",r))}var a;Ie(t,!0)}(e):Ie(e._data={},!0),t.computed&&function(e,t){var n=e._computedWatchers=Object.create(null),o=ie();for(var i in t){var r=t[i],a="function"==typeof r?r:r.get;0,o||(n[i]=new fn(e,a||P,P,wn)),i in e||vn(e,i,r)}}(e,t.computed),t.watch&&t.watch!==te&&function(e,t){for(var n in t){var o=t[n];if(Array.isArray(o))for(var i=0;i<o.length;i++)kn(e,n,o[i]);else kn(e,n,o)}}(e,t.watch)}var wn={lazy:!0};function vn(e,t,n){var o=!ie();"function"==typeof n?(pn.get=o?yn(t):bn(n),pn.set=P):(pn.get=n.get?o&&!1!==n.cache?yn(t):bn(n.get):P,pn.set=n.set||P),Object.defineProperty(e,t,pn)}function yn(e){return function(){var t=this._computedWatchers&&this._computedWatchers[e];if(t)return t.dirty&&t.evaluate(),de.target&&t.depend(),t.value}}function bn(e){return function(){return e.call(this,this)}}function kn(e,t,n,o){return d(n)&&(o=n,n=n.handler),"string"==typeof n&&(n=e[n]),e.$watch(t,n,o)}var xn=0;function Sn(e){var t=e.options;if(e.super){var n=Sn(e.super);if(n!==e.superOptions){e.superOptions=n;var o=function(e){var t,n=e.options,o=e.sealedOptions;for(var i in n)n[i]!==o[i]&&(t||(t={}),t[i]=n[i]);return t}(e);o&&O(e.extendOptions,o),(t=e.options=Re(n,e.extendOptions)).name&&(t.components[t.name]=e)}}return t}function Tn(e){this._init(e)}function Cn(e){e.cid=0;var t=1;e.extend=function(e){e=e||{};var n=this,o=n.cid,i=e._Ctor||(e._Ctor={});if(i[o])return i[o];var r=e.name||n.options.name;var a=function(e){this._init(e)};return(a.prototype=Object.create(n.prototype)).constructor=a,a.cid=t++,a.options=Re(n.options,e),a.super=n,a.options.props&&function(e){var t=e.options.props;for(var n in t)mn(e.prototype,"_props",n)}(a),a.options.computed&&function(e){var t=e.options.computed;for(var n in t)vn(e.prototype,n,t[n])}(a),a.extend=n.extend,a.mixin=n.mixin,a.use=n.use,L.forEach((function(e){a[e]=n[e]})),r&&(a.options.components[r]=a),a.superOptions=n.options,a.extendOptions=e,a.sealedOptions=O({},a.options),i[o]=a,a}}function In(e){return e&&(e.Ctor.options.name||e.tag)}function _n(e,t){return Array.isArray(e)?e.indexOf(t)>-1:"string"==typeof e?e.split(",").indexOf(t)>-1:!!h(e)&&e.test(t)}function An(e,t){var n=e.cache,o=e.keys,i=e._vnode;for(var r in n){var a=n[r];if(a){var s=In(a.componentOptions);s&&!t(s)&&En(n,r,o,i)}}}function En(e,t,n,o){var i=e[t];!i||o&&i.tag===o.tag||i.componentInstance.$destroy(),e[t]=null,y(n,t)}Tn.prototype._init=function(e){var t=this;t._uid=xn++,t._isVue=!0,e&&e._isComponent?function(e,t){var n=e.$options=Object.create(e.constructor.options),o=t._parentVnode;n.parent=t.parent,n._parentVnode=o;var i=o.componentOptions;n.propsData=i.propsData,n._parentListeners=i.listeners,n._renderChildren=i.children,n._componentTag=i.tag,t.render&&(n.render=t.render,n.staticRenderFns=t.staticRenderFns)}(t,e):t.$options=Re(Sn(t.constructor),e||{},t),t._renderProxy=t,t._self=t,function(e){var t=e.$options,n=t.parent;if(n&&!t.abstract){for(;n.$options.abstract&&n.$parent;)n=n.$parent;n.$children.push(e)}e.$parent=n,e.$root=n?n.$root:e,e.$children=[],e.$refs={},e._watcher=null,e._inactive=null,e._directInactive=!1,e._isMounted=!1,e._isDestroyed=!1,e._isBeingDestroyed=!1}(t),function(e){e._events=Object.create(null),e._hasHookEvent=!1;var t=e.$options._parentListeners;t&&Kt(e,t)}(t),function(e){e._vnode=null,e._staticTrees=null;var t=e.$options,n=e.$vnode=t._parentVnode,o=n&&n.context;e.$slots=ft(t._renderChildren,o),e.$scopedSlots=i,e._c=function(t,n,o,i){return zt(e,t,n,o,i,!1)},e.$createElement=function(t,n,o,i){return zt(e,t,n,o,i,!0)};var r=n&&n.data;_e(e,"$attrs",r&&r.attrs||i,null,!0),_e(e,"$listeners",t._parentListeners||i,null,!0)}(t),en(t,"beforeCreate"),function(e){var t=ht(e.$options.inject,e);t&&(Te(!1),Object.keys(t).forEach((function(n){_e(e,n,t[n])})),Te(!0))}(t),gn(t),function(e){var t=e.$options.provide;t&&(e._provided="function"==typeof t?t.call(e):t)}(t),en(t,"created"),t.$options.el&&t.$mount(t.$options.el)},function(e){var t={get:function(){return this._data}},n={get:function(){return this._props}};Object.defineProperty(e.prototype,"$data",t),Object.defineProperty(e.prototype,"$props",n),e.prototype.$set=Ae,e.prototype.$delete=Ee,e.prototype.$watch=function(e,t,n){if(d(t))return kn(this,e,t,n);(n=n||{}).user=!0;var o=new fn(this,e,t,n);if(n.immediate)try{t.call(this,o.value)}catch(e){Me(e,this,'callback for immediate watcher "'+o.expression+'"')}return function(){o.teardown()}}}(Tn),function(e){var t=/^hook:/;e.prototype.$on=function(e,n){var o=this;if(Array.isArray(e))for(var i=0,r=e.length;i<r;i++)o.$on(e[i],n);else(o._events[e]||(o._events[e]=[])).push(n),t.test(e)&&(o._hasHookEvent=!0);return o},e.prototype.$once=function(e,t){var n=this;function o(){n.$off(e,o),t.apply(n,arguments)}return o.fn=t,n.$on(e,o),n},e.prototype.$off=function(e,t){var n=this;if(!arguments.length)return n._events=Object.create(null),n;if(Array.isArray(e)){for(var o=0,i=e.length;o<i;o++)n.$off(e[o],t);return n}var r,a=n._events[e];if(!a)return n;if(!t)return n._events[e]=null,n;for(var s=a.length;s--;)if((r=a[s])===t||r.fn===t){a.splice(s,1);break}return n},e.prototype.$emit=function(e){var t=this,n=t._events[e];if(n){n=n.length>1?E(n):n;for(var o=E(arguments,1),i='event handler for "'+e+'"',r=0,a=n.length;r<a;r++)Ge(n[r],t,o,t,i)}return t}}(Tn),function(e){e.prototype._update=function(e,t){var n=this,o=n.$el,i=n._vnode,r=Jt(n);n._vnode=e,n.$el=i?n.__patch__(i,e):n.__patch__(n.$el,e,t,!1),r(),o&&(o.__vue__=null),n.$el&&(n.$el.__vue__=n),n.$vnode&&n.$parent&&n.$vnode===n.$parent._vnode&&(n.$parent.$el=n.$el)},e.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},e.prototype.$destroy=function(){var e=this;if(!e._isBeingDestroyed){en(e,"beforeDestroy"),e._isBeingDestroyed=!0;var t=e.$parent;!t||t._isBeingDestroyed||e.$options.abstract||y(t.$children,e),e._watcher&&e._watcher.teardown();for(var n=e._watchers.length;n--;)e._watchers[n].teardown();e._data.__ob__&&e._data.__ob__.vmCount--,e._isDestroyed=!0,e.__patch__(e._vnode,null),en(e,"destroyed"),e.$off(),e.$el&&(e.$el.__vue__=null),e.$vnode&&(e.$vnode.parent=null)}}}(Tn),function(e){Pt(e.prototype),e.prototype.$nextTick=function(e){return nt(e,this)},e.prototype._render=function(){var e,t=this,n=t.$options,o=n.render,i=n._parentVnode;i&&(t.$scopedSlots=mt(i.data.scopedSlots,t.$slots,t.$scopedSlots)),t.$vnode=i;try{$t=t,e=o.call(t._renderProxy,t.$createElement)}catch(n){Me(n,t,"render"),e=t._vnode}finally{$t=null}return Array.isArray(e)&&1===e.length&&(e=e[0]),e instanceof me||(e=we()),e.parent=i,e}}(Tn);var On=[String,RegExp,Array],jn={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:On,exclude:On,max:[String,Number]},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var e in this.cache)En(this.cache,e,this.keys)},mounted:function(){var e=this;this.$watch("include",(function(t){An(e,(function(e){return _n(t,e)}))})),this.$watch("exclude",(function(t){An(e,(function(e){return!_n(t,e)}))}))},render:function(){var e=this.$slots.default,t=Ut(e),n=t&&t.componentOptions;if(n){var o=In(n),i=this.include,r=this.exclude;if(i&&(!o||!_n(i,o))||r&&o&&_n(r,o))return t;var a=this.cache,s=this.keys,l=null==t.key?n.Ctor.cid+(n.tag?"::"+n.tag:""):t.key;a[l]?(t.componentInstance=a[l].componentInstance,y(s,l),s.push(l)):(a[l]=t,s.push(l),this.max&&s.length>parseInt(this.max)&&En(a,s[0],s,this._vnode)),t.data.keepAlive=!0}return t||e&&e[0]}}};!function(e){var t={get:function(){return z}};Object.defineProperty(e,"config",t),e.util={warn:ce,extend:O,mergeOptions:Re,defineReactive:_e},e.set=Ae,e.delete=Ee,e.nextTick=nt,e.observable=function(e){return Ie(e),e},e.options=Object.create(null),L.forEach((function(t){e.options[t+"s"]=Object.create(null)})),e.options._base=e,O(e.options.components,jn),function(e){e.use=function(e){var t=this._installedPlugins||(this._installedPlugins=[]);if(t.indexOf(e)>-1)return this;var n=E(arguments,1);return n.unshift(this),"function"==typeof e.install?e.install.apply(e,n):"function"==typeof e&&e.apply(null,n),t.push(e),this}}(e),function(e){e.mixin=function(e){return this.options=Re(this.options,e),this}}(e),Cn(e),function(e){L.forEach((function(t){e[t]=function(e,n){return n?("component"===t&&d(n)&&(n.name=n.name||e,n=this.options._base.extend(n)),"directive"===t&&"function"==typeof n&&(n={bind:n,update:n}),this.options[t+"s"][e]=n,n):this.options[t+"s"][e]}}))}(e)}(Tn),Object.defineProperty(Tn.prototype,"$isServer",{get:ie}),Object.defineProperty(Tn.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Tn,"FunctionalRenderContext",{value:Wt}),Tn.version="2.6.12";var Pn=w("style,class"),Wn=w("input,textarea,option,select,progress"),qn=w("contenteditable,draggable,spellcheck"),Dn=w("events,caret,typing,plaintext-only"),Nn=w("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,translate,truespeed,typemustmatch,visible"),Rn="http://www.w3.org/1999/xlink",Ln=function(e){return":"===e.charAt(5)&&"xlink"===e.slice(0,5)},Fn=function(e){return Ln(e)?e.slice(6,e.length):""},zn=function(e){return null==e||!1===e};function Hn(e){for(var t=e.data,n=e,o=e;a(o.componentInstance);)(o=o.componentInstance._vnode)&&o.data&&(t=$n(o.data,t));for(;a(n=n.parent);)n&&n.data&&(t=$n(t,n.data));return function(e,t){if(a(e)||a(t))return Mn(e,Gn(t));return""}(t.staticClass,t.class)}function $n(e,t){return{staticClass:Mn(e.staticClass,t.staticClass),class:a(e.class)?[e.class,t.class]:t.class}}function Mn(e,t){return e?t?e+" "+t:e:t||""}function Gn(e){return Array.isArray(e)?function(e){for(var t,n="",o=0,i=e.length;o<i;o++)a(t=Gn(e[o]))&&""!==t&&(n&&(n+=" "),n+=t);return n}(e):c(e)?function(e){var t="";for(var n in e)e[n]&&(t&&(t+=" "),t+=n);return t}(e):"string"==typeof e?e:""}var Un={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},Bn=w("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),Vn=w("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignObject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),Yn=function(e){return Bn(e)||Vn(e)};var Kn=Object.create(null);var Qn=w("text,number,password,search,email,tel,url");var Jn=Object.freeze({createElement:function(e,t){var n=document.createElement(e);return"select"!==e||t.data&&t.data.attrs&&void 0!==t.data.attrs.multiple&&n.setAttribute("multiple","multiple"),n},createElementNS:function(e,t){return document.createElementNS(Un[e],t)},createTextNode:function(e){return document.createTextNode(e)},createComment:function(e){return document.createComment(e)},insertBefore:function(e,t,n){e.insertBefore(t,n)},removeChild:function(e,t){e.removeChild(t)},appendChild:function(e,t){e.appendChild(t)},parentNode:function(e){return e.parentNode},nextSibling:function(e){return e.nextSibling},tagName:function(e){return e.tagName},setTextContent:function(e,t){e.textContent=t},setStyleScope:function(e,t){e.setAttribute(t,"")}}),Xn={create:function(e,t){Zn(t)},update:function(e,t){e.data.ref!==t.data.ref&&(Zn(e,!0),Zn(t))},destroy:function(e){Zn(e,!0)}};function Zn(e,t){var n=e.data.ref;if(a(n)){var o=e.context,i=e.componentInstance||e.elm,r=o.$refs;t?Array.isArray(r[n])?y(r[n],i):r[n]===i&&(r[n]=void 0):e.data.refInFor?Array.isArray(r[n])?r[n].indexOf(i)<0&&r[n].push(i):r[n]=[i]:r[n]=i}}var eo=new me("",{},[]),to=["create","activate","update","remove","destroy"];function no(e,t){return e.key===t.key&&(e.tag===t.tag&&e.isComment===t.isComment&&a(e.data)===a(t.data)&&function(e,t){if("input"!==e.tag)return!0;var n,o=a(n=e.data)&&a(n=n.attrs)&&n.type,i=a(n=t.data)&&a(n=n.attrs)&&n.type;return o===i||Qn(o)&&Qn(i)}(e,t)||s(e.isAsyncPlaceholder)&&e.asyncFactory===t.asyncFactory&&r(t.asyncFactory.error))}function oo(e,t,n){var o,i,r={};for(o=t;o<=n;++o)a(i=e[o].key)&&(r[i]=o);return r}var io={create:ro,update:ro,destroy:function(e){ro(e,eo)}};function ro(e,t){(e.data.directives||t.data.directives)&&function(e,t){var n,o,i,r=e===eo,a=t===eo,s=so(e.data.directives,e.context),l=so(t.data.directives,t.context),c=[],u=[];for(n in l)o=s[n],i=l[n],o?(i.oldValue=o.value,i.oldArg=o.arg,co(i,"update",t,e),i.def&&i.def.componentUpdated&&u.push(i)):(co(i,"bind",t,e),i.def&&i.def.inserted&&c.push(i));if(c.length){var d=function(){for(var n=0;n<c.length;n++)co(c[n],"inserted",t,e)};r?lt(t,"insert",d):d()}u.length&&lt(t,"postpatch",(function(){for(var n=0;n<u.length;n++)co(u[n],"componentUpdated",t,e)}));if(!r)for(n in s)l[n]||co(s[n],"unbind",e,e,a)}(e,t)}var ao=Object.create(null);function so(e,t){var n,o,i=Object.create(null);if(!e)return i;for(n=0;n<e.length;n++)(o=e[n]).modifiers||(o.modifiers=ao),i[lo(o)]=o,o.def=Le(t.$options,"directives",o.name);return i}function lo(e){return e.rawName||e.name+"."+Object.keys(e.modifiers||{}).join(".")}function co(e,t,n,o,i){var r=e.def&&e.def[t];if(r)try{r(n.elm,e,n,o,i)}catch(o){Me(o,n.context,"directive "+e.name+" "+t+" hook")}}var uo=[Xn,io];function ho(e,t){var n=t.componentOptions;if(!(a(n)&&!1===n.Ctor.options.inheritAttrs||r(e.data.attrs)&&r(t.data.attrs))){var o,i,s=t.elm,l=e.data.attrs||{},c=t.data.attrs||{};for(o in a(c.__ob__)&&(c=t.data.attrs=O({},c)),c)i=c[o],l[o]!==i&&fo(s,o,i);for(o in(Q||X)&&c.value!==l.value&&fo(s,"value",c.value),l)r(c[o])&&(Ln(o)?s.removeAttributeNS(Rn,Fn(o)):qn(o)||s.removeAttribute(o))}}function fo(e,t,n){e.tagName.indexOf("-")>-1?po(e,t,n):Nn(t)?zn(n)?e.removeAttribute(t):(n="allowfullscreen"===t&&"EMBED"===e.tagName?"true":t,e.setAttribute(t,n)):qn(t)?e.setAttribute(t,function(e,t){return zn(t)||"false"===t?"false":"contenteditable"===e&&Dn(t)?t:"true"}(t,n)):Ln(t)?zn(n)?e.removeAttributeNS(Rn,Fn(t)):e.setAttributeNS(Rn,t,n):po(e,t,n)}function po(e,t,n){if(zn(n))e.removeAttribute(t);else{if(Q&&!J&&"TEXTAREA"===e.tagName&&"placeholder"===t&&""!==n&&!e.__ieph){var o=function(t){t.stopImmediatePropagation(),e.removeEventListener("input",o)};e.addEventListener("input",o),e.__ieph=!0}e.setAttribute(t,n)}}var mo={create:ho,update:ho};function go(e,t){var n=t.elm,o=t.data,i=e.data;if(!(r(o.staticClass)&&r(o.class)&&(r(i)||r(i.staticClass)&&r(i.class)))){var s=Hn(t),l=n._transitionClasses;a(l)&&(s=Mn(s,Gn(l))),s!==n._prevClass&&(n.setAttribute("class",s),n._prevClass=s)}}var wo,vo={create:go,update:go};function yo(e,t,n){var o=wo;return function i(){var r=t.apply(null,arguments);null!==r&&xo(e,i,n,o)}}var bo=Ye&&!(ee&&Number(ee[1])<=53);function ko(e,t,n,o){if(bo){var i=ln,r=t;t=r._wrapper=function(e){if(e.target===e.currentTarget||e.timeStamp>=i||e.timeStamp<=0||e.target.ownerDocument!==document)return r.apply(this,arguments)}}wo.addEventListener(e,t,ne?{capture:n,passive:o}:n)}function xo(e,t,n,o){(o||wo).removeEventListener(e,t._wrapper||t,n)}function So(e,t){if(!r(e.data.on)||!r(t.data.on)){var n=t.data.on||{},o=e.data.on||{};wo=t.elm,function(e){if(a(e.__r)){var t=Q?"change":"input";e[t]=[].concat(e.__r,e[t]||[]),delete e.__r}a(e.__c)&&(e.change=[].concat(e.__c,e.change||[]),delete e.__c)}(n),st(n,o,ko,xo,yo,t.context),wo=void 0}}var To,Co={create:So,update:So};function Io(e,t){if(!r(e.data.domProps)||!r(t.data.domProps)){var n,o,i=t.elm,s=e.data.domProps||{},l=t.data.domProps||{};for(n in a(l.__ob__)&&(l=t.data.domProps=O({},l)),s)n in l||(i[n]="");for(n in l){if(o=l[n],"textContent"===n||"innerHTML"===n){if(t.children&&(t.children.length=0),o===s[n])continue;1===i.childNodes.length&&i.removeChild(i.childNodes[0])}if("value"===n&&"PROGRESS"!==i.tagName){i._value=o;var c=r(o)?"":String(o);_o(i,c)&&(i.value=c)}else if("innerHTML"===n&&Vn(i.tagName)&&r(i.innerHTML)){(To=To||document.createElement("div")).innerHTML="<svg>"+o+"</svg>";for(var u=To.firstChild;i.firstChild;)i.removeChild(i.firstChild);for(;u.firstChild;)i.appendChild(u.firstChild)}else if(o!==s[n])try{i[n]=o}catch(e){}}}}function _o(e,t){return!e.composing&&("OPTION"===e.tagName||function(e,t){var n=!0;try{n=document.activeElement!==e}catch(e){}return n&&e.value!==t}(e,t)||function(e,t){var n=e.value,o=e._vModifiers;if(a(o)){if(o.number)return g(n)!==g(t);if(o.trim)return n.trim()!==t.trim()}return n!==t}(e,t))}var Ao={create:Io,update:Io},Eo=x((function(e){var t={},n=/:(.+)/;return e.split(/;(?![^(]*\))/g).forEach((function(e){if(e){var o=e.split(n);o.length>1&&(t[o[0].trim()]=o[1].trim())}})),t}));function Oo(e){var t=jo(e.style);return e.staticStyle?O(e.staticStyle,t):t}function jo(e){return Array.isArray(e)?j(e):"string"==typeof e?Eo(e):e}var Po,Wo=/^--/,qo=/\s*!important$/,Do=function(e,t,n){if(Wo.test(t))e.style.setProperty(t,n);else if(qo.test(n))e.style.setProperty(_(t),n.replace(qo,""),"important");else{var o=Ro(t);if(Array.isArray(n))for(var i=0,r=n.length;i<r;i++)e.style[o]=n[i];else e.style[o]=n}},No=["Webkit","Moz","ms"],Ro=x((function(e){if(Po=Po||document.createElement("div").style,"filter"!==(e=T(e))&&e in Po)return e;for(var t=e.charAt(0).toUpperCase()+e.slice(1),n=0;n<No.length;n++){var o=No[n]+t;if(o in Po)return o}}));function Lo(e,t){var n=t.data,o=e.data;if(!(r(n.staticStyle)&&r(n.style)&&r(o.staticStyle)&&r(o.style))){var i,s,l=t.elm,c=o.staticStyle,u=o.normalizedStyle||o.style||{},d=c||u,h=jo(t.data.style)||{};t.data.normalizedStyle=a(h.__ob__)?O({},h):h;var f=function(e,t){var n,o={};if(t)for(var i=e;i.componentInstance;)(i=i.componentInstance._vnode)&&i.data&&(n=Oo(i.data))&&O(o,n);(n=Oo(e.data))&&O(o,n);for(var r=e;r=r.parent;)r.data&&(n=Oo(r.data))&&O(o,n);return o}(t,!0);for(s in d)r(f[s])&&Do(l,s,"");for(s in f)(i=f[s])!==d[s]&&Do(l,s,null==i?"":i)}}var Fo={create:Lo,update:Lo},zo=/\s+/;function Ho(e,t){if(t&&(t=t.trim()))if(e.classList)t.indexOf(" ")>-1?t.split(zo).forEach((function(t){return e.classList.add(t)})):e.classList.add(t);else{var n=" "+(e.getAttribute("class")||"")+" ";n.indexOf(" "+t+" ")<0&&e.setAttribute("class",(n+t).trim())}}function $o(e,t){if(t&&(t=t.trim()))if(e.classList)t.indexOf(" ")>-1?t.split(zo).forEach((function(t){return e.classList.remove(t)})):e.classList.remove(t),e.classList.length||e.removeAttribute("class");else{for(var n=" "+(e.getAttribute("class")||"")+" ",o=" "+t+" ";n.indexOf(o)>=0;)n=n.replace(o," ");(n=n.trim())?e.setAttribute("class",n):e.removeAttribute("class")}}function Mo(e){if(e){if("object"==typeof e){var t={};return!1!==e.css&&O(t,Go(e.name||"v")),O(t,e),t}return"string"==typeof e?Go(e):void 0}}var Go=x((function(e){return{enterClass:e+"-enter",enterToClass:e+"-enter-to",enterActiveClass:e+"-enter-active",leaveClass:e+"-leave",leaveToClass:e+"-leave-to",leaveActiveClass:e+"-leave-active"}})),Uo=B&&!J,Bo="transition",Vo="transitionend",Yo="animation",Ko="animationend";Uo&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(Bo="WebkitTransition",Vo="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(Yo="WebkitAnimation",Ko="webkitAnimationEnd"));var Qo=B?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(e){return e()};function Jo(e){Qo((function(){Qo(e)}))}function Xo(e,t){var n=e._transitionClasses||(e._transitionClasses=[]);n.indexOf(t)<0&&(n.push(t),Ho(e,t))}function Zo(e,t){e._transitionClasses&&y(e._transitionClasses,t),$o(e,t)}function ei(e,t,n){var o=ni(e,t),i=o.type,r=o.timeout,a=o.propCount;if(!i)return n();var s="transition"===i?Vo:Ko,l=0,c=function(){e.removeEventListener(s,u),n()},u=function(t){t.target===e&&++l>=a&&c()};setTimeout((function(){l<a&&c()}),r+1),e.addEventListener(s,u)}var ti=/\b(transform|all)(,|$)/;function ni(e,t){var n,o=window.getComputedStyle(e),i=(o[Bo+"Delay"]||"").split(", "),r=(o[Bo+"Duration"]||"").split(", "),a=oi(i,r),s=(o[Yo+"Delay"]||"").split(", "),l=(o[Yo+"Duration"]||"").split(", "),c=oi(s,l),u=0,d=0;return"transition"===t?a>0&&(n="transition",u=a,d=r.length):"animation"===t?c>0&&(n="animation",u=c,d=l.length):d=(n=(u=Math.max(a,c))>0?a>c?"transition":"animation":null)?"transition"===n?r.length:l.length:0,{type:n,timeout:u,propCount:d,hasTransform:"transition"===n&&ti.test(o[Bo+"Property"])}}function oi(e,t){for(;e.length<t.length;)e=e.concat(e);return Math.max.apply(null,t.map((function(t,n){return ii(t)+ii(e[n])})))}function ii(e){return 1e3*Number(e.slice(0,-1).replace(",","."))}function ri(e,t){var n=e.elm;a(n._leaveCb)&&(n._leaveCb.cancelled=!0,n._leaveCb());var o=Mo(e.data.transition);if(!r(o)&&!a(n._enterCb)&&1===n.nodeType){for(var i=o.css,s=o.type,l=o.enterClass,u=o.enterToClass,d=o.enterActiveClass,h=o.appearClass,f=o.appearToClass,p=o.appearActiveClass,m=o.beforeEnter,w=o.enter,v=o.afterEnter,y=o.enterCancelled,b=o.beforeAppear,k=o.appear,x=o.afterAppear,S=o.appearCancelled,T=o.duration,C=Qt,I=Qt.$vnode;I&&I.parent;)C=I.context,I=I.parent;var _=!C._isMounted||!e.isRootInsert;if(!_||k||""===k){var A=_&&h?h:l,E=_&&p?p:d,O=_&&f?f:u,j=_&&b||m,P=_&&"function"==typeof k?k:w,W=_&&x||v,q=_&&S||y,D=g(c(T)?T.enter:T);0;var N=!1!==i&&!J,L=li(P),F=n._enterCb=R((function(){N&&(Zo(n,O),Zo(n,E)),F.cancelled?(N&&Zo(n,A),q&&q(n)):W&&W(n),n._enterCb=null}));e.data.show||lt(e,"insert",(function(){var t=n.parentNode,o=t&&t._pending&&t._pending[e.key];o&&o.tag===e.tag&&o.elm._leaveCb&&o.elm._leaveCb(),P&&P(n,F)})),j&&j(n),N&&(Xo(n,A),Xo(n,E),Jo((function(){Zo(n,A),F.cancelled||(Xo(n,O),L||(si(D)?setTimeout(F,D):ei(n,s,F)))}))),e.data.show&&(t&&t(),P&&P(n,F)),N||L||F()}}}function ai(e,t){var n=e.elm;a(n._enterCb)&&(n._enterCb.cancelled=!0,n._enterCb());var o=Mo(e.data.transition);if(r(o)||1!==n.nodeType)return t();if(!a(n._leaveCb)){var i=o.css,s=o.type,l=o.leaveClass,u=o.leaveToClass,d=o.leaveActiveClass,h=o.beforeLeave,f=o.leave,p=o.afterLeave,m=o.leaveCancelled,w=o.delayLeave,v=o.duration,y=!1!==i&&!J,b=li(f),k=g(c(v)?v.leave:v);0;var x=n._leaveCb=R((function(){n.parentNode&&n.parentNode._pending&&(n.parentNode._pending[e.key]=null),y&&(Zo(n,u),Zo(n,d)),x.cancelled?(y&&Zo(n,l),m&&m(n)):(t(),p&&p(n)),n._leaveCb=null}));w?w(S):S()}function S(){x.cancelled||(!e.data.show&&n.parentNode&&((n.parentNode._pending||(n.parentNode._pending={}))[e.key]=e),h&&h(n),y&&(Xo(n,l),Xo(n,d),Jo((function(){Zo(n,l),x.cancelled||(Xo(n,u),b||(si(k)?setTimeout(x,k):ei(n,s,x)))}))),f&&f(n,x),y||b||x())}}function si(e){return"number"==typeof e&&!isNaN(e)}function li(e){if(r(e))return!1;var t=e.fns;return a(t)?li(Array.isArray(t)?t[0]:t):(e._length||e.length)>1}function ci(e,t){!0!==t.data.show&&ri(t)}var ui=function(e){var t,n,o={},i=e.modules,c=e.nodeOps;for(t=0;t<to.length;++t)for(o[to[t]]=[],n=0;n<i.length;++n)a(i[n][to[t]])&&o[to[t]].push(i[n][to[t]]);function u(e){var t=c.parentNode(e);a(t)&&c.removeChild(t,e)}function d(e,t,n,i,r,l,u){if(a(e.elm)&&a(l)&&(e=l[u]=ye(e)),e.isRootInsert=!r,!function(e,t,n,i){var r=e.data;if(a(r)){var l=a(e.componentInstance)&&r.keepAlive;if(a(r=r.hook)&&a(r=r.init)&&r(e,!1),a(e.componentInstance))return h(e,t),f(n,e.elm,i),s(l)&&function(e,t,n,i){var r,s=e;for(;s.componentInstance;)if(s=s.componentInstance._vnode,a(r=s.data)&&a(r=r.transition)){for(r=0;r<o.activate.length;++r)o.activate[r](eo,s);t.push(s);break}f(n,e.elm,i)}(e,t,n,i),!0}}(e,t,n,i)){var d=e.data,m=e.children,w=e.tag;a(w)?(e.elm=e.ns?c.createElementNS(e.ns,w):c.createElement(w,e),v(e),p(e,m,t),a(d)&&g(e,t),f(n,e.elm,i)):s(e.isComment)?(e.elm=c.createComment(e.text),f(n,e.elm,i)):(e.elm=c.createTextNode(e.text),f(n,e.elm,i))}}function h(e,t){a(e.data.pendingInsert)&&(t.push.apply(t,e.data.pendingInsert),e.data.pendingInsert=null),e.elm=e.componentInstance.$el,m(e)?(g(e,t),v(e)):(Zn(e),t.push(e))}function f(e,t,n){a(e)&&(a(n)?c.parentNode(n)===e&&c.insertBefore(e,t,n):c.appendChild(e,t))}function p(e,t,n){if(Array.isArray(t)){0;for(var o=0;o<t.length;++o)d(t[o],n,e.elm,null,!0,t,o)}else l(e.text)&&c.appendChild(e.elm,c.createTextNode(String(e.text)))}function m(e){for(;e.componentInstance;)e=e.componentInstance._vnode;return a(e.tag)}function g(e,n){for(var i=0;i<o.create.length;++i)o.create[i](eo,e);a(t=e.data.hook)&&(a(t.create)&&t.create(eo,e),a(t.insert)&&n.push(e))}function v(e){var t;if(a(t=e.fnScopeId))c.setStyleScope(e.elm,t);else for(var n=e;n;)a(t=n.context)&&a(t=t.$options._scopeId)&&c.setStyleScope(e.elm,t),n=n.parent;a(t=Qt)&&t!==e.context&&t!==e.fnContext&&a(t=t.$options._scopeId)&&c.setStyleScope(e.elm,t)}function y(e,t,n,o,i,r){for(;o<=i;++o)d(n[o],r,e,t,!1,n,o)}function b(e){var t,n,i=e.data;if(a(i))for(a(t=i.hook)&&a(t=t.destroy)&&t(e),t=0;t<o.destroy.length;++t)o.destroy[t](e);if(a(t=e.children))for(n=0;n<e.children.length;++n)b(e.children[n])}function k(e,t,n){for(;t<=n;++t){var o=e[t];a(o)&&(a(o.tag)?(x(o),b(o)):u(o.elm))}}function x(e,t){if(a(t)||a(e.data)){var n,i=o.remove.length+1;for(a(t)?t.listeners+=i:t=function(e,t){function n(){0==--n.listeners&&u(e)}return n.listeners=t,n}(e.elm,i),a(n=e.componentInstance)&&a(n=n._vnode)&&a(n.data)&&x(n,t),n=0;n<o.remove.length;++n)o.remove[n](e,t);a(n=e.data.hook)&&a(n=n.remove)?n(e,t):t()}else u(e.elm)}function S(e,t,n,o){for(var i=n;i<o;i++){var r=t[i];if(a(r)&&no(e,r))return i}}function T(e,t,n,i,l,u){if(e!==t){a(t.elm)&&a(i)&&(t=i[l]=ye(t));var h=t.elm=e.elm;if(s(e.isAsyncPlaceholder))a(t.asyncFactory.resolved)?_(e.elm,t,n):t.isAsyncPlaceholder=!0;else if(s(t.isStatic)&&s(e.isStatic)&&t.key===e.key&&(s(t.isCloned)||s(t.isOnce)))t.componentInstance=e.componentInstance;else{var f,p=t.data;a(p)&&a(f=p.hook)&&a(f=f.prepatch)&&f(e,t);var g=e.children,w=t.children;if(a(p)&&m(t)){for(f=0;f<o.update.length;++f)o.update[f](e,t);a(f=p.hook)&&a(f=f.update)&&f(e,t)}r(t.text)?a(g)&&a(w)?g!==w&&function(e,t,n,o,i){var s,l,u,h=0,f=0,p=t.length-1,m=t[0],g=t[p],w=n.length-1,v=n[0],b=n[w],x=!i;for(0;h<=p&&f<=w;)r(m)?m=t[++h]:r(g)?g=t[--p]:no(m,v)?(T(m,v,o,n,f),m=t[++h],v=n[++f]):no(g,b)?(T(g,b,o,n,w),g=t[--p],b=n[--w]):no(m,b)?(T(m,b,o,n,w),x&&c.insertBefore(e,m.elm,c.nextSibling(g.elm)),m=t[++h],b=n[--w]):no(g,v)?(T(g,v,o,n,f),x&&c.insertBefore(e,g.elm,m.elm),g=t[--p],v=n[++f]):(r(s)&&(s=oo(t,h,p)),r(l=a(v.key)?s[v.key]:S(v,t,h,p))?d(v,o,e,m.elm,!1,n,f):no(u=t[l],v)?(T(u,v,o,n,f),t[l]=void 0,x&&c.insertBefore(e,u.elm,m.elm)):d(v,o,e,m.elm,!1,n,f),v=n[++f]);h>p?y(e,r(n[w+1])?null:n[w+1].elm,n,f,w,o):f>w&&k(t,h,p)}(h,g,w,n,u):a(w)?(a(e.text)&&c.setTextContent(h,""),y(h,null,w,0,w.length-1,n)):a(g)?k(g,0,g.length-1):a(e.text)&&c.setTextContent(h,""):e.text!==t.text&&c.setTextContent(h,t.text),a(p)&&a(f=p.hook)&&a(f=f.postpatch)&&f(e,t)}}}function C(e,t,n){if(s(n)&&a(e.parent))e.parent.data.pendingInsert=t;else for(var o=0;o<t.length;++o)t[o].data.hook.insert(t[o])}var I=w("attrs,class,staticClass,staticStyle,key");function _(e,t,n,o){var i,r=t.tag,l=t.data,c=t.children;if(o=o||l&&l.pre,t.elm=e,s(t.isComment)&&a(t.asyncFactory))return t.isAsyncPlaceholder=!0,!0;if(a(l)&&(a(i=l.hook)&&a(i=i.init)&&i(t,!0),a(i=t.componentInstance)))return h(t,n),!0;if(a(r)){if(a(c))if(e.hasChildNodes())if(a(i=l)&&a(i=i.domProps)&&a(i=i.innerHTML)){if(i!==e.innerHTML)return!1}else{for(var u=!0,d=e.firstChild,f=0;f<c.length;f++){if(!d||!_(d,c[f],n,o)){u=!1;break}d=d.nextSibling}if(!u||d)return!1}else p(t,c,n);if(a(l)){var m=!1;for(var w in l)if(!I(w)){m=!0,g(t,n);break}!m&&l.class&&it(l.class)}}else e.data!==t.text&&(e.data=t.text);return!0}return function(e,t,n,i){if(!r(t)){var l,u=!1,h=[];if(r(e))u=!0,d(t,h);else{var f=a(e.nodeType);if(!f&&no(e,t))T(e,t,h,null,null,i);else{if(f){if(1===e.nodeType&&e.hasAttribute("data-server-rendered")&&(e.removeAttribute("data-server-rendered"),n=!0),s(n)&&_(e,t,h))return C(t,h,!0),e;l=e,e=new me(c.tagName(l).toLowerCase(),{},[],void 0,l)}var p=e.elm,g=c.parentNode(p);if(d(t,h,p._leaveCb?null:g,c.nextSibling(p)),a(t.parent))for(var w=t.parent,v=m(t);w;){for(var y=0;y<o.destroy.length;++y)o.destroy[y](w);if(w.elm=t.elm,v){for(var x=0;x<o.create.length;++x)o.create[x](eo,w);var S=w.data.hook.insert;if(S.merged)for(var I=1;I<S.fns.length;I++)S.fns[I]()}else Zn(w);w=w.parent}a(g)?k([e],0,0):a(e.tag)&&b(e)}}return C(t,h,u),t.elm}a(e)&&b(e)}}({nodeOps:Jn,modules:[mo,vo,Co,Ao,Fo,B?{create:ci,activate:ci,remove:function(e,t){!0!==e.data.show?ai(e,t):t()}}:{}].concat(uo)});J&&document.addEventListener("selectionchange",(function(){var e=document.activeElement;e&&e.vmodel&&vi(e,"input")}));var di={inserted:function(e,t,n,o){"select"===n.tag?(o.elm&&!o.elm._vOptions?lt(n,"postpatch",(function(){di.componentUpdated(e,t,n)})):hi(e,t,n.context),e._vOptions=[].map.call(e.options,mi)):("textarea"===n.tag||Qn(e.type))&&(e._vModifiers=t.modifiers,t.modifiers.lazy||(e.addEventListener("compositionstart",gi),e.addEventListener("compositionend",wi),e.addEventListener("change",wi),J&&(e.vmodel=!0)))},componentUpdated:function(e,t,n){if("select"===n.tag){hi(e,t,n.context);var o=e._vOptions,i=e._vOptions=[].map.call(e.options,mi);if(i.some((function(e,t){return!D(e,o[t])})))(e.multiple?t.value.some((function(e){return pi(e,i)})):t.value!==t.oldValue&&pi(t.value,i))&&vi(e,"change")}}};function hi(e,t,n){fi(e,t,n),(Q||X)&&setTimeout((function(){fi(e,t,n)}),0)}function fi(e,t,n){var o=t.value,i=e.multiple;if(!i||Array.isArray(o)){for(var r,a,s=0,l=e.options.length;s<l;s++)if(a=e.options[s],i)r=N(o,mi(a))>-1,a.selected!==r&&(a.selected=r);else if(D(mi(a),o))return void(e.selectedIndex!==s&&(e.selectedIndex=s));i||(e.selectedIndex=-1)}}function pi(e,t){return t.every((function(t){return!D(t,e)}))}function mi(e){return"_value"in e?e._value:e.value}function gi(e){e.target.composing=!0}function wi(e){e.target.composing&&(e.target.composing=!1,vi(e.target,"input"))}function vi(e,t){var n=document.createEvent("HTMLEvents");n.initEvent(t,!0,!0),e.dispatchEvent(n)}function yi(e){return!e.componentInstance||e.data&&e.data.transition?e:yi(e.componentInstance._vnode)}var bi={model:di,show:{bind:function(e,t,n){var o=t.value,i=(n=yi(n)).data&&n.data.transition,r=e.__vOriginalDisplay="none"===e.style.display?"":e.style.display;o&&i?(n.data.show=!0,ri(n,(function(){e.style.display=r}))):e.style.display=o?r:"none"},update:function(e,t,n){var o=t.value;!o!=!t.oldValue&&((n=yi(n)).data&&n.data.transition?(n.data.show=!0,o?ri(n,(function(){e.style.display=e.__vOriginalDisplay})):ai(n,(function(){e.style.display="none"}))):e.style.display=o?e.__vOriginalDisplay:"none")},unbind:function(e,t,n,o,i){i||(e.style.display=e.__vOriginalDisplay)}}},ki={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function xi(e){var t=e&&e.componentOptions;return t&&t.Ctor.options.abstract?xi(Ut(t.children)):e}function Si(e){var t={},n=e.$options;for(var o in n.propsData)t[o]=e[o];var i=n._parentListeners;for(var r in i)t[T(r)]=i[r];return t}function Ti(e,t){if(/\d-keep-alive$/.test(t.tag))return e("keep-alive",{props:t.componentOptions.propsData})}var Ci=function(e){return e.tag||Gt(e)},Ii=function(e){return"show"===e.name},_i={name:"transition",props:ki,abstract:!0,render:function(e){var t=this,n=this.$slots.default;if(n&&(n=n.filter(Ci)).length){0;var o=this.mode;0;var i=n[0];if(function(e){for(;e=e.parent;)if(e.data.transition)return!0}(this.$vnode))return i;var r=xi(i);if(!r)return i;if(this._leaving)return Ti(e,i);var a="__transition-"+this._uid+"-";r.key=null==r.key?r.isComment?a+"comment":a+r.tag:l(r.key)?0===String(r.key).indexOf(a)?r.key:a+r.key:r.key;var s=(r.data||(r.data={})).transition=Si(this),c=this._vnode,u=xi(c);if(r.data.directives&&r.data.directives.some(Ii)&&(r.data.show=!0),u&&u.data&&!function(e,t){return t.key===e.key&&t.tag===e.tag}(r,u)&&!Gt(u)&&(!u.componentInstance||!u.componentInstance._vnode.isComment)){var d=u.data.transition=O({},s);if("out-in"===o)return this._leaving=!0,lt(d,"afterLeave",(function(){t._leaving=!1,t.$forceUpdate()})),Ti(e,i);if("in-out"===o){if(Gt(r))return c;var h,f=function(){h()};lt(s,"afterEnter",f),lt(s,"enterCancelled",f),lt(d,"delayLeave",(function(e){h=e}))}}return i}}},Ai=O({tag:String,moveClass:String},ki);function Ei(e){e.elm._moveCb&&e.elm._moveCb(),e.elm._enterCb&&e.elm._enterCb()}function Oi(e){e.data.newPos=e.elm.getBoundingClientRect()}function ji(e){var t=e.data.pos,n=e.data.newPos,o=t.left-n.left,i=t.top-n.top;if(o||i){e.data.moved=!0;var r=e.elm.style;r.transform=r.WebkitTransform="translate("+o+"px,"+i+"px)",r.transitionDuration="0s"}}delete Ai.mode;var Pi={Transition:_i,TransitionGroup:{props:Ai,beforeMount:function(){var e=this,t=this._update;this._update=function(n,o){var i=Jt(e);e.__patch__(e._vnode,e.kept,!1,!0),e._vnode=e.kept,i(),t.call(e,n,o)}},render:function(e){for(var t=this.tag||this.$vnode.data.tag||"span",n=Object.create(null),o=this.prevChildren=this.children,i=this.$slots.default||[],r=this.children=[],a=Si(this),s=0;s<i.length;s++){var l=i[s];if(l.tag)if(null!=l.key&&0!==String(l.key).indexOf("__vlist"))r.push(l),n[l.key]=l,(l.data||(l.data={})).transition=a;else;}if(o){for(var c=[],u=[],d=0;d<o.length;d++){var h=o[d];h.data.transition=a,h.data.pos=h.elm.getBoundingClientRect(),n[h.key]?c.push(h):u.push(h)}this.kept=e(t,null,c),this.removed=u}return e(t,null,r)},updated:function(){var e=this.prevChildren,t=this.moveClass||(this.name||"v")+"-move";e.length&&this.hasMove(e[0].elm,t)&&(e.forEach(Ei),e.forEach(Oi),e.forEach(ji),this._reflow=document.body.offsetHeight,e.forEach((function(e){if(e.data.moved){var n=e.elm,o=n.style;Xo(n,t),o.transform=o.WebkitTransform=o.transitionDuration="",n.addEventListener(Vo,n._moveCb=function e(o){o&&o.target!==n||o&&!/transform$/.test(o.propertyName)||(n.removeEventListener(Vo,e),n._moveCb=null,Zo(n,t))})}})))},methods:{hasMove:function(e,t){if(!Uo)return!1;if(this._hasMove)return this._hasMove;var n=e.cloneNode();e._transitionClasses&&e._transitionClasses.forEach((function(e){$o(n,e)})),Ho(n,t),n.style.display="none",this.$el.appendChild(n);var o=ni(n);return this.$el.removeChild(n),this._hasMove=o.hasTransform}}}};Tn.config.mustUseProp=function(e,t,n){return"value"===n&&Wn(e)&&"button"!==t||"selected"===n&&"option"===e||"checked"===n&&"input"===e||"muted"===n&&"video"===e},Tn.config.isReservedTag=Yn,Tn.config.isReservedAttr=Pn,Tn.config.getTagNamespace=function(e){return Vn(e)?"svg":"math"===e?"math":void 0},Tn.config.isUnknownElement=function(e){if(!B)return!0;if(Yn(e))return!1;if(e=e.toLowerCase(),null!=Kn[e])return Kn[e];var t=document.createElement(e);return e.indexOf("-")>-1?Kn[e]=t.constructor===window.HTMLUnknownElement||t.constructor===window.HTMLElement:Kn[e]=/HTMLUnknownElement/.test(t.toString())},O(Tn.options.directives,bi),O(Tn.options.components,Pi),Tn.prototype.__patch__=B?ui:P,Tn.prototype.$mount=function(e,t){return function(e,t,n){var o;return e.$el=t,e.$options.render||(e.$options.render=we),en(e,"beforeMount"),o=function(){e._update(e._render(),n)},new fn(e,o,P,{before:function(){e._isMounted&&!e._isDestroyed&&en(e,"beforeUpdate")}},!0),n=!1,null==e.$vnode&&(e._isMounted=!0,en(e,"mounted")),e}(this,e=e&&B?function(e){if("string"==typeof e){var t=document.querySelector(e);return t||document.createElement("div")}return e}(e):void 0,t)},B&&setTimeout((function(){z.devtools&&re&&re.emit("init",Tn)}),0);var Wi=Tn;
/*!
  * vue-router v3.4.9
  * (c) 2020 Evan You
  * @license MIT
  */function qi(e,t){for(var n in t)e[n]=t[n];return e}var Di=/[!'()*]/g,Ni=function(e){return"%"+e.charCodeAt(0).toString(16)},Ri=/%2C/g,Li=function(e){return encodeURIComponent(e).replace(Di,Ni).replace(Ri,",")};function Fi(e){try{return decodeURIComponent(e)}catch(e){0}return e}var zi=function(e){return null==e||"object"==typeof e?e:String(e)};function Hi(e){var t={};return(e=e.trim().replace(/^(\?|#|&)/,""))?(e.split("&").forEach((function(e){var n=e.replace(/\+/g," ").split("="),o=Fi(n.shift()),i=n.length>0?Fi(n.join("=")):null;void 0===t[o]?t[o]=i:Array.isArray(t[o])?t[o].push(i):t[o]=[t[o],i]})),t):t}function $i(e){var t=e?Object.keys(e).map((function(t){var n=e[t];if(void 0===n)return"";if(null===n)return Li(t);if(Array.isArray(n)){var o=[];return n.forEach((function(e){void 0!==e&&(null===e?o.push(Li(t)):o.push(Li(t)+"="+Li(e)))})),o.join("&")}return Li(t)+"="+Li(n)})).filter((function(e){return e.length>0})).join("&"):null;return t?"?"+t:""}var Mi=/\/?$/;function Gi(e,t,n,o){var i=o&&o.options.stringifyQuery,r=t.query||{};try{r=Ui(r)}catch(e){}var a={name:t.name||e&&e.name,meta:e&&e.meta||{},path:t.path||"/",hash:t.hash||"",query:r,params:t.params||{},fullPath:Yi(t,i),matched:e?Vi(e):[]};return n&&(a.redirectedFrom=Yi(n,i)),Object.freeze(a)}function Ui(e){if(Array.isArray(e))return e.map(Ui);if(e&&"object"==typeof e){var t={};for(var n in e)t[n]=Ui(e[n]);return t}return e}var Bi=Gi(null,{path:"/"});function Vi(e){for(var t=[];e;)t.unshift(e),e=e.parent;return t}function Yi(e,t){var n=e.path,o=e.query;void 0===o&&(o={});var i=e.hash;return void 0===i&&(i=""),(n||"/")+(t||$i)(o)+i}function Ki(e,t){return t===Bi?e===t:!!t&&(e.path&&t.path?e.path.replace(Mi,"")===t.path.replace(Mi,"")&&e.hash===t.hash&&Qi(e.query,t.query):!(!e.name||!t.name)&&(e.name===t.name&&e.hash===t.hash&&Qi(e.query,t.query)&&Qi(e.params,t.params)))}function Qi(e,t){if(void 0===e&&(e={}),void 0===t&&(t={}),!e||!t)return e===t;var n=Object.keys(e).sort(),o=Object.keys(t).sort();return n.length===o.length&&n.every((function(n,i){var r=e[n];if(o[i]!==n)return!1;var a=t[n];return null==r||null==a?r===a:"object"==typeof r&&"object"==typeof a?Qi(r,a):String(r)===String(a)}))}function Ji(e){for(var t=0;t<e.matched.length;t++){var n=e.matched[t];for(var o in n.instances){var i=n.instances[o],r=n.enteredCbs[o];if(i&&r){delete n.enteredCbs[o];for(var a=0;a<r.length;a++)i._isBeingDestroyed||r[a](i)}}}}var Xi={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(e,t){var n=t.props,o=t.children,i=t.parent,r=t.data;r.routerView=!0;for(var a=i.$createElement,s=n.name,l=i.$route,c=i._routerViewCache||(i._routerViewCache={}),u=0,d=!1;i&&i._routerRoot!==i;){var h=i.$vnode?i.$vnode.data:{};h.routerView&&u++,h.keepAlive&&i._directInactive&&i._inactive&&(d=!0),i=i.$parent}if(r.routerViewDepth=u,d){var f=c[s],p=f&&f.component;return p?(f.configProps&&Zi(p,r,f.route,f.configProps),a(p,r,o)):a()}var m=l.matched[u],g=m&&m.components[s];if(!m||!g)return c[s]=null,a();c[s]={component:g},r.registerRouteInstance=function(e,t){var n=m.instances[s];(t&&n!==e||!t&&n===e)&&(m.instances[s]=t)},(r.hook||(r.hook={})).prepatch=function(e,t){m.instances[s]=t.componentInstance},r.hook.init=function(e){e.data.keepAlive&&e.componentInstance&&e.componentInstance!==m.instances[s]&&(m.instances[s]=e.componentInstance),Ji(l)};var w=m.props&&m.props[s];return w&&(qi(c[s],{route:l,configProps:w}),Zi(g,r,l,w)),a(g,r,o)}};function Zi(e,t,n,o){var i=t.props=function(e,t){switch(typeof t){case"undefined":return;case"object":return t;case"function":return t(e);case"boolean":return t?e.params:void 0;default:0}}(n,o);if(i){i=t.props=qi({},i);var r=t.attrs=t.attrs||{};for(var a in i)e.props&&a in e.props||(r[a]=i[a],delete i[a])}}function er(e,t,n){var o=e.charAt(0);if("/"===o)return e;if("?"===o||"#"===o)return t+e;var i=t.split("/");n&&i[i.length-1]||i.pop();for(var r=e.replace(/^\//,"").split("/"),a=0;a<r.length;a++){var s=r[a];".."===s?i.pop():"."!==s&&i.push(s)}return""!==i[0]&&i.unshift(""),i.join("/")}function tr(e){return e.replace(/\/\//g,"/")}var nr=Array.isArray||function(e){return"[object Array]"==Object.prototype.toString.call(e)},or=wr,ir=cr,rr=function(e,t){return dr(cr(e,t),t)},ar=dr,sr=gr,lr=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function cr(e,t){for(var n,o=[],i=0,r=0,a="",s=t&&t.delimiter||"/";null!=(n=lr.exec(e));){var l=n[0],c=n[1],u=n.index;if(a+=e.slice(r,u),r=u+l.length,c)a+=c[1];else{var d=e[r],h=n[2],f=n[3],p=n[4],m=n[5],g=n[6],w=n[7];a&&(o.push(a),a="");var v=null!=h&&null!=d&&d!==h,y="+"===g||"*"===g,b="?"===g||"*"===g,k=n[2]||s,x=p||m;o.push({name:f||i++,prefix:h||"",delimiter:k,optional:b,repeat:y,partial:v,asterisk:!!w,pattern:x?fr(x):w?".*":"[^"+hr(k)+"]+?"})}}return r<e.length&&(a+=e.substr(r)),a&&o.push(a),o}function ur(e){return encodeURI(e).replace(/[\/?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()}))}function dr(e,t){for(var n=new Array(e.length),o=0;o<e.length;o++)"object"==typeof e[o]&&(n[o]=new RegExp("^(?:"+e[o].pattern+")$",mr(t)));return function(t,o){for(var i="",r=t||{},a=(o||{}).pretty?ur:encodeURIComponent,s=0;s<e.length;s++){var l=e[s];if("string"!=typeof l){var c,u=r[l.name];if(null==u){if(l.optional){l.partial&&(i+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(nr(u)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(u)+"`");if(0===u.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var d=0;d<u.length;d++){if(c=a(u[d]),!n[s].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");i+=(0===d?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(u).replace(/[?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()})):a(u),!n[s].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');i+=l.prefix+c}}else i+=l}return i}}function hr(e){return e.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function fr(e){return e.replace(/([=!:$\/()])/g,"\\$1")}function pr(e,t){return e.keys=t,e}function mr(e){return e&&e.sensitive?"":"i"}function gr(e,t,n){nr(t)||(n=t||n,t=[]);for(var o=(n=n||{}).strict,i=!1!==n.end,r="",a=0;a<e.length;a++){var s=e[a];if("string"==typeof s)r+=hr(s);else{var l=hr(s.prefix),c="(?:"+s.pattern+")";t.push(s),s.repeat&&(c+="(?:"+l+c+")*"),r+=c=s.optional?s.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var u=hr(n.delimiter||"/"),d=r.slice(-u.length)===u;return o||(r=(d?r.slice(0,-u.length):r)+"(?:"+u+"(?=$))?"),r+=i?"$":o&&d?"":"(?="+u+"|$)",pr(new RegExp("^"+r,mr(n)),t)}function wr(e,t,n){return nr(t)||(n=t||n,t=[]),n=n||{},e instanceof RegExp?function(e,t){var n=e.source.match(/\((?!\?)/g);if(n)for(var o=0;o<n.length;o++)t.push({name:o,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return pr(e,t)}(e,t):nr(e)?function(e,t,n){for(var o=[],i=0;i<e.length;i++)o.push(wr(e[i],t,n).source);return pr(new RegExp("(?:"+o.join("|")+")",mr(n)),t)}(e,t,n):function(e,t,n){return gr(cr(e,n),t,n)}(e,t,n)}or.parse=ir,or.compile=rr,or.tokensToFunction=ar,or.tokensToRegExp=sr;var vr=Object.create(null);function yr(e,t,n){t=t||{};try{var o=vr[e]||(vr[e]=or.compile(e));return"string"==typeof t.pathMatch&&(t[0]=t.pathMatch),o(t,{pretty:!0})}catch(e){return""}finally{delete t[0]}}function br(e,t,n,o){var i="string"==typeof e?{path:e}:e;if(i._normalized)return i;if(i.name){var r=(i=qi({},e)).params;return r&&"object"==typeof r&&(i.params=qi({},r)),i}if(!i.path&&i.params&&t){(i=qi({},i))._normalized=!0;var a=qi(qi({},t.params),i.params);if(t.name)i.name=t.name,i.params=a;else if(t.matched.length){var s=t.matched[t.matched.length-1].path;i.path=yr(s,a,t.path)}else 0;return i}var l=function(e){var t="",n="",o=e.indexOf("#");o>=0&&(t=e.slice(o),e=e.slice(0,o));var i=e.indexOf("?");return i>=0&&(n=e.slice(i+1),e=e.slice(0,i)),{path:e,query:n,hash:t}}(i.path||""),c=t&&t.path||"/",u=l.path?er(l.path,c,n||i.append):c,d=function(e,t,n){void 0===t&&(t={});var o,i=n||Hi;try{o=i(e||"")}catch(e){o={}}for(var r in t){var a=t[r];o[r]=Array.isArray(a)?a.map(zi):zi(a)}return o}(l.query,i.query,o&&o.options.parseQuery),h=i.hash||l.hash;return h&&"#"!==h.charAt(0)&&(h="#"+h),{_normalized:!0,path:u,query:d,hash:h}}var kr,xr=function(){},Sr={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},exact:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(e){var t=this,n=this.$router,o=this.$route,i=n.resolve(this.to,o,this.append),r=i.location,a=i.route,s=i.href,l={},c=n.options.linkActiveClass,u=n.options.linkExactActiveClass,d=null==c?"router-link-active":c,h=null==u?"router-link-exact-active":u,f=null==this.activeClass?d:this.activeClass,p=null==this.exactActiveClass?h:this.exactActiveClass,m=a.redirectedFrom?Gi(null,br(a.redirectedFrom),null,n):a;l[p]=Ki(o,m),l[f]=this.exact?l[p]:function(e,t){return 0===e.path.replace(Mi,"/").indexOf(t.path.replace(Mi,"/"))&&(!t.hash||e.hash===t.hash)&&function(e,t){for(var n in t)if(!(n in e))return!1;return!0}(e.query,t.query)}(o,m);var g=l[p]?this.ariaCurrentValue:null,w=function(e){Tr(e)&&(t.replace?n.replace(r,xr):n.push(r,xr))},v={click:Tr};Array.isArray(this.event)?this.event.forEach((function(e){v[e]=w})):v[this.event]=w;var y={class:l},b=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:a,navigate:w,isActive:l[f],isExactActive:l[p]});if(b){if(1===b.length)return b[0];if(b.length>1||!b.length)return 0===b.length?e():e("span",{},b)}if("a"===this.tag)y.on=v,y.attrs={href:s,"aria-current":g};else{var k=function e(t){var n;if(t)for(var o=0;o<t.length;o++){if("a"===(n=t[o]).tag)return n;if(n.children&&(n=e(n.children)))return n}}(this.$slots.default);if(k){k.isStatic=!1;var x=k.data=qi({},k.data);for(var S in x.on=x.on||{},x.on){var T=x.on[S];S in v&&(x.on[S]=Array.isArray(T)?T:[T])}for(var C in v)C in x.on?x.on[C].push(v[C]):x.on[C]=w;var I=k.data.attrs=qi({},k.data.attrs);I.href=s,I["aria-current"]=g}else y.on=v}return e(this.tag,y,this.$slots.default)}};function Tr(e){if(!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey||e.defaultPrevented||void 0!==e.button&&0!==e.button)){if(e.currentTarget&&e.currentTarget.getAttribute){var t=e.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(t))return}return e.preventDefault&&e.preventDefault(),!0}}var Cr="undefined"!=typeof window;function Ir(e,t,n,o){var i=t||[],r=n||Object.create(null),a=o||Object.create(null);e.forEach((function(e){!function e(t,n,o,i,r,a){var s=i.path,l=i.name;0;var c=i.pathToRegexpOptions||{},u=function(e,t,n){n||(e=e.replace(/\/$/,""));if("/"===e[0])return e;if(null==t)return e;return tr(t.path+"/"+e)}(s,r,c.strict);"boolean"==typeof i.caseSensitive&&(c.sensitive=i.caseSensitive);var d={path:u,regex:_r(u,c),components:i.components||{default:i.component},instances:{},enteredCbs:{},name:l,parent:r,matchAs:a,redirect:i.redirect,beforeEnter:i.beforeEnter,meta:i.meta||{},props:null==i.props?{}:i.components?i.props:{default:i.props}};i.children&&i.children.forEach((function(i){var r=a?tr(a+"/"+i.path):void 0;e(t,n,o,i,d,r)}));n[d.path]||(t.push(d.path),n[d.path]=d);if(void 0!==i.alias)for(var h=Array.isArray(i.alias)?i.alias:[i.alias],f=0;f<h.length;++f){0;var p={path:h[f],children:i.children};e(t,n,o,p,r,d.path||"/")}l&&(o[l]||(o[l]=d))}(i,r,a,e)}));for(var s=0,l=i.length;s<l;s++)"*"===i[s]&&(i.push(i.splice(s,1)[0]),l--,s--);return{pathList:i,pathMap:r,nameMap:a}}function _r(e,t){return or(e,[],t)}function Ar(e,t){var n=Ir(e),o=n.pathList,i=n.pathMap,r=n.nameMap;function a(e,n,a){var s=br(e,n,!1,t),c=s.name;if(c){var u=r[c];if(!u)return l(null,s);var d=u.regex.keys.filter((function(e){return!e.optional})).map((function(e){return e.name}));if("object"!=typeof s.params&&(s.params={}),n&&"object"==typeof n.params)for(var h in n.params)!(h in s.params)&&d.indexOf(h)>-1&&(s.params[h]=n.params[h]);return s.path=yr(u.path,s.params),l(u,s,a)}if(s.path){s.params={};for(var f=0;f<o.length;f++){var p=o[f],m=i[p];if(Er(m.regex,s.path,s.params))return l(m,s,a)}}return l(null,s)}function s(e,n){var o=e.redirect,i="function"==typeof o?o(Gi(e,n,null,t)):o;if("string"==typeof i&&(i={path:i}),!i||"object"!=typeof i)return l(null,n);var s=i,c=s.name,u=s.path,d=n.query,h=n.hash,f=n.params;if(d=s.hasOwnProperty("query")?s.query:d,h=s.hasOwnProperty("hash")?s.hash:h,f=s.hasOwnProperty("params")?s.params:f,c){r[c];return a({_normalized:!0,name:c,query:d,hash:h,params:f},void 0,n)}if(u){var p=function(e,t){return er(e,t.parent?t.parent.path:"/",!0)}(u,e);return a({_normalized:!0,path:yr(p,f),query:d,hash:h},void 0,n)}return l(null,n)}function l(e,n,o){return e&&e.redirect?s(e,o||n):e&&e.matchAs?function(e,t,n){var o=a({_normalized:!0,path:yr(n,t.params)});if(o){var i=o.matched,r=i[i.length-1];return t.params=o.params,l(r,t)}return l(null,t)}(0,n,e.matchAs):Gi(e,n,o,t)}return{match:a,addRoutes:function(e){Ir(e,o,i,r)}}}function Er(e,t,n){var o=t.match(e);if(!o)return!1;if(!n)return!0;for(var i=1,r=o.length;i<r;++i){var a=e.keys[i-1];a&&(n[a.name||"pathMatch"]="string"==typeof o[i]?Fi(o[i]):o[i])}return!0}var Or=Cr&&window.performance&&window.performance.now?window.performance:Date;function jr(){return Or.now().toFixed(3)}var Pr=jr();function Wr(){return Pr}function qr(e){return Pr=e}var Dr=Object.create(null);function Nr(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var e=window.location.protocol+"//"+window.location.host,t=window.location.href.replace(e,""),n=qi({},window.history.state);return n.key=Wr(),window.history.replaceState(n,"",t),window.addEventListener("popstate",Fr),function(){window.removeEventListener("popstate",Fr)}}function Rr(e,t,n,o){if(e.app){var i=e.options.scrollBehavior;i&&e.app.$nextTick((function(){var r=function(){var e=Wr();if(e)return Dr[e]}(),a=i.call(e,t,n,o?r:null);a&&("function"==typeof a.then?a.then((function(e){Gr(e,r)})).catch((function(e){0})):Gr(a,r))}))}}function Lr(){var e=Wr();e&&(Dr[e]={x:window.pageXOffset,y:window.pageYOffset})}function Fr(e){Lr(),e.state&&e.state.key&&qr(e.state.key)}function zr(e){return $r(e.x)||$r(e.y)}function Hr(e){return{x:$r(e.x)?e.x:window.pageXOffset,y:$r(e.y)?e.y:window.pageYOffset}}function $r(e){return"number"==typeof e}var Mr=/^#\d/;function Gr(e,t){var n,o="object"==typeof e;if(o&&"string"==typeof e.selector){var i=Mr.test(e.selector)?document.getElementById(e.selector.slice(1)):document.querySelector(e.selector);if(i){var r=e.offset&&"object"==typeof e.offset?e.offset:{};t=function(e,t){var n=document.documentElement.getBoundingClientRect(),o=e.getBoundingClientRect();return{x:o.left-n.left-t.x,y:o.top-n.top-t.y}}(i,r={x:$r((n=r).x)?n.x:0,y:$r(n.y)?n.y:0})}else zr(e)&&(t=Hr(e))}else o&&zr(e)&&(t=Hr(e));t&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:t.x,top:t.y,behavior:e.behavior}):window.scrollTo(t.x,t.y))}var Ur,Br=Cr&&((-1===(Ur=window.navigator.userAgent).indexOf("Android 2.")&&-1===Ur.indexOf("Android 4.0")||-1===Ur.indexOf("Mobile Safari")||-1!==Ur.indexOf("Chrome")||-1!==Ur.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function Vr(e,t){Lr();var n=window.history;try{if(t){var o=qi({},n.state);o.key=Wr(),n.replaceState(o,"",e)}else n.pushState({key:qr(jr())},"",e)}catch(n){window.location[t?"replace":"assign"](e)}}function Yr(e){Vr(e,!0)}function Kr(e,t,n){var o=function(i){i>=e.length?n():e[i]?t(e[i],(function(){o(i+1)})):o(i+1)};o(0)}var Qr={redirected:2,aborted:4,cancelled:8,duplicated:16};function Jr(e,t){return Zr(e,t,Qr.redirected,'Redirected when going from "'+e.fullPath+'" to "'+function(e){if("string"==typeof e)return e;if("path"in e)return e.path;var t={};return ea.forEach((function(n){n in e&&(t[n]=e[n])})),JSON.stringify(t,null,2)}(t)+'" via a navigation guard.')}function Xr(e,t){return Zr(e,t,Qr.cancelled,'Navigation cancelled from "'+e.fullPath+'" to "'+t.fullPath+'" with a new navigation.')}function Zr(e,t,n,o){var i=new Error(o);return i._isRouter=!0,i.from=e,i.to=t,i.type=n,i}var ea=["params","query","hash"];function ta(e){return Object.prototype.toString.call(e).indexOf("Error")>-1}function na(e,t){return ta(e)&&e._isRouter&&(null==t||e.type===t)}function oa(e){return function(t,n,o){var i=!1,r=0,a=null;ia(e,(function(e,t,n,s){if("function"==typeof e&&void 0===e.cid){i=!0,r++;var l,c=sa((function(t){var i;((i=t).__esModule||aa&&"Module"===i[Symbol.toStringTag])&&(t=t.default),e.resolved="function"==typeof t?t:kr.extend(t),n.components[s]=t,--r<=0&&o()})),u=sa((function(e){var t="Failed to resolve async component "+s+": "+e;a||(a=ta(e)?e:new Error(t),o(a))}));try{l=e(c,u)}catch(e){u(e)}if(l)if("function"==typeof l.then)l.then(c,u);else{var d=l.component;d&&"function"==typeof d.then&&d.then(c,u)}}})),i||o()}}function ia(e,t){return ra(e.map((function(e){return Object.keys(e.components).map((function(n){return t(e.components[n],e.instances[n],e,n)}))})))}function ra(e){return Array.prototype.concat.apply([],e)}var aa="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function sa(e){var t=!1;return function(){for(var n=[],o=arguments.length;o--;)n[o]=arguments[o];if(!t)return t=!0,e.apply(this,n)}}var la=function(e,t){this.router=e,this.base=function(e){if(!e)if(Cr){var t=document.querySelector("base");e=(e=t&&t.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else e="/";"/"!==e.charAt(0)&&(e="/"+e);return e.replace(/\/$/,"")}(t),this.current=Bi,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function ca(e,t,n,o){var i=ia(e,(function(e,o,i,r){var a=function(e,t){"function"!=typeof e&&(e=kr.extend(e));return e.options[t]}(e,t);if(a)return Array.isArray(a)?a.map((function(e){return n(e,o,i,r)})):n(a,o,i,r)}));return ra(o?i.reverse():i)}function ua(e,t){if(t)return function(){return e.apply(t,arguments)}}la.prototype.listen=function(e){this.cb=e},la.prototype.onReady=function(e,t){this.ready?e():(this.readyCbs.push(e),t&&this.readyErrorCbs.push(t))},la.prototype.onError=function(e){this.errorCbs.push(e)},la.prototype.transitionTo=function(e,t,n){var o,i=this;try{o=this.router.match(e,this.current)}catch(e){throw this.errorCbs.forEach((function(t){t(e)})),e}var r=this.current;this.confirmTransition(o,(function(){i.updateRoute(o),t&&t(o),i.ensureURL(),i.router.afterHooks.forEach((function(e){e&&e(o,r)})),i.ready||(i.ready=!0,i.readyCbs.forEach((function(e){e(o)})))}),(function(e){n&&n(e),e&&!i.ready&&(na(e,Qr.redirected)&&r===Bi||(i.ready=!0,i.readyErrorCbs.forEach((function(t){t(e)}))))}))},la.prototype.confirmTransition=function(e,t,n){var o=this,i=this.current;this.pending=e;var r,a,s=function(e){!na(e)&&ta(e)&&(o.errorCbs.length?o.errorCbs.forEach((function(t){t(e)})):console.error(e)),n&&n(e)},l=e.matched.length-1,c=i.matched.length-1;if(Ki(e,i)&&l===c&&e.matched[l]===i.matched[c])return this.ensureURL(),s(((a=Zr(r=i,e,Qr.duplicated,'Avoided redundant navigation to current location: "'+r.fullPath+'".')).name="NavigationDuplicated",a));var u=function(e,t){var n,o=Math.max(e.length,t.length);for(n=0;n<o&&e[n]===t[n];n++);return{updated:t.slice(0,n),activated:t.slice(n),deactivated:e.slice(n)}}(this.current.matched,e.matched),d=u.updated,h=u.deactivated,f=u.activated,p=[].concat(function(e){return ca(e,"beforeRouteLeave",ua,!0)}(h),this.router.beforeHooks,function(e){return ca(e,"beforeRouteUpdate",ua)}(d),f.map((function(e){return e.beforeEnter})),oa(f)),m=function(t,n){if(o.pending!==e)return s(Xr(i,e));try{t(e,i,(function(t){!1===t?(o.ensureURL(!0),s(function(e,t){return Zr(e,t,Qr.aborted,'Navigation aborted from "'+e.fullPath+'" to "'+t.fullPath+'" via a navigation guard.')}(i,e))):ta(t)?(o.ensureURL(!0),s(t)):"string"==typeof t||"object"==typeof t&&("string"==typeof t.path||"string"==typeof t.name)?(s(Jr(i,e)),"object"==typeof t&&t.replace?o.replace(t):o.push(t)):n(t)}))}catch(e){s(e)}};Kr(p,m,(function(){Kr(function(e){return ca(e,"beforeRouteEnter",(function(e,t,n,o){return function(e,t,n){return function(o,i,r){return e(o,i,(function(e){"function"==typeof e&&(t.enteredCbs[n]||(t.enteredCbs[n]=[]),t.enteredCbs[n].push(e)),r(e)}))}}(e,n,o)}))}(f).concat(o.router.resolveHooks),m,(function(){if(o.pending!==e)return s(Xr(i,e));o.pending=null,t(e),o.router.app&&o.router.app.$nextTick((function(){Ji(e)}))}))}))},la.prototype.updateRoute=function(e){this.current=e,this.cb&&this.cb(e)},la.prototype.setupListeners=function(){},la.prototype.teardown=function(){this.listeners.forEach((function(e){e()})),this.listeners=[],this.current=Bi,this.pending=null};var da=function(e){function t(t,n){e.call(this,t,n),this._startLocation=ha(this.base)}return e&&(t.__proto__=e),t.prototype=Object.create(e&&e.prototype),t.prototype.constructor=t,t.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var t=this.router,n=t.options.scrollBehavior,o=Br&&n;o&&this.listeners.push(Nr());var i=function(){var n=e.current,i=ha(e.base);e.current===Bi&&i===e._startLocation||e.transitionTo(i,(function(e){o&&Rr(t,e,n,!0)}))};window.addEventListener("popstate",i),this.listeners.push((function(){window.removeEventListener("popstate",i)}))}},t.prototype.go=function(e){window.history.go(e)},t.prototype.push=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){Vr(tr(o.base+e.fullPath)),Rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.replace=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){Yr(tr(o.base+e.fullPath)),Rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.ensureURL=function(e){if(ha(this.base)!==this.current.fullPath){var t=tr(this.base+this.current.fullPath);e?Vr(t):Yr(t)}},t.prototype.getCurrentLocation=function(){return ha(this.base)},t}(la);function ha(e){var t=window.location.pathname;return e&&0===t.toLowerCase().indexOf(e.toLowerCase())&&(t=t.slice(e.length)),(t||"/")+window.location.search+window.location.hash}var fa=function(e){function t(t,n,o){e.call(this,t,n),o&&function(e){var t=ha(e);if(!/^\/#/.test(t))return window.location.replace(tr(e+"/#"+t)),!0}(this.base)||pa()}return e&&(t.__proto__=e),t.prototype=Object.create(e&&e.prototype),t.prototype.constructor=t,t.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var t=this.router.options.scrollBehavior,n=Br&&t;n&&this.listeners.push(Nr());var o=function(){var t=e.current;pa()&&e.transitionTo(ma(),(function(o){n&&Rr(e.router,o,t,!0),Br||va(o.fullPath)}))},i=Br?"popstate":"hashchange";window.addEventListener(i,o),this.listeners.push((function(){window.removeEventListener(i,o)}))}},t.prototype.push=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){wa(e.fullPath),Rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.replace=function(e,t,n){var o=this,i=this.current;this.transitionTo(e,(function(e){va(e.fullPath),Rr(o.router,e,i,!1),t&&t(e)}),n)},t.prototype.go=function(e){window.history.go(e)},t.prototype.ensureURL=function(e){var t=this.current.fullPath;ma()!==t&&(e?wa(t):va(t))},t.prototype.getCurrentLocation=function(){return ma()},t}(la);function pa(){var e=ma();return"/"===e.charAt(0)||(va("/"+e),!1)}function ma(){var e=window.location.href,t=e.indexOf("#");return t<0?"":e=e.slice(t+1)}function ga(e){var t=window.location.href,n=t.indexOf("#");return(n>=0?t.slice(0,n):t)+"#"+e}function wa(e){Br?Vr(ga(e)):window.location.hash=e}function va(e){Br?Yr(ga(e)):window.location.replace(ga(e))}var ya=function(e){function t(t,n){e.call(this,t,n),this.stack=[],this.index=-1}return e&&(t.__proto__=e),t.prototype=Object.create(e&&e.prototype),t.prototype.constructor=t,t.prototype.push=function(e,t,n){var o=this;this.transitionTo(e,(function(e){o.stack=o.stack.slice(0,o.index+1).concat(e),o.index++,t&&t(e)}),n)},t.prototype.replace=function(e,t,n){var o=this;this.transitionTo(e,(function(e){o.stack=o.stack.slice(0,o.index).concat(e),t&&t(e)}),n)},t.prototype.go=function(e){var t=this,n=this.index+e;if(!(n<0||n>=this.stack.length)){var o=this.stack[n];this.confirmTransition(o,(function(){var e=t.current;t.index=n,t.updateRoute(o),t.router.afterHooks.forEach((function(t){t&&t(o,e)}))}),(function(e){na(e,Qr.duplicated)&&(t.index=n)}))}},t.prototype.getCurrentLocation=function(){var e=this.stack[this.stack.length-1];return e?e.fullPath:"/"},t.prototype.ensureURL=function(){},t}(la),ba=function(e){void 0===e&&(e={}),this.app=null,this.apps=[],this.options=e,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Ar(e.routes||[],this);var t=e.mode||"hash";switch(this.fallback="history"===t&&!Br&&!1!==e.fallback,this.fallback&&(t="hash"),Cr||(t="abstract"),this.mode=t,t){case"history":this.history=new da(this,e.base);break;case"hash":this.history=new fa(this,e.base,this.fallback);break;case"abstract":this.history=new ya(this,e.base);break;default:0}},ka={currentRoute:{configurable:!0}};function xa(e,t){return e.push(t),function(){var n=e.indexOf(t);n>-1&&e.splice(n,1)}}ba.prototype.match=function(e,t,n){return this.matcher.match(e,t,n)},ka.currentRoute.get=function(){return this.history&&this.history.current},ba.prototype.init=function(e){var t=this;if(this.apps.push(e),e.$once("hook:destroyed",(function(){var n=t.apps.indexOf(e);n>-1&&t.apps.splice(n,1),t.app===e&&(t.app=t.apps[0]||null),t.app||t.history.teardown()})),!this.app){this.app=e;var n=this.history;if(n instanceof da||n instanceof fa){var o=function(e){n.setupListeners(),function(e){var o=n.current,i=t.options.scrollBehavior;Br&&i&&"fullPath"in e&&Rr(t,e,o,!1)}(e)};n.transitionTo(n.getCurrentLocation(),o,o)}n.listen((function(e){t.apps.forEach((function(t){t._route=e}))}))}},ba.prototype.beforeEach=function(e){return xa(this.beforeHooks,e)},ba.prototype.beforeResolve=function(e){return xa(this.resolveHooks,e)},ba.prototype.afterEach=function(e){return xa(this.afterHooks,e)},ba.prototype.onReady=function(e,t){this.history.onReady(e,t)},ba.prototype.onError=function(e){this.history.onError(e)},ba.prototype.push=function(e,t,n){var o=this;if(!t&&!n&&"undefined"!=typeof Promise)return new Promise((function(t,n){o.history.push(e,t,n)}));this.history.push(e,t,n)},ba.prototype.replace=function(e,t,n){var o=this;if(!t&&!n&&"undefined"!=typeof Promise)return new Promise((function(t,n){o.history.replace(e,t,n)}));this.history.replace(e,t,n)},ba.prototype.go=function(e){this.history.go(e)},ba.prototype.back=function(){this.go(-1)},ba.prototype.forward=function(){this.go(1)},ba.prototype.getMatchedComponents=function(e){var t=e?e.matched?e:this.resolve(e).route:this.currentRoute;return t?[].concat.apply([],t.matched.map((function(e){return Object.keys(e.components).map((function(t){return e.components[t]}))}))):[]},ba.prototype.resolve=function(e,t,n){var o=br(e,t=t||this.history.current,n,this),i=this.match(o,t),r=i.redirectedFrom||i.fullPath;return{location:o,route:i,href:function(e,t,n){var o="hash"===n?"#"+t:t;return e?tr(e+"/"+o):o}(this.history.base,r,this.mode),normalizedTo:o,resolved:i}},ba.prototype.addRoutes=function(e){this.matcher.addRoutes(e),this.history.current!==Bi&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(ba.prototype,ka),ba.install=function e(t){if(!e.installed||kr!==t){e.installed=!0,kr=t;var n=function(e){return void 0!==e},o=function(e,t){var o=e.$options._parentVnode;n(o)&&n(o=o.data)&&n(o=o.registerRouteInstance)&&o(e,t)};t.mixin({beforeCreate:function(){n(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),t.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,o(this,this)},destroyed:function(){o(this)}}),Object.defineProperty(t.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(t.prototype,"$route",{get:function(){return this._routerRoot._route}}),t.component("RouterView",Xi),t.component("RouterLink",Sr);var i=t.config.optionMergeStrategies;i.beforeRouteEnter=i.beforeRouteLeave=i.beforeRouteUpdate=i.created}},ba.version="3.4.9",ba.isNavigationFailure=na,ba.NavigationFailureType=Qr,Cr&&window.Vue&&window.Vue.use(ba);var Sa=ba;n(51),n(211),n(213),n(148),n(149),n(73),n(215),n(52);function Ta(e){e.locales&&Object.keys(e.locales).forEach((function(t){e.locales[t].path=t})),Object.freeze(e)}n(193),n(152),n(23),n(195),n(46),n(42),n(63),n(92);function Ca(e){return(Ca="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e})(e)}var Ia=n(44),_a={NotFound:function(){return n.e(7).then(n.bind(null,388))},Layout:function(){return Promise.all([n.e(0),n.e(2)]).then(n.bind(null,387))}},Aa={"v-1c019fb2":function(){return n.e(9).then(n.bind(null,393))},"v-512ef402":function(){return n.e(10).then(n.bind(null,394))},"v-863e8124":function(){return n.e(11).then(n.bind(null,395))},"v-6f803ea8":function(){return n.e(12).then(n.bind(null,396))},"v-4d735b42":function(){return n.e(13).then(n.bind(null,397))},"v-7d3ade22":function(){return n.e(14).then(n.bind(null,398))},"v-03657f14":function(){return n.e(15).then(n.bind(null,399))},"v-0853f13c":function(){return n.e(16).then(n.bind(null,400))},"v-2d694702":function(){return n.e(17).then(n.bind(null,401))},"v-28dd3202":function(){return n.e(18).then(n.bind(null,402))},"v-2380d6f2":function(){return n.e(19).then(n.bind(null,403))},"v-1d6d6d3a":function(){return n.e(20).then(n.bind(null,404))},"v-ef9d367c":function(){return n.e(21).then(n.bind(null,405))},"v-42d0cb0a":function(){return n.e(22).then(n.bind(null,406))},"v-68a1c262":function(){return n.e(23).then(n.bind(null,407))},"v-3a29e1d0":function(){return n.e(24).then(n.bind(null,408))},"v-2cb6c482":function(){return n.e(25).then(n.bind(null,409))},"v-55ad5442":function(){return n.e(26).then(n.bind(null,410))},"v-b430d54c":function(){return n.e(27).then(n.bind(null,411))},"v-6695c940":function(){return n.e(28).then(n.bind(null,412))},"v-3c8e9720":function(){return n.e(29).then(n.bind(null,413))},"v-d2d99830":function(){return n.e(30).then(n.bind(null,414))},"v-750c7ee2":function(){return n.e(31).then(n.bind(null,415))},"v-be41a8c6":function(){return n.e(32).then(n.bind(null,416))},"v-546411c2":function(){return n.e(33).then(n.bind(null,417))},"v-0d0c6d7b":function(){return n.e(34).then(n.bind(null,418))},"v-745671b4":function(){return n.e(35).then(n.bind(null,419))},"v-3d11f802":function(){return n.e(36).then(n.bind(null,420))},"v-264670c2":function(){return n.e(37).then(n.bind(null,421))},"v-11997e3c":function(){return n.e(38).then(n.bind(null,422))},"v-5a20c23c":function(){return n.e(39).then(n.bind(null,423))},"v-056557ea":function(){return n.e(40).then(n.bind(null,424))},"v-ee26987c":function(){return n.e(41).then(n.bind(null,425))},"v-5951033c":function(){return n.e(42).then(n.bind(null,426))},"v-e9a63714":function(){return n.e(44).then(n.bind(null,427))},"v-d91dcabc":function(){return n.e(45).then(n.bind(null,428))},"v-241aa182":function(){return n.e(46).then(n.bind(null,429))},"v-7109c462":function(){return n.e(47).then(n.bind(null,430))},"v-30ee6212":function(){return n.e(48).then(n.bind(null,431))},"v-63bf2e6c":function(){return n.e(49).then(n.bind(null,432))},"v-651b4e0a":function(){return n.e(43).then(n.bind(null,433))},"v-103bbcbc":function(){return n.e(50).then(n.bind(null,434))},"v-65ea467c":function(){return n.e(51).then(n.bind(null,435))},"v-b60e670c":function(){return n.e(52).then(n.bind(null,436))},"v-3c7b0dd4":function(){return n.e(53).then(n.bind(null,437))},"v-a558de54":function(){return n.e(54).then(n.bind(null,438))},"v-5b7bae8a":function(){return n.e(55).then(n.bind(null,439))},"v-722c1fc2":function(){return n.e(56).then(n.bind(null,440))},"v-957246a8":function(){return n.e(57).then(n.bind(null,441))},"v-389752bc":function(){return n.e(58).then(n.bind(null,442))},"v-0c11d262":function(){return n.e(59).then(n.bind(null,443))},"v-2d3e7cdb":function(){return n.e(61).then(n.bind(null,444))},"v-a139e6dc":function(){return n.e(60).then(n.bind(null,445))},"v-2dfd6d7b":function(){return n.e(62).then(n.bind(null,446))},"v-884a5d48":function(){return n.e(63).then(n.bind(null,447))},"v-0747733b":function(){return n.e(64).then(n.bind(null,448))},"v-54cca634":function(){return n.e(65).then(n.bind(null,449))},"v-0615a98a":function(){return n.e(66).then(n.bind(null,450))}};function Ea(e){var t=Object.create(null);return function(n){return t[n]||(t[n]=e(n))}}var Oa=/-(\w)/g,ja=Ea((function(e){return e.replace(Oa,(function(e,t){return t?t.toUpperCase():""}))})),Pa=/\B([A-Z])/g,Wa=Ea((function(e){return e.replace(Pa,"-$1").toLowerCase()})),qa=Ea((function(e){return e.charAt(0).toUpperCase()+e.slice(1)}));function Da(e,t){if(t)return e(t)?e(t):t.includes("-")?e(qa(ja(t))):e(qa(t))||e(Wa(t))}var Na=Object.assign({},_a,Aa),Ra=function(e){return Na[e]},La=function(e){return Aa[e]},Fa=function(e){return _a[e]},za=function(e){return Wi.component(e)};function Ha(e){return Da(La,e)}function $a(e){return Da(Fa,e)}function Ma(e){return Da(Ra,e)}function Ga(e){return Da(za,e)}function Ua(){for(var e=arguments.length,t=new Array(e),n=0;n<e;n++)t[n]=arguments[n];return Promise.all(t.filter((function(e){return e})).map(function(){var e=Object(o.a)(regeneratorRuntime.mark((function e(t){var n;return regeneratorRuntime.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:if(Ga(t)||!Ma(t)){e.next=5;break}return e.next=3,Ma(t)();case 3:n=e.sent,Wi.component(t,n.default);case 5:case"end":return e.stop()}}),e)})));return function(t){return e.apply(this,arguments)}}()))}function Ba(e,t){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[e]=t)}n(53),n(74);var Va=n(103),Ya=n(185),Ka=n.n(Ya),Qa={created:function(){if(this.siteMeta=this.$site.headTags.filter((function(e){return"meta"===Object(Va.a)(e,1)[0]})).map((function(e){var t=Object(Va.a)(e,2);t[0];return t[1]})),this.$ssrContext){var e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(t=e)?t.map((function(e){var t="<meta";return Object.keys(e).forEach((function(n){t+=" ".concat(n,'="').concat(e[n],'"')})),t+">"})).join("\n    "):"",this.$ssrContext.canonicalLink=Xa(this.$canonicalUrl)}var t},mounted:function(){this.currentMetaTags=Object(Ia.a)(document.querySelectorAll("meta")),this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta:function(){document.title=this.$title,document.documentElement.lang=this.$lang;var e=this.getMergedMetaTags();this.currentMetaTags=Za(e,this.currentMetaTags)},getMergedMetaTags:function(){var e=this.$page.frontmatter.meta||[];return Ka()([{name:"description",content:this.$description}],e,this.siteMeta,es)},updateCanonicalLink:function(){Ja(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",Xa(this.$canonicalUrl))}},watch:{$page:function(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy:function(){Za(null,this.currentMetaTags),Ja()}};function Ja(){var e=document.querySelector("link[rel='canonical']");e&&e.remove()}function Xa(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"";return e?'<link href="'.concat(e,'" rel="canonical" />'):""}function Za(e,t){if(t&&Object(Ia.a)(t).filter((function(e){return e.parentNode===document.head})).forEach((function(e){return document.head.removeChild(e)})),e)return e.map((function(e){var t=document.createElement("meta");return Object.keys(e).forEach((function(n){t.setAttribute(n,e[n])})),document.head.appendChild(t),t}))}function es(e){for(var t=0,n=["name","property","itemprop"];t<n.length;t++){var o=n[t];if(e.hasOwnProperty(o))return e[o]+o}return JSON.stringify(e)}n(186);var ts=n(70),ns=n.n(ts),os={mounted:function(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:ns()((function(){this.setActiveHash()}),300),setActiveHash:function(){for(var e=this,t=[].slice.call(document.querySelectorAll(".sidebar-link")),n=[].slice.call(document.querySelectorAll(".header-anchor")).filter((function(e){return t.some((function(t){return t.hash===e.hash}))})),o=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),i=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),r=window.innerHeight+o,a=0;a<n.length;a++){var s=n[a],l=n[a+1],c=0===a&&0===o||o>=s.parentElement.offsetTop+10&&(!l||o<l.parentElement.offsetTop-10),u=decodeURIComponent(this.$route.hash);if(c&&u!==decodeURIComponent(s.hash)){var d=s;if(r===i)for(var h=a+1;h<n.length;h++)if(u===decodeURIComponent(n[h].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(d.hash),(function(){e.$nextTick((function(){e.$vuepress.$set("disableScrollBehavior",!1)}))}))}}}},beforeDestroy:function(){window.removeEventListener("scroll",this.onScroll)}},is=(n(55),n(71)),rs=n.n(is),as={mounted:function(){var e=this;rs.a.configure({showSpinner:!1}),this.$router.beforeEach((function(e,t,n){e.path===t.path||Wi.component(e.name)||rs.a.start(),n()})),this.$router.afterEach((function(){rs.a.done(),e.isSidebarOpen=!1}))}},ss=(n(176),n(124)),ls=(n(198),{props:{parent:Object,code:String,options:{align:String,color:String,backgroundTransition:Boolean,backgroundColor:String,successText:String,staticIcon:Boolean}},data:function(){return{success:!1,originalBackground:null,originalTransition:null}},computed:{alignStyle:function(){var e={};return e[this.options.align]="7.5px",e},iconClass:function(){return this.options.staticIcon?"":"hover"}},mounted:function(){this.originalTransition=this.parent.style.transition,this.originalBackground=this.parent.style.background},beforeDestroy:function(){this.parent.style.transition=this.originalTransition,this.parent.style.background=this.originalBackground},methods:{hexToRgb:function(e){var t=/^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i.exec(e);return t?{r:parseInt(t[1],16),g:parseInt(t[2],16),b:parseInt(t[3],16)}:null},copyToClipboard:function(e){var t=this;if(navigator.clipboard)navigator.clipboard.writeText(this.code).then((function(){t.setSuccessTransitions()}),(function(){}));else{var n=document.createElement("textarea");document.body.appendChild(n),n.value=this.code,n.select(),document.execCommand("Copy"),n.remove(),this.setSuccessTransitions()}},setSuccessTransitions:function(){var e=this;if(clearTimeout(this.successTimeout),this.options.backgroundTransition){this.parent.style.transition="background 350ms";var t=this.hexToRgb(this.options.backgroundColor);this.parent.style.background="rgba(".concat(t.r,", ").concat(t.g,", ").concat(t.b,", 0.1)")}this.success=!0,this.successTimeout=setTimeout((function(){e.options.backgroundTransition&&(e.parent.style.background=e.originalBackground,e.parent.style.transition=e.originalTransition),e.success=!1}),500)}}}),cs=(n(314),n(8)),us=Object(cs.a)(ls,(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("div",{staticClass:"code-copy"},[n("svg",{class:e.iconClass,style:e.alignStyle,attrs:{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24"},on:{click:e.copyToClipboard}},[n("path",{attrs:{fill:"none",d:"M0 0h24v24H0z"}}),e._v(" "),n("path",{attrs:{fill:e.options.color,d:"M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm-1 4l6 6v10c0 1.1-.9 2-2 2H7.99C6.89 23 6 22.1 6 21l.01-14c0-1.1.89-2 1.99-2h7zm-1 7h5.5L14 6.5V12z"}})]),e._v(" "),n("span",{class:e.success?"success":"",style:e.alignStyle},[e._v("\n        "+e._s(e.options.successText)+"\n    ")])])}),[],!1,null,"49140617",null).exports,ds=(n(315),[Qa,os,as,{updated:function(){this.update()},methods:{update:function(){setTimeout((function(){document.querySelectorAll('div[class*="language-"] pre').forEach((function(e){if(!e.classList.contains("code-copy-added")){var t=new(Wi.extend(us));t.options=Object(ss.a)({},{align:"bottom",color:"#27b1ff",backgroundTransition:!0,backgroundColor:"#0075b8",successText:"Copied!",staticIcon:!1}),t.code=e.innerText,t.parent=e,t.$mount(),e.classList.add("code-copy-added"),e.appendChild(t.$el)}}))}),100)}}}]),hs={name:"GlobalLayout",computed:{layout:function(){var e=this.getLayout();return Ba("layout",e),Wi.component(e)}},methods:{getLayout:function(){if(this.$page.path){var e=this.$page.frontmatter.layout;return e&&(this.$vuepress.getLayoutAsyncComponent(e)||this.$vuepress.getVueComponent(e))?e:"Layout"}return"NotFound"}}},fs=Object(cs.a)(hs,(function(){var e=this.$createElement;return(this._self._c||e)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(e,t,n){var o;switch(t){case"components":e[t]||(e[t]={}),Object.assign(e[t],n);break;case"mixins":e[t]||(e[t]=[]),(o=e[t]).push.apply(o,Object(Ia.a)(n));break;default:throw new Error("Unknown option name.")}}(fs,"mixins",ds);var ps=[{name:"v-1c019fb2",path:"/GLOSSARY.html",component:fs,beforeEnter:function(e,t,n){Ua("default","v-1c019fb2").then(n)}},{name:"v-512ef402",path:"/docs/use-cases/periodic-execution/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-512ef402").then(n)}},{path:"/docs/use-cases/periodic-execution/index.html",redirect:"/docs/use-cases/periodic-execution/"},{path:"/docs/01-use-cases/01-periodic-execution.html",redirect:"/docs/use-cases/periodic-execution/"},{name:"v-863e8124",path:"/docs/use-cases/orchestration/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-863e8124").then(n)}},{path:"/docs/use-cases/orchestration/index.html",redirect:"/docs/use-cases/orchestration/"},{path:"/docs/01-use-cases/02-orchestration.html",redirect:"/docs/use-cases/orchestration/"},{name:"v-6f803ea8",path:"/docs/use-cases/polling/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-6f803ea8").then(n)}},{path:"/docs/use-cases/polling/index.html",redirect:"/docs/use-cases/polling/"},{path:"/docs/01-use-cases/03-polling.html",redirect:"/docs/use-cases/polling/"},{name:"v-4d735b42",path:"/docs/use-cases/event-driven/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-4d735b42").then(n)}},{path:"/docs/use-cases/event-driven/index.html",redirect:"/docs/use-cases/event-driven/"},{path:"/docs/01-use-cases/04-event-driven.html",redirect:"/docs/use-cases/event-driven/"},{name:"v-7d3ade22",path:"/docs/use-cases/partitioned-scan/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-7d3ade22").then(n)}},{path:"/docs/use-cases/partitioned-scan/index.html",redirect:"/docs/use-cases/partitioned-scan/"},{path:"/docs/01-use-cases/05-partitioned-scan.html",redirect:"/docs/use-cases/partitioned-scan/"},{name:"v-03657f14",path:"/docs/use-cases/batch-job/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-03657f14").then(n)}},{path:"/docs/use-cases/batch-job/index.html",redirect:"/docs/use-cases/batch-job/"},{path:"/docs/01-use-cases/06-batch-job.html",redirect:"/docs/use-cases/batch-job/"},{name:"v-0853f13c",path:"/docs/use-cases/provisioning/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-0853f13c").then(n)}},{path:"/docs/use-cases/provisioning/index.html",redirect:"/docs/use-cases/provisioning/"},{path:"/docs/01-use-cases/07-provisioning.html",redirect:"/docs/use-cases/provisioning/"},{name:"v-2d694702",path:"/docs/use-cases/deployment/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-2d694702").then(n)}},{path:"/docs/use-cases/deployment/index.html",redirect:"/docs/use-cases/deployment/"},{path:"/docs/01-use-cases/08-deployment.html",redirect:"/docs/use-cases/deployment/"},{name:"v-28dd3202",path:"/docs/use-cases/operational-management/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-28dd3202").then(n)}},{path:"/docs/use-cases/operational-management/index.html",redirect:"/docs/use-cases/operational-management/"},{path:"/docs/01-use-cases/09-operational-management.html",redirect:"/docs/use-cases/operational-management/"},{name:"v-2380d6f2",path:"/docs/use-cases/interactive/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-2380d6f2").then(n)}},{path:"/docs/use-cases/interactive/index.html",redirect:"/docs/use-cases/interactive/"},{path:"/docs/01-use-cases/10-interactive.html",redirect:"/docs/use-cases/interactive/"},{name:"v-1d6d6d3a",path:"/docs/use-cases/dsl/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-1d6d6d3a").then(n)}},{path:"/docs/use-cases/dsl/index.html",redirect:"/docs/use-cases/dsl/"},{path:"/docs/01-use-cases/11-dsl.html",redirect:"/docs/use-cases/dsl/"},{name:"v-ef9d367c",path:"/docs/use-cases/big-ml/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-ef9d367c").then(n)}},{path:"/docs/use-cases/big-ml/index.html",redirect:"/docs/use-cases/big-ml/"},{path:"/docs/01-use-cases/12-big-ml.html",redirect:"/docs/use-cases/big-ml/"},{name:"v-42d0cb0a",path:"/docs/use-cases/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-42d0cb0a").then(n)}},{path:"/docs/use-cases/index.html",redirect:"/docs/use-cases/"},{path:"/docs/01-use-cases/",redirect:"/docs/use-cases/"},{name:"v-68a1c262",path:"/docs/concepts/workflows/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-68a1c262").then(n)}},{path:"/docs/concepts/workflows/index.html",redirect:"/docs/concepts/workflows/"},{path:"/docs/02-concepts/01-workflows.html",redirect:"/docs/concepts/workflows/"},{name:"v-3a29e1d0",path:"/docs/concepts/activities/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-3a29e1d0").then(n)}},{path:"/docs/concepts/activities/index.html",redirect:"/docs/concepts/activities/"},{path:"/docs/02-concepts/02-activities.html",redirect:"/docs/concepts/activities/"},{name:"v-2cb6c482",path:"/docs/concepts/events/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-2cb6c482").then(n)}},{path:"/docs/concepts/events/index.html",redirect:"/docs/concepts/events/"},{path:"/docs/02-concepts/03-events.html",redirect:"/docs/concepts/events/"},{name:"v-55ad5442",path:"/docs/concepts/queries/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-55ad5442").then(n)}},{path:"/docs/concepts/queries/index.html",redirect:"/docs/concepts/queries/"},{path:"/docs/02-concepts/04-queries.html",redirect:"/docs/concepts/queries/"},{name:"v-b430d54c",path:"/docs/concepts/topology/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-b430d54c").then(n)}},{path:"/docs/concepts/topology/index.html",redirect:"/docs/concepts/topology/"},{path:"/docs/02-concepts/05-topology.html",redirect:"/docs/concepts/topology/"},{name:"v-6695c940",path:"/docs/concepts/task-lists/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-6695c940").then(n)}},{path:"/docs/concepts/task-lists/index.html",redirect:"/docs/concepts/task-lists/"},{path:"/docs/02-concepts/06-task-lists.html",redirect:"/docs/concepts/task-lists/"},{name:"v-3c8e9720",path:"/docs/concepts/archival/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-3c8e9720").then(n)}},{path:"/docs/concepts/archival/index.html",redirect:"/docs/concepts/archival/"},{path:"/docs/02-concepts/07-archival.html",redirect:"/docs/concepts/archival/"},{name:"v-d2d99830",path:"/docs/concepts/cross-dc-replication/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-d2d99830").then(n)}},{path:"/docs/concepts/cross-dc-replication/index.html",redirect:"/docs/concepts/cross-dc-replication/"},{path:"/docs/02-concepts/08-cross-dc-replication.html",redirect:"/docs/concepts/cross-dc-replication/"},{name:"v-750c7ee2",path:"/docs/concepts/search-workflows/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-750c7ee2").then(n)}},{path:"/docs/concepts/search-workflows/index.html",redirect:"/docs/concepts/search-workflows/"},{path:"/docs/02-concepts/09-search-workflows.html",redirect:"/docs/concepts/search-workflows/"},{name:"v-be41a8c6",path:"/docs/concepts/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-be41a8c6").then(n)}},{path:"/docs/concepts/index.html",redirect:"/docs/concepts/"},{path:"/docs/02-concepts/",redirect:"/docs/concepts/"},{name:"v-546411c2",path:"/docs/tutorials/java-hello-world/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-546411c2").then(n)}},{path:"/docs/tutorials/java-hello-world/index.html",redirect:"/docs/tutorials/java-hello-world/"},{path:"/docs/03-video-tutorials/01-java-hello-world.html",redirect:"/docs/tutorials/java-hello-world/"},{name:"v-0d0c6d7b",path:"/docs/tutorials/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-0d0c6d7b").then(n)}},{path:"/docs/tutorials/index.html",redirect:"/docs/tutorials/"},{path:"/docs/03-video-tutorials/",redirect:"/docs/tutorials/"},{name:"v-745671b4",path:"/docs/java-client/quick-start/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-745671b4").then(n)}},{path:"/docs/java-client/quick-start/index.html",redirect:"/docs/java-client/quick-start/"},{path:"/docs/04-java-client/01-quick-start.html",redirect:"/docs/java-client/quick-start/"},{name:"v-3d11f802",path:"/docs/java-client/workflow-interface/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-3d11f802").then(n)}},{path:"/docs/java-client/workflow-interface/index.html",redirect:"/docs/java-client/workflow-interface/"},{path:"/docs/04-java-client/02-workflow-interface.html",redirect:"/docs/java-client/workflow-interface/"},{name:"v-264670c2",path:"/docs/java-client/implementing-workflows/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-264670c2").then(n)}},{path:"/docs/java-client/implementing-workflows/index.html",redirect:"/docs/java-client/implementing-workflows/"},{path:"/docs/04-java-client/03-implementing-workflows.html",redirect:"/docs/java-client/implementing-workflows/"},{name:"v-11997e3c",path:"/docs/java-client/starting-workflow-executions/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-11997e3c").then(n)}},{path:"/docs/java-client/starting-workflow-executions/index.html",redirect:"/docs/java-client/starting-workflow-executions/"},{path:"/docs/04-java-client/04-starting-workflow-executions.html",redirect:"/docs/java-client/starting-workflow-executions/"},{name:"v-5a20c23c",path:"/docs/java-client/activity-interface/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-5a20c23c").then(n)}},{path:"/docs/java-client/activity-interface/index.html",redirect:"/docs/java-client/activity-interface/"},{path:"/docs/04-java-client/05-activity-interface.html",redirect:"/docs/java-client/activity-interface/"},{name:"v-056557ea",path:"/docs/java-client/implementing-activities/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-056557ea").then(n)}},{path:"/docs/java-client/implementing-activities/index.html",redirect:"/docs/java-client/implementing-activities/"},{path:"/docs/04-java-client/06-implementing-activities.html",redirect:"/docs/java-client/implementing-activities/"},{name:"v-ee26987c",path:"/docs/java-client/versioning/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-ee26987c").then(n)}},{path:"/docs/java-client/versioning/index.html",redirect:"/docs/java-client/versioning/"},{path:"/docs/04-java-client/07-versioning.html",redirect:"/docs/java-client/versioning/"},{name:"v-5951033c",path:"/docs/java-client/distributed-cron/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-5951033c").then(n)}},{path:"/docs/java-client/distributed-cron/index.html",redirect:"/docs/java-client/distributed-cron/"},{path:"/docs/04-java-client/08-distributed-cron.html",redirect:"/docs/java-client/distributed-cron/"},{name:"v-e9a63714",path:"/docs/go-client/workers/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-e9a63714").then(n)}},{path:"/docs/go-client/workers/index.html",redirect:"/docs/go-client/workers/"},{path:"/docs/05-go-client/01-workers.html",redirect:"/docs/go-client/workers/"},{name:"v-d91dcabc",path:"/docs/go-client/create-workflows/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-d91dcabc").then(n)}},{path:"/docs/go-client/create-workflows/index.html",redirect:"/docs/go-client/create-workflows/"},{path:"/docs/05-go-client/02-create-workflows.html",redirect:"/docs/go-client/create-workflows/"},{name:"v-241aa182",path:"/docs/go-client/activities/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-241aa182").then(n)}},{path:"/docs/go-client/activities/index.html",redirect:"/docs/go-client/activities/"},{path:"/docs/05-go-client/03-activities.html",redirect:"/docs/go-client/activities/"},{name:"v-7109c462",path:"/docs/go-client/execute-activity/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-7109c462").then(n)}},{path:"/docs/go-client/execute-activity/index.html",redirect:"/docs/go-client/execute-activity/"},{path:"/docs/05-go-client/04-execute-activity.html",redirect:"/docs/go-client/execute-activity/"},{name:"v-30ee6212",path:"/docs/go-client/child-workflows/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-30ee6212").then(n)}},{path:"/docs/go-client/child-workflows/index.html",redirect:"/docs/go-client/child-workflows/"},{path:"/docs/05-go-client/05-child-workflows.html",redirect:"/docs/go-client/child-workflows/"},{name:"v-63bf2e6c",path:"/docs/go-client/retries/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-63bf2e6c").then(n)}},{path:"/docs/go-client/retries/index.html",redirect:"/docs/go-client/retries/"},{path:"/docs/05-go-client/06-retries.html",redirect:"/docs/go-client/retries/"},{name:"v-651b4e0a",path:"/docs/java-client/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-651b4e0a").then(n)}},{path:"/docs/java-client/index.html",redirect:"/docs/java-client/"},{path:"/docs/04-java-client/",redirect:"/docs/java-client/"},{name:"v-103bbcbc",path:"/docs/go-client/error-handling/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-103bbcbc").then(n)}},{path:"/docs/go-client/error-handling/index.html",redirect:"/docs/go-client/error-handling/"},{path:"/docs/05-go-client/07-error-handling.html",redirect:"/docs/go-client/error-handling/"},{name:"v-65ea467c",path:"/docs/go-client/signals/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-65ea467c").then(n)}},{path:"/docs/go-client/signals/index.html",redirect:"/docs/go-client/signals/"},{path:"/docs/05-go-client/08-signals.html",redirect:"/docs/go-client/signals/"},{name:"v-b60e670c",path:"/docs/go-client/continue-as-new/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-b60e670c").then(n)}},{path:"/docs/go-client/continue-as-new/index.html",redirect:"/docs/go-client/continue-as-new/"},{path:"/docs/05-go-client/09-continue-as-new.html",redirect:"/docs/go-client/continue-as-new/"},{name:"v-3c7b0dd4",path:"/docs/go-client/side-effect/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-3c7b0dd4").then(n)}},{path:"/docs/go-client/side-effect/index.html",redirect:"/docs/go-client/side-effect/"},{path:"/docs/05-go-client/10-side-effect.html",redirect:"/docs/go-client/side-effect/"},{name:"v-a558de54",path:"/docs/go-client/queries/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-a558de54").then(n)}},{path:"/docs/go-client/queries/index.html",redirect:"/docs/go-client/queries/"},{path:"/docs/05-go-client/11-queries.html",redirect:"/docs/go-client/queries/"},{name:"v-5b7bae8a",path:"/docs/go-client/activity-async-completion/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-5b7bae8a").then(n)}},{path:"/docs/go-client/activity-async-completion/index.html",redirect:"/docs/go-client/activity-async-completion/"},{path:"/docs/05-go-client/12-activity-async-completion.html",redirect:"/docs/go-client/activity-async-completion/"},{name:"v-722c1fc2",path:"/docs/go-client/workflow-testing/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-722c1fc2").then(n)}},{path:"/docs/go-client/workflow-testing/index.html",redirect:"/docs/go-client/workflow-testing/"},{path:"/docs/05-go-client/13-workflow-testing.html",redirect:"/docs/go-client/workflow-testing/"},{name:"v-957246a8",path:"/docs/go-client/workflow-versioning/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-957246a8").then(n)}},{path:"/docs/go-client/workflow-versioning/index.html",redirect:"/docs/go-client/workflow-versioning/"},{path:"/docs/05-go-client/14-workflow-versioning.html",redirect:"/docs/go-client/workflow-versioning/"},{name:"v-389752bc",path:"/docs/go-client/sessions/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-389752bc").then(n)}},{path:"/docs/go-client/sessions/index.html",redirect:"/docs/go-client/sessions/"},{path:"/docs/05-go-client/15-sessions.html",redirect:"/docs/go-client/sessions/"},{name:"v-0c11d262",path:"/docs/go-client/distributed-cron/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-0c11d262").then(n)}},{path:"/docs/go-client/distributed-cron/index.html",redirect:"/docs/go-client/distributed-cron/"},{path:"/docs/05-go-client/16-distributed-cron.html",redirect:"/docs/go-client/distributed-cron/"},{name:"v-2d3e7cdb",path:"/docs/go-client/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-2d3e7cdb").then(n)}},{path:"/docs/go-client/index.html",redirect:"/docs/go-client/"},{path:"/docs/05-go-client/",redirect:"/docs/go-client/"},{name:"v-a139e6dc",path:"/docs/go-client/tracing/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-a139e6dc").then(n)}},{path:"/docs/go-client/tracing/index.html",redirect:"/docs/go-client/tracing/"},{path:"/docs/05-go-client/17-tracing.html",redirect:"/docs/go-client/tracing/"},{name:"v-2dfd6d7b",path:"/docs/cli/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-2dfd6d7b").then(n)}},{path:"/docs/cli/index.html",redirect:"/docs/cli/"},{path:"/docs/06-cli/",redirect:"/docs/cli/"},{name:"v-884a5d48",path:"/docs/about/license/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-884a5d48").then(n)}},{path:"/docs/about/license/index.html",redirect:"/docs/about/license/"},{path:"/docs/07-about/01-license.html",redirect:"/docs/about/license/"},{name:"v-0747733b",path:"/docs/about/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-0747733b").then(n)}},{path:"/docs/about/index.html",redirect:"/docs/about/"},{path:"/docs/07-about/",redirect:"/docs/about/"},{name:"v-54cca634",path:"/docs/cadence/",component:fs,beforeEnter:function(e,t,n){Ua("default","v-54cca634").then(n)}},{path:"/docs/cadence/index.html",redirect:"/docs/cadence/"},{path:"/docs/cadence.html",redirect:"/docs/cadence/"},{name:"v-0615a98a",path:"/",component:fs,beforeEnter:function(e,t,n){Ua("Layout","v-0615a98a").then(n)}},{path:"/index.html",redirect:"/"},{path:"*",component:fs}],ms={title:"Cadence",description:"",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}]],pages:[{title:"Glossary",frontmatter:{layout:"default",title:"Glossary",terms:{activity:"A business-level function that implements your application logic such as calling a service or transcoding a media file. An activity usually implements a single well-defined action; it can be short or long running. An activity can be implemented as a synchronous method or fully asynchronously involving multiple processes. An activity can be retried indefinitely according to the provided exponential retry policy. If for any reason an activity is not completed within the specified timeout, an error is reported to the workflow and the workflow decides how to handle it. There is no limit on potential activity duration.","activity task":"A task that contains an activity invocation information that is delivered to an activity worker through and an  activity task list. An activity worker upon receiving activity task executes a correponding activity","activity task list":"Task list that is used to deliver activity task to activity worker","activity worker":"An object that is executed in the client application and receives activity task from an  activity task list it is subscribed to. Once task is received it invokes a correspondent activity.",archival:"Archival is a feature that automatically moves event history from persistence to a blobstore after the workflow retention period. The purpose of archival is to be able to keep histories as long as needed while not overwhelming the persistence store. There are two reasons you may want to keep the histories after the retention period has passed: 1. Compliance: For legal reasons, histories may need to be stored for a long period of time. 2. Debugging: Old histories can still be accessed for debugging.",CLI:"Cadence command-line interface.","client stub":"A client-side proxy used to make remote invocations to an entity that it represents. For example, to start a workflow, a stub object that represents this workflow is created through a special API. Then this stub is used to start, query, or signal the corresponding workflow.\nThe Go client doesn't use this.",decision:"Any action taken by the workflow durable function is called a decision. For example: scheduling an activity, canceling a child workflow, or starting a timer. A decision task contains an optional list of decisions. Every decision is recorded in the event history as an event.","decision task":"Every time a new external event that might affect a workflow state is recorded, a decision task that contains it is added to a decision task list and then picked up by a workflow worker. After the new event is handled, the decision task is completed with a list of decision. Note that handling of a decision task is usually very fast and is not related to duration of operations that the workflow invokes.","decision task list":"Task list that is used to deliver decision task to workflow worker",domain:"Cadence is backed by a multitenant service. The unit of isolation is called a domain. Each domain acts as a namespace for task list names as well as workflow IDs. For example, when a workflow is started, it is started in a specific domain. Cadence guarantees a unique workflow ID within a domain, and supports running workflow executions to use the same workflow ID if they are in different domains. Various configuration options like retention period or archival destination are configured per domain as well through a special CRUD API or through the Cadence CLI. In the multi-cluster deployment, domain is a unit of fail-over. Each domain can only be active on a single Cadence cluster at a time. However, different domains can be active in different clusters and can fail-over independently.",event:"An indivisible operation performed by your application. For example, activity_task_started, task_failed, or timer_canceled. Events are recorded in the event history.","event history":"An append log of events for your application. History is durably persisted by the Cadence service, enabling seamless recovery of your application state from crashes or failures. It also serves as an audit log for debugging.","local activity":"A local activity is an activity that is invoked directly in the same process by a workflow code. It consumes much less resources than a normal activity, but imposes a lot of limitations like low duration and lack of rate limiting.",query:"A synchronous (from the caller's point of view) operation that is used to report a workflow state. Note that a query is inherently read only and cannot affect a workflow state.","run ID":"A UUID that a Cadence service assigns to each workflow run. If allowed by a configured policy, you might be able to re-execute a workflow, after it has closed or failed, with the same workflow id. Each such re-execution is called a run. run id is used to uniquely identify a run even if it shares a workflow id with others.",signal:"An external asynchronous request to a workflow. It can be used to deliver notifications or updates to a running workflow at any point in its existence.",task:"The context needed to execute a specific activity or workflow state transition. There are two types of tasks: an activity task and a decision task (aka workflow task). Note that a single activity execution corresponds to a single activity task, while a workflow execution employs multiple decision tasks.","task list":"Common name for activity task list and decision task list","task token":"A unique correlation ID for a Cadence activity. Activity completion calls take either task token or DomainName, WorkflowID, ActivityID arguments.",worker:"Also known as a worker service. A service that hosts the workflow and activity implementations. The worker polls the Cadence service for tasks, performs those tasks, and communicates task execution results back to the Cadence service. Worker services are developed, deployed, and operated by Cadence customers.",workflow:"A fault-oblivious stateful function that orchestrates activities. A workflow has full control over which activities are executed, and in which order. A workflow must not affect the external world directly, only through activities. What makes workflow code a workflow is that its state is preserved by Cadence. Therefore any failure of a worker process that hosts the workflow code does not affect the workflow execution. The workflow continues as if these failures did not happen. At the same time, activities can fail any moment for any reason. Because workflow code is fully fault-oblivious, it is guaranteed to get notifications about activity failures or timeouts and act accordingly. There is no limit on potential workflow duration.","workflow execution":"An instance of a workflow. The instance can be in the process of executing or it could have already completed execution.","workflow ID":"A unique identifier for a workflow execution. Cadence guarantees the uniqueness of an ID within a domain. An attempt to start a workflow with a duplicate ID results in an already started error.","workflow task":"Synonym of the decision task.","workflow worker":"An object that is executed in the client application and receives decision task from an  decision task list it is subscribed to. Once task is received it is handled by a correponding workflow."},readingShow:"top"},regularPath:"/GLOSSARY.html",relativePath:"GLOSSARY.md",key:"v-1c019fb2",path:"/GLOSSARY.html",headersStr:null,content:"# Glossary",normalizedContent:"# glossary",charsets:{}},{title:"Periodic execution",frontmatter:{layout:"default",title:"Periodic execution",permalink:"/docs/use-cases/periodic-execution",readingShow:"top"},regularPath:"/docs/01-use-cases/01-periodic-execution.html",relativePath:"docs/01-use-cases/01-periodic-execution.md",key:"v-512ef402",path:"/docs/use-cases/periodic-execution/",headersStr:null,content:"# Periodic execution (aka Distributed Cron)\nPeriodic execution, frequently referred to as distributed cron, is when you execute business logic periodically. The advantage of Cadence for these scenarios is that it guarantees execution, sophisticated error handling, retry policies, and visibility into execution history.\n\nAnother important dimension is scale. Some use cases require periodic execution for a large number of entities. At Uber, there are applications that create periodic per customer. Imagine 100+ million parallel cron jobs that don't require a separate batch processing framework.\n\nPeriodic execution is often part of other use cases. For example, once a month report generation is a periodic service orchestration. Or an event-driven that accumulates loyalty points for a customer and applies those points once a month.\n\nThere are many real-world examples of Cadence periodic executions. Such as the following:\n\n * An Uber backend service that recalculates various statistics for each hex in each city once a minute.\n * Monthly Uber for Business report generation.",normalizedContent:"# periodic execution (aka distributed cron)\nperiodic execution, frequently referred to as distributed cron, is when you execute business logic periodically. the advantage of cadence for these scenarios is that it guarantees execution, sophisticated error handling, retry policies, and visibility into execution history.\n\nanother important dimension is scale. some use cases require periodic execution for a large number of entities. at uber, there are applications that create periodic per customer. imagine 100+ million parallel cron jobs that don't require a separate batch processing framework.\n\nperiodic execution is often part of other use cases. for example, once a month report generation is a periodic service orchestration. or an event-driven that accumulates loyalty points for a customer and applies those points once a month.\n\nthere are many real-world examples of cadence periodic executions. such as the following:\n\n * an uber backend service that recalculates various statistics for each hex in each city once a minute.\n * monthly uber for business report generation.",charsets:{}},{title:"Orchestration",frontmatter:{layout:"default",title:"Orchestration",permalink:"/docs/use-cases/orchestration",readingShow:"top"},regularPath:"/docs/01-use-cases/02-orchestration.html",relativePath:"docs/01-use-cases/02-orchestration.md",key:"v-863e8124",path:"/docs/use-cases/orchestration/",headersStr:null,content:"# Microservice Orchestration and Saga\nIt is common that some business processes are implemented as multiple microservice calls. And the implementation must guarantee that all of the calls must eventually succeed even with the occurrence of prolonged downstream service failures. In some cases, instead of trying to complete the process by retrying for a long time, compensation rollback logic should be executed.Saga Pattern is one way to standardize on compensation APIs.\n\nCadence is a perfect fit for such scenarios. It guarantees that code eventually completes, has built-in support for unlimited exponential retries and simplifies coding of the compensation logic. It also gives full visibility into the state of each , in contrast to an orchestration based on queues where getting a current status of each individual request is practically impossible.\n\nFollowing are some real-world examples of Cadence-based service orchestration scenarios:\n\n * Using Cadence workflows to spin up Kubernetes by Banzai Cloud\n * Improving the User Experience with Uber’s Customer Obsession Ticket Routing Workflow and Orchestration Engine",normalizedContent:"# microservice orchestration and saga\nit is common that some business processes are implemented as multiple microservice calls. and the implementation must guarantee that all of the calls must eventually succeed even with the occurrence of prolonged downstream service failures. in some cases, instead of trying to complete the process by retrying for a long time, compensation rollback logic should be executed.saga pattern is one way to standardize on compensation apis.\n\ncadence is a perfect fit for such scenarios. it guarantees that code eventually completes, has built-in support for unlimited exponential retries and simplifies coding of the compensation logic. it also gives full visibility into the state of each , in contrast to an orchestration based on queues where getting a current status of each individual request is practically impossible.\n\nfollowing are some real-world examples of cadence-based service orchestration scenarios:\n\n * using cadence workflows to spin up kubernetes by banzai cloud\n * improving the user experience with uber’s customer obsession ticket routing workflow and orchestration engine",charsets:{}},{title:"Polling",frontmatter:{layout:"default",title:"Polling",permalink:"/docs/use-cases/polling",readingShow:"top"},regularPath:"/docs/01-use-cases/03-polling.html",relativePath:"docs/01-use-cases/03-polling.md",key:"v-6f803ea8",path:"/docs/use-cases/polling/",headersStr:null,content:"# Polling\nPolling is executing a periodic action checking for a state change. Examples are pinging a host, calling a REST API, or listing an Amazon S3 bucket for newly uploaded files.\n\nCadence support for long running and unlimited retries makes it a good fit.\n\nSome real-world use cases:\n\n * Network, host and service monitoring\n * Processing files uploaded to FTP or S3\n * Polling an external API for a specific resource to become available",normalizedContent:"# polling\npolling is executing a periodic action checking for a state change. examples are pinging a host, calling a rest api, or listing an amazon s3 bucket for newly uploaded files.\n\ncadence support for long running and unlimited retries makes it a good fit.\n\nsome real-world use cases:\n\n * network, host and service monitoring\n * processing files uploaded to ftp or s3\n * polling an external api for a specific resource to become available",charsets:{}},{title:"Event driven application",frontmatter:{layout:"default",title:"Event driven application",permalink:"/docs/use-cases/event-driven",readingShow:"top"},regularPath:"/docs/01-use-cases/04-event-driven.html",relativePath:"docs/01-use-cases/04-event-driven.md",key:"v-4d735b42",path:"/docs/use-cases/event-driven/",headersStr:null,content:"# Event driven application\nMany applications listen to multiple sources, update the state of correspondent business entities, and have to execute actions if some state is reached. Cadence is a good fit for many of these. It has direct support for asynchronous (aka ), has a simple programming model that obscures a lot of complexity around state persistence, and ensures external action execution through built-in retries.\n\nReal-world examples:\n\n * Fraud detection where reacts to generated by consumer behavior\n * Customer loyalty program where the accumulates reward points and applies them when requested",normalizedContent:"# event driven application\nmany applications listen to multiple sources, update the state of correspondent business entities, and have to execute actions if some state is reached. cadence is a good fit for many of these. it has direct support for asynchronous (aka ), has a simple programming model that obscures a lot of complexity around state persistence, and ensures external action execution through built-in retries.\n\nreal-world examples:\n\n * fraud detection where reacts to generated by consumer behavior\n * customer loyalty program where the accumulates reward points and applies them when requested",charsets:{}},{title:"Storage scan",frontmatter:{layout:"default",title:"Storage scan",permalink:"/docs/use-cases/partitioned-scan",readingShow:"top"},regularPath:"/docs/01-use-cases/05-partitioned-scan.html",relativePath:"docs/01-use-cases/05-partitioned-scan.md",key:"v-7d3ade22",path:"/docs/use-cases/partitioned-scan/",headersStr:null,content:"# Storage scan\nIt is common to have large data sets partitioned across a large number of hosts or databases, or having billions of files in an Amazon S3 bucket. Cadence is an ideal solution for implementing the full scan of such data in a scalable and resilient way. The standard pattern is to run an (or multiple parallel for partitioned data sets) that performs the scan and heartbeats its progress back to Cadence. In the case of a host failure, the is retried on a different host and continues execution from the last reported progress.\n\nA real-world example:\n\n * Cadence internal system that performs periodic scan of all records",normalizedContent:"# storage scan\nit is common to have large data sets partitioned across a large number of hosts or databases, or having billions of files in an amazon s3 bucket. cadence is an ideal solution for implementing the full scan of such data in a scalable and resilient way. the standard pattern is to run an (or multiple parallel for partitioned data sets) that performs the scan and heartbeats its progress back to cadence. in the case of a host failure, the is retried on a different host and continues execution from the last reported progress.\n\na real-world example:\n\n * cadence internal system that performs periodic scan of all records",charsets:{}},{title:"Batch job",frontmatter:{layout:"default",title:"Batch job",permalink:"/docs/use-cases/batch-job",readingShow:"top"},regularPath:"/docs/01-use-cases/06-batch-job.html",relativePath:"docs/01-use-cases/06-batch-job.md",key:"v-03657f14",path:"/docs/use-cases/batch-job/",headersStr:null,content:"# Batch job\nA lot of batch jobs are not pure data manipulation programs. For those, the existing big data frameworks are the best fit. But if processing a record requires external API calls that might fail and potentially take a long time, Cadence might be preferable.\n\nOne of our internal Uber customer uses Cadence for end of month statement generation. Each statement requires calls to multiple microservices and some statements can be really large. Cadence was chosen because it provides hard guarantees around durability of the financial data and seamlessly deals with long running operations, retries, and intermittent failures.",normalizedContent:"# batch job\na lot of batch jobs are not pure data manipulation programs. for those, the existing big data frameworks are the best fit. but if processing a record requires external api calls that might fail and potentially take a long time, cadence might be preferable.\n\none of our internal uber customer uses cadence for end of month statement generation. each statement requires calls to multiple microservices and some statements can be really large. cadence was chosen because it provides hard guarantees around durability of the financial data and seamlessly deals with long running operations, retries, and intermittent failures.",charsets:{}},{title:"Infrastructure provisioning",frontmatter:{layout:"default",title:"Infrastructure provisioning",permalink:"/docs/use-cases/provisioning",readingShow:"top"},regularPath:"/docs/01-use-cases/07-provisioning.html",relativePath:"docs/01-use-cases/07-provisioning.md",key:"v-0853f13c",path:"/docs/use-cases/provisioning/",headersStr:null,content:"# Infrastructure provisioning\nProvisioning a new datacenter or a pool of machines in a public cloud is a potentially long running operation with a lot of possibilities for intermittent failures. The scale is also a concern when tens or even hundreds of thousands of resources should be provisioned and configured. One useful feature for provisioning scenarios is Cadence support for routing execution to a specific process or host.\n\nA lot of operations require some sort of locking to ensure that no more than one mutation is executed on a resource at a time. Cadence provides strong guarantees of uniqueness by business ID. This can be used to implement such locking behavior in a fault tolerant and scalable manner.\n\nSome real-world use cases:\n\n * Using Cadence workflows to spin up Kubernetes, by Banzai Cloud\n * Using Cadence to orchestrate cluster life cycle in HashiCorp Consul, by HashiCorp",normalizedContent:"# infrastructure provisioning\nprovisioning a new datacenter or a pool of machines in a public cloud is a potentially long running operation with a lot of possibilities for intermittent failures. the scale is also a concern when tens or even hundreds of thousands of resources should be provisioned and configured. one useful feature for provisioning scenarios is cadence support for routing execution to a specific process or host.\n\na lot of operations require some sort of locking to ensure that no more than one mutation is executed on a resource at a time. cadence provides strong guarantees of uniqueness by business id. this can be used to implement such locking behavior in a fault tolerant and scalable manner.\n\nsome real-world use cases:\n\n * using cadence workflows to spin up kubernetes, by banzai cloud\n * using cadence to orchestrate cluster life cycle in hashicorp consul, by hashicorp",charsets:{}},{title:"Deployment",frontmatter:{layout:"default",title:"Deployment",permalink:"/docs/use-cases/deployment",readingShow:"top"},regularPath:"/docs/01-use-cases/08-deployment.html",relativePath:"docs/01-use-cases/08-deployment.md",key:"v-2d694702",path:"/docs/use-cases/deployment/",headersStr:null,content:"# CI/CD and Deployment\nImplementing CI/CD pipelines and deployment of applications to containers or virtual or physical machines is a non-trivial process. Its business logic has to deal with complex requirements around rolling upgrades, canary deployments, and rollbacks. Cadence is a perfect platform for building a deployment solution because it provides all the necessary guarantees and abstractions allowing developers to focus on the business logic.\n\nExample production systems:\n\n * Uber internal deployment infrastructure\n * Update push to IoT devices",normalizedContent:"# ci/cd and deployment\nimplementing ci/cd pipelines and deployment of applications to containers or virtual or physical machines is a non-trivial process. its business logic has to deal with complex requirements around rolling upgrades, canary deployments, and rollbacks. cadence is a perfect platform for building a deployment solution because it provides all the necessary guarantees and abstractions allowing developers to focus on the business logic.\n\nexample production systems:\n\n * uber internal deployment infrastructure\n * update push to iot devices",charsets:{}},{title:"Operational management",frontmatter:{layout:"default",title:"Operational management",permalink:"/docs/use-cases/operational-management",readingShow:"top"},regularPath:"/docs/01-use-cases/09-operational-management.html",relativePath:"docs/01-use-cases/09-operational-management.md",key:"v-28dd3202",path:"/docs/use-cases/operational-management/",headersStr:null,content:"# Operational management\nImagine that you have to create a self operating database similar to Amazon RDS. Cadence is used in multiple projects that automate managing and automatic recovery of various products like MySQL, Elasticsearch and Apache Cassandra.\n\nSuch systems are usually a mixture of different use cases. They need to monitor the status of resources using polling. They have to execute orchestration API calls to administrative interfaces of a database. They have to provision new hardware or Docker instances if necessary. They need to push configuration updates and perform other actions like backups periodically.",normalizedContent:"# operational management\nimagine that you have to create a self operating database similar to amazon rds. cadence is used in multiple projects that automate managing and automatic recovery of various products like mysql, elasticsearch and apache cassandra.\n\nsuch systems are usually a mixture of different use cases. they need to monitor the status of resources using polling. they have to execute orchestration api calls to administrative interfaces of a database. they have to provision new hardware or docker instances if necessary. they need to push configuration updates and perform other actions like backups periodically.",charsets:{}},{title:"Interactive application",frontmatter:{layout:"default",title:"Interactive application",permalink:"/docs/use-cases/interactive",readingShow:"top"},regularPath:"/docs/01-use-cases/10-interactive.html",relativePath:"docs/01-use-cases/10-interactive.md",key:"v-2380d6f2",path:"/docs/use-cases/interactive/",headersStr:null,content:"# Interactive application\nCadence is performant and scalable enough to support interactive applications. It can be used to track UI session state and at the same time execute background operations. For example, while placing an order a customer might need to go through several screens while a background evaluates the customer for fraudulent .",normalizedContent:"# interactive application\ncadence is performant and scalable enough to support interactive applications. it can be used to track ui session state and at the same time execute background operations. for example, while placing an order a customer might need to go through several screens while a background evaluates the customer for fraudulent .",charsets:{}},{title:"DSL workflows",frontmatter:{layout:"default",title:"DSL workflows",permalink:"/docs/use-cases/dsl",readingShow:"top"},regularPath:"/docs/01-use-cases/11-dsl.html",relativePath:"docs/01-use-cases/11-dsl.md",key:"v-1d6d6d3a",path:"/docs/use-cases/dsl/",headersStr:null,content:'# DSL workflows\nCadence supports implementing business logic directly in programming languages like Java and Go. But there are cases when using a domain-specific language is more appropriate. Or there might be a legacy system that uses some form of DSL for process definition but it is not operationally stable and scalable. This also applies to more recent systems like Apache Airflow, various BPMN engines and AWS Step Functions.\n\nAn application that interprets the DSL definition can be written using the Cadence SDK. It automatically becomes highly fault tolerant, scalable, and durable when running on Cadence. Cadence has been used to deprecate several Uber internal DSL engines. The customers continue to use existing process definitions, but Cadence is used as an execution engine.\n\nThere are multiple benefits of unifying all company engines on top of Cadence. The most obvious one is that it is more efficient to support a single product instead of many. It is also difficult to beat the scalability and stability of Cadence which each of the integrations it comes with. Additionally, the ability to share across "engines" might be a huge benefit in some cases.',normalizedContent:'# dsl workflows\ncadence supports implementing business logic directly in programming languages like java and go. but there are cases when using a domain-specific language is more appropriate. or there might be a legacy system that uses some form of dsl for process definition but it is not operationally stable and scalable. this also applies to more recent systems like apache airflow, various bpmn engines and aws step functions.\n\nan application that interprets the dsl definition can be written using the cadence sdk. it automatically becomes highly fault tolerant, scalable, and durable when running on cadence. cadence has been used to deprecate several uber internal dsl engines. the customers continue to use existing process definitions, but cadence is used as an execution engine.\n\nthere are multiple benefits of unifying all company engines on top of cadence. the most obvious one is that it is more efficient to support a single product instead of many. it is also difficult to beat the scalability and stability of cadence which each of the integrations it comes with. additionally, the ability to share across "engines" might be a huge benefit in some cases.',charsets:{}},{title:"Big data and ML",frontmatter:{layout:"default",title:"Big data and ML",permalink:"/docs/use-cases/big-ml",readingShow:"top"},regularPath:"/docs/01-use-cases/12-big-ml.html",relativePath:"docs/01-use-cases/12-big-ml.md",key:"v-ef9d367c",path:"/docs/use-cases/big-ml/",headersStr:null,content:"# Big data and ML\nA lot of companies build custom ETL and ML training and deployment solutions. Cadence is a good fit for a control plane for such applications.\n\nOne important feature of Cadence is its ability to route execution to a specific process or host. It is useful to control how ML models and other large files are allocated to hosts. For example, if an ML model is partitioned by city, the requests should be routed to hosts that contain the corresponding city model.",normalizedContent:"# big data and ml\na lot of companies build custom etl and ml training and deployment solutions. cadence is a good fit for a control plane for such applications.\n\none important feature of cadence is its ability to route execution to a specific process or host. it is useful to control how ml models and other large files are allocated to hosts. for example, if an ml model is partitioned by city, the requests should be routed to hosts that contain the corresponding city model.",charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/use-cases/",readingShow:"top"},regularPath:"/docs/01-use-cases/",relativePath:"docs/01-use-cases/index.md",key:"v-42d0cb0a",path:"/docs/use-cases/",headersStr:null,content:'# Use cases\nAs Cadence developers, we face a difficult non-technical problem: How to position and describe the Cadence platform.\n\nWe call it workflow. But when most people hear the word "workflow" they think about low-code and UIs. While these might be useful for non technical users, they frequently bring more pain than value to software engineers. Most UIs and low-code DSLs are awesome for "hello world" demo applications, but any diagram with 100+ elements or a few thousand lines of JSON DSL is completely impractical. So positioning Cadence as a is not ideal as it turns away developers that would enjoy its code-only approach.\n\nWe call it orchestrator. But this term is pretty narrow and turns away customers that want to implement business process automation solutions.\n\nWe call it durable function platform. It is technically a correct term. But most developers outside of the Microsoft ecosystem have never heard of Durable Functions.\n\nWe believe that problem in naming comes from the fact that Cadence is indeed a new way to write distributed applications. It is generic enough that it can be applied to practically any use case that goes beyond a single request reply. It can be used to build applications that are in traditional areas of or orchestration platforms. But it is also huge developer productivity boost for multiple use cases that traditionally rely on databases and/or queues.\n\nThis section represents a far from complete list of use cases where Cadence is a good fit. All of them have been used by real production services inside and outside of Uber.\n\nDon\'t think of this list as exhaustive. It is common to employ multiple use types in a single application. For example, an operational management use case might need periodic execution, service orchestration, polling, driven, as well as interactive parts.',normalizedContent:'# use cases\nas cadence developers, we face a difficult non-technical problem: how to position and describe the cadence platform.\n\nwe call it workflow. but when most people hear the word "workflow" they think about low-code and uis. while these might be useful for non technical users, they frequently bring more pain than value to software engineers. most uis and low-code dsls are awesome for "hello world" demo applications, but any diagram with 100+ elements or a few thousand lines of json dsl is completely impractical. so positioning cadence as a is not ideal as it turns away developers that would enjoy its code-only approach.\n\nwe call it orchestrator. but this term is pretty narrow and turns away customers that want to implement business process automation solutions.\n\nwe call it durable function platform. it is technically a correct term. but most developers outside of the microsoft ecosystem have never heard of durable functions.\n\nwe believe that problem in naming comes from the fact that cadence is indeed a new way to write distributed applications. it is generic enough that it can be applied to practically any use case that goes beyond a single request reply. it can be used to build applications that are in traditional areas of or orchestration platforms. but it is also huge developer productivity boost for multiple use cases that traditionally rely on databases and/or queues.\n\nthis section represents a far from complete list of use cases where cadence is a good fit. all of them have been used by real production services inside and outside of uber.\n\ndon\'t think of this list as exhaustive. it is common to employ multiple use types in a single application. for example, an operational management use case might need periodic execution, service orchestration, polling, driven, as well as interactive parts.',charsets:{}},{title:"Workflows",frontmatter:{layout:"default",title:"Workflows",permalink:"/docs/concepts/workflows",readingShow:"top"},regularPath:"/docs/02-concepts/01-workflows.html",relativePath:"docs/02-concepts/01-workflows.md",key:"v-68a1c262",path:"/docs/concepts/workflows/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:43},{level:2,title:"Example",slug:"example",normalizedTitle:"example",charIndex:343},{level:2,title:"State Recovery and Determinism",slug:"state-recovery-and-determinism",normalizedTitle:"state recovery and determinism",charIndex:5381},{level:2,title:"ID Uniqueness",slug:"id-uniqueness",normalizedTitle:"id uniqueness",charIndex:6114},{level:2,title:"Child Workflow",slug:"child-workflow",normalizedTitle:"child workflow",charIndex:7133},{level:2,title:"Workflow Retries",slug:"workflow-retries",normalizedTitle:"workflow retries",charIndex:8704}],headersStr:"Overview Example State Recovery and Determinism ID Uniqueness Child Workflow Workflow Retries",content:"# Fault-oblivious stateful workflow code\n# Overview\nCadence core abstraction is a fault-oblivious stateful . The state of the code, including local variables and threads it creates, is immune to process and Cadence service failures. This is a very powerful concept as it encapsulates state, processing threads, durable timers and handlers.\n\n# Example\nLet's look at a use case. A customer signs up for an application with a trial period. After the period, if the customer has not cancelled, he should be charged once a month for the renewal. The customer has to be notified by email about the charges and should be able to cancel the subscription at any time.\n\nThe business logic of this use case is not very complicated and can be expressed in a few dozen lines of code. But any practical implementation has to ensure that the business process is fault tolerant and scalable. There are various ways to approach the design of such a system.\n\nOne approach is to center it around a database. An application process would periodically scan database tables for customers in specific states, execute necessary actions, and update the state to reflect that. While feasible, this approach has various drawbacks. The most obvious is that the state machine of the customer state quickly becomes extremely complicated. For example, charging a credit card or sending emails can fail due to a downstream system unavailability. The failed calls might need to be retried for a long time, ideally using an exponential retry policy. These calls should be throttled to not overload external systems. There should be support for poison pills to avoid blocking the whole process if a single customer record cannot be processed for whatever reason. The database-based approach also usually has performance problems. Databases are not efficient for scenarios that require constant polling for records in a specific state.\n\nAnother commonly employed approach is to use a timer service and queues. Any update is pushed to a queue and then a that consumes from it updates a database and possibly pushes more messages in downstream queues. For operations that require scheduling, an external timer service can be used. This approach usually scales much better because a database is not constantly polled for changes. But it makes the programming model more complex and error prone as usually there is no transactional update between a queuing system and a database.\n\nWith Cadence, the entire logic can be encapsulated in a simple durable function that directly implements the business logic. Because the function is stateful, the implementer doesn't need to employ any additional systems to ensure durability and fault tolerance.\n\nHere is an example that implements the subscription management use case. It is in Java, but Go is also supported. The Python and .NET libraries are under active development.\n\npublic interface SubscriptionWorkflow {\n    @WorkflowMethod\n    void execute(String customerId);\n}\n\npublic class SubscriptionWorkflowImpl implements SubscriptionWorkflow {\n\n    private final SubscriptionActivities activities =\n        Workflow.newActivityStub(SubscriptionActivities.class);\n\n    @Override\n    public void execute(String customerId) {\n        activities.sendWelcomeEmail(customerId);\n        try {\n            boolean trialPeriod = true;\n            while (true) {\n                Workflow.sleep(Duration.ofDays(30));\n                activities.chargeMonthlyFee(customerId);\n                if (trialPeriod) {\n                    activities.sendEndOfTrialEmail(customerId);\n                    trialPeriod = false;\n                } else {\n                    activities.sendMonthlyChargeEmail(customerId);\n                }\n            }\n        } catch (CancellationException e) {\n            activities.processSubscriptionCancellation(customerId);\n            activities.sendSorryToSeeYouGoEmail(customerId);\n        }\n    }\n}\n\n\nAgain, note that this code directly implements the business logic. If any of the invoked operations (aka ) takes a long time, the code is not going to change. It is okay to block on chargeMonthlyFee for a day if the downstream processing service is down that long. The same way that blocking sleep for 30 days is a normal operation inside the code.\n\nCadence has practically no scalability limits on the number of open instances. So even if your site has hundreds of millions of consumers, the above code is not going to change.\n\nThe commonly asked question by developers that learn Cadence is \"How do I handle process failure/restart in my \"? The answer is that you do not. The code is completely oblivious to any failures and downtime of or even the Cadence service itself. As soon as they are recovered and the needs to handle some , like timer or an completion, the current state of the is fully restored and the execution is continued. The only reason for a failure is the business code throwing an exception, not underlying infrastructure outages.\n\nAnother commonly asked question is whether a can handle more instances than its cache size or number of threads it can support. The answer is that a , when in a blocked state, can be safely removed from a . Later it can be resurrected on a different or the same when the need (in the form of an external ) arises. So a single can handle millions of open , assuming it can handle the update rate.\n\n# State Recovery and Determinism\nThe state recovery utilizes sourcing which puts a few restrictions on how the code is written. The main restriction is that the code must be deterministic which means that it must produce exactly the same result if executed multiple times. This rules out any external API calls from the code as external calls can fail intermittently or change its output any time. That is why all communication with the external world should happen through . For the same reason, code must use Cadence APIs to get current time, sleep, and create new threads.\n\nTo understand the Cadence execution model as well as the recovery mechanism, watch the following webcast. The animation covering recovery starts at 15:50.\n\n# ID Uniqueness\n is assigned by a client when starting a . It is usually a business level ID like customer ID or order ID.\n\nCadence guarantees that there could be only one (across all types) with a given ID open per at any time. An attempt to start a with the same ID is going to fail with WorkflowExecutionAlreadyStarted error.\n\nAn attempt to start a if there is a completed with the same ID depends on a WorkflowIdReusePolicy option:\n\n * AllowDuplicateFailedOnly means that it is allowed to start a only if a previously executed with the same ID failed.\n * AllowDuplicate means that it is allowed to start independently of the previous completion status.\n * RejectDuplicate means that it is not allowed to start a using the same at all.\n\nThe default is AllowDuplicateFailedOnly.\n\nTo distinguish multiple runs of a with the same , Cadence identifies a with two IDs: Workflow ID and Run ID. Run ID is a service-assigned UUID. To be precise, any is uniquely identified by a triple: Domain Name, Workflow ID and Run ID.\n\n# Child Workflow\nA can execute other as child :workflow:workflows:. A child completion or failure is reported to its parent.\n\nSome reasons to use child are:\n\n * A child can be hosted by a separate set of which don't contain the parent code. So it would act as a separate service that can be invoked from multiple other .\n * A single has a limited size. For example, it cannot execute 100k . Child can be used to partition the problem into smaller chunks. One parent with 1000 children each executing 1000 is 1 million executed .\n * A child can be used to manage some resource using its ID to guarantee uniqueness. For example, a that manages host upgrades can have a child per host (host name being a ) and use them to ensure that all operations on the host are serialized.\n * A child can be used to execute some periodic logic without blowing up the parent history size. When a parent starts a child, it executes periodic logic calling that continues as many times as needed, then completes. From the parent point if view, it is just a single child invocation.\n\nThe main limitation of a child versus collocating all the application logic in a single is lack of the shared state. Parent and child can communicate only through asynchronous . But if there is a tight coupling between them, it might be simpler to use a single and just rely on a shared object state.\n\nWe recommended starting from a single implementation if your problem has bounded size in terms of number of executed and processed . It is more straightforward than multiple asynchronously communicating .\n\n# Workflow Retries\n code is unaffected by infrastructure level downtime and failures. But it still can fail due to business logic level failures. For example, an can fail due to exceeding the retry interval and the error is not handled by application code, or the code having a bug.\n\nSome require a guarantee that they keep running even in presence of such failures. To support such use cases, an optional exponential retry policy can be specified when starting a . When it is specified, a failure restarts a from the beginning after the calculated retry interval. Following are the retry policy parameters:\n\n * InitialInterval is a delay before the first retry.\n * BackoffCoefficient. Retry policies are exponential. The coefficient specifies how fast the retry interval is growing. The coefficient of 1 means that the retry interval is always equal to the InitialInterval.\n * MaximumInterval specifies the maximum interval between retries. Useful for coefficients of more than 1.\n * MaximumAttempts specifies how many times to attempt to execute a in the presence of failures. If this limit is exceeded, the fails without retry. Not required if ExpirationInterval is specified.\n * ExpirationInterval specifies for how long to attempt executing a in the presence of failures. If this interval is exceeded, the fails without retry. Not required if MaximumAttempts is specified.\n * NonRetryableErrorReasons allows to specify errors that shouldn't be retried. For example, retrying invalid arguments error doesn't make sense in some scenarios.",normalizedContent:"# fault-oblivious stateful workflow code\n# overview\ncadence core abstraction is a fault-oblivious stateful . the state of the code, including local variables and threads it creates, is immune to process and cadence service failures. this is a very powerful concept as it encapsulates state, processing threads, durable timers and handlers.\n\n# example\nlet's look at a use case. a customer signs up for an application with a trial period. after the period, if the customer has not cancelled, he should be charged once a month for the renewal. the customer has to be notified by email about the charges and should be able to cancel the subscription at any time.\n\nthe business logic of this use case is not very complicated and can be expressed in a few dozen lines of code. but any practical implementation has to ensure that the business process is fault tolerant and scalable. there are various ways to approach the design of such a system.\n\none approach is to center it around a database. an application process would periodically scan database tables for customers in specific states, execute necessary actions, and update the state to reflect that. while feasible, this approach has various drawbacks. the most obvious is that the state machine of the customer state quickly becomes extremely complicated. for example, charging a credit card or sending emails can fail due to a downstream system unavailability. the failed calls might need to be retried for a long time, ideally using an exponential retry policy. these calls should be throttled to not overload external systems. there should be support for poison pills to avoid blocking the whole process if a single customer record cannot be processed for whatever reason. the database-based approach also usually has performance problems. databases are not efficient for scenarios that require constant polling for records in a specific state.\n\nanother commonly employed approach is to use a timer service and queues. any update is pushed to a queue and then a that consumes from it updates a database and possibly pushes more messages in downstream queues. for operations that require scheduling, an external timer service can be used. this approach usually scales much better because a database is not constantly polled for changes. but it makes the programming model more complex and error prone as usually there is no transactional update between a queuing system and a database.\n\nwith cadence, the entire logic can be encapsulated in a simple durable function that directly implements the business logic. because the function is stateful, the implementer doesn't need to employ any additional systems to ensure durability and fault tolerance.\n\nhere is an example that implements the subscription management use case. it is in java, but go is also supported. the python and .net libraries are under active development.\n\npublic interface subscriptionworkflow {\n    @workflowmethod\n    void execute(string customerid);\n}\n\npublic class subscriptionworkflowimpl implements subscriptionworkflow {\n\n    private final subscriptionactivities activities =\n        workflow.newactivitystub(subscriptionactivities.class);\n\n    @override\n    public void execute(string customerid) {\n        activities.sendwelcomeemail(customerid);\n        try {\n            boolean trialperiod = true;\n            while (true) {\n                workflow.sleep(duration.ofdays(30));\n                activities.chargemonthlyfee(customerid);\n                if (trialperiod) {\n                    activities.sendendoftrialemail(customerid);\n                    trialperiod = false;\n                } else {\n                    activities.sendmonthlychargeemail(customerid);\n                }\n            }\n        } catch (cancellationexception e) {\n            activities.processsubscriptioncancellation(customerid);\n            activities.sendsorrytoseeyougoemail(customerid);\n        }\n    }\n}\n\n\nagain, note that this code directly implements the business logic. if any of the invoked operations (aka ) takes a long time, the code is not going to change. it is okay to block on chargemonthlyfee for a day if the downstream processing service is down that long. the same way that blocking sleep for 30 days is a normal operation inside the code.\n\ncadence has practically no scalability limits on the number of open instances. so even if your site has hundreds of millions of consumers, the above code is not going to change.\n\nthe commonly asked question by developers that learn cadence is \"how do i handle process failure/restart in my \"? the answer is that you do not. the code is completely oblivious to any failures and downtime of or even the cadence service itself. as soon as they are recovered and the needs to handle some , like timer or an completion, the current state of the is fully restored and the execution is continued. the only reason for a failure is the business code throwing an exception, not underlying infrastructure outages.\n\nanother commonly asked question is whether a can handle more instances than its cache size or number of threads it can support. the answer is that a , when in a blocked state, can be safely removed from a . later it can be resurrected on a different or the same when the need (in the form of an external ) arises. so a single can handle millions of open , assuming it can handle the update rate.\n\n# state recovery and determinism\nthe state recovery utilizes sourcing which puts a few restrictions on how the code is written. the main restriction is that the code must be deterministic which means that it must produce exactly the same result if executed multiple times. this rules out any external api calls from the code as external calls can fail intermittently or change its output any time. that is why all communication with the external world should happen through . for the same reason, code must use cadence apis to get current time, sleep, and create new threads.\n\nto understand the cadence execution model as well as the recovery mechanism, watch the following webcast. the animation covering recovery starts at 15:50.\n\n# id uniqueness\n is assigned by a client when starting a . it is usually a business level id like customer id or order id.\n\ncadence guarantees that there could be only one (across all types) with a given id open per at any time. an attempt to start a with the same id is going to fail with workflowexecutionalreadystarted error.\n\nan attempt to start a if there is a completed with the same id depends on a workflowidreusepolicy option:\n\n * allowduplicatefailedonly means that it is allowed to start a only if a previously executed with the same id failed.\n * allowduplicate means that it is allowed to start independently of the previous completion status.\n * rejectduplicate means that it is not allowed to start a using the same at all.\n\nthe default is allowduplicatefailedonly.\n\nto distinguish multiple runs of a with the same , cadence identifies a with two ids: workflow id and run id. run id is a service-assigned uuid. to be precise, any is uniquely identified by a triple: domain name, workflow id and run id.\n\n# child workflow\na can execute other as child :workflow:workflows:. a child completion or failure is reported to its parent.\n\nsome reasons to use child are:\n\n * a child can be hosted by a separate set of which don't contain the parent code. so it would act as a separate service that can be invoked from multiple other .\n * a single has a limited size. for example, it cannot execute 100k . child can be used to partition the problem into smaller chunks. one parent with 1000 children each executing 1000 is 1 million executed .\n * a child can be used to manage some resource using its id to guarantee uniqueness. for example, a that manages host upgrades can have a child per host (host name being a ) and use them to ensure that all operations on the host are serialized.\n * a child can be used to execute some periodic logic without blowing up the parent history size. when a parent starts a child, it executes periodic logic calling that continues as many times as needed, then completes. from the parent point if view, it is just a single child invocation.\n\nthe main limitation of a child versus collocating all the application logic in a single is lack of the shared state. parent and child can communicate only through asynchronous . but if there is a tight coupling between them, it might be simpler to use a single and just rely on a shared object state.\n\nwe recommended starting from a single implementation if your problem has bounded size in terms of number of executed and processed . it is more straightforward than multiple asynchronously communicating .\n\n# workflow retries\n code is unaffected by infrastructure level downtime and failures. but it still can fail due to business logic level failures. for example, an can fail due to exceeding the retry interval and the error is not handled by application code, or the code having a bug.\n\nsome require a guarantee that they keep running even in presence of such failures. to support such use cases, an optional exponential retry policy can be specified when starting a . when it is specified, a failure restarts a from the beginning after the calculated retry interval. following are the retry policy parameters:\n\n * initialinterval is a delay before the first retry.\n * backoffcoefficient. retry policies are exponential. the coefficient specifies how fast the retry interval is growing. the coefficient of 1 means that the retry interval is always equal to the initialinterval.\n * maximuminterval specifies the maximum interval between retries. useful for coefficients of more than 1.\n * maximumattempts specifies how many times to attempt to execute a in the presence of failures. if this limit is exceeded, the fails without retry. not required if expirationinterval is specified.\n * expirationinterval specifies for how long to attempt executing a in the presence of failures. if this interval is exceeded, the fails without retry. not required if maximumattempts is specified.\n * nonretryableerrorreasons allows to specify errors that shouldn't be retried. for example, retrying invalid arguments error doesn't make sense in some scenarios.",charsets:{}},{title:"Activities",frontmatter:{layout:"default",title:"Activities",permalink:"/docs/concepts/activities",readingShow:"top"},regularPath:"/docs/02-concepts/02-activities.html",relativePath:"docs/02-concepts/02-activities.md",key:"v-3a29e1d0",path:"/docs/concepts/activities/",headers:[{level:2,title:"Timeouts",slug:"timeouts",normalizedTitle:"timeouts",charIndex:853},{level:2,title:"Retries",slug:"retries",normalizedTitle:"retries",charIndex:1715},{level:2,title:"Long Running Activities",slug:"long-running-activities",normalizedTitle:"long running activities",charIndex:1599},{level:2,title:"Cancellation",slug:"cancellation",normalizedTitle:"cancellation",charIndex:4702},{level:2,title:"Activity Task Routing through Task Lists",slug:"activity-task-routing-through-task-lists",normalizedTitle:"activity task routing through task lists",charIndex:5309},{level:2,title:"Asynchronous Activity Completion",slug:"asynchronous-activity-completion",normalizedTitle:"asynchronous activity completion",charIndex:7114},{level:2,title:"Local Activities",slug:"local-activities",normalizedTitle:"local activities",charIndex:7732}],headersStr:"Timeouts Retries Long Running Activities Cancellation Activity Task Routing through Task Lists Asynchronous Activity Completion Local Activities",content:"# Activities\nFault-oblivious stateful code is the core abstraction of Cadence. But, due to deterministic execution requirements, they are not allowed to call any external API directly. Instead they orchestrate execution of . In its simplest form, a Cadence is a function or an object method in one of the supported languages. Cadence does not recover state in case of failures. Therefore an function is allowed to contain any code without restrictions.\n\n are invoked asynchronously through . A is essentially a queue used to store an until it is picked up by an available . The processes an by invoking its implementation function. When the function returns, the reports the result back to the Cadence service which in turn notifies the about completion. It is possible to implement an fully asynchronously by completing it from a different process.\n\n# Timeouts\nCadence does not impose any system limit on duration. It is up to the application to choose the timeouts for its execution. These are the configurable timeouts:\n\n * ScheduleToStart is the maximum time from a requesting execution to a starting its execution. The usual reason for this timeout to fire is all being down or not being able to keep up with the request rate. We recommend setting this timeout to the maximum time a is willing to wait for an execution in the presence of all possible outages.\n * StartToClose is the maximum time an can execute after it was picked by a .\n * ScheduleToClose is the maximum time from the requesting an execution to its completion.\n * Heartbeat is the maximum time between heartbeat requests. See Long Running Activities.\n\nEither ScheduleToClose or both ScheduleToStart and StartToClose timeouts are required.\n\n# Retries\nAs Cadence doesn't recover an 's state and they can communicate to any external system, failures are expected. Therefore, Cadence supports automatic retries. Any when invoked can have an associated retry policy. Here are the retry policy parameters:\n\n * InitialInterval is a delay before the first retry.\n * BackoffCoefficient. Retry policies are exponential. The coefficient specifies how fast the retry interval is growing. The coefficient of 1 means that the retry interval is always equal to the InitialInterval.\n * MaximumInterval specifies the maximum interval between retries. Useful for coefficients more than 1.\n * MaximumAttempts specifies how many times to attempt to execute an in the presence of failures. If this limit is exceeded, the error is returned back to the that invoked the . Not required if ExpirationInterval is specified.\n * ExpirationInterval specifies for how long to attempt executing an in the presence of failures. If this interval is exceeded, the error is returned back to the that invoked the . Not required if MaximumAttempts is specified.\n * NonRetryableErrorReasons allows you to specify errors that shouldn't be retried. For example retrying invalid arguments error doesn't make sense in some scenarios.\n\nThere are scenarios when not a single but rather the whole part of a should be retried on failure. For example, a media encoding that downloads a file to a host, processes it, and then uploads the result back to storage. In this , if the host that hosts the dies, all three should be retried on a different host. Such retries should be handled by the code as they are very use case specific.\n\n# Long Running Activities\nFor long running , we recommended that you specify a relatively short heartbeat timeout and constantly heartbeat. This way failures for even very long running can be handled in a timely manner. An that specifies the heartbeat timeout is expected to call the heartbeat method periodically from its implementation.\n\nA heartbeat request can include application specific payload. This is useful to save execution progress. If an times out due to a missed heartbeat, the next attempt to execute it can access that progress and continue its execution from that point.\n\nLong running can be used as a special case of leader election. Cadence timeouts use second resolution. So it is not a solution for realtime applications. But if it is okay to react to the process failure within a few seconds, then a Cadence heartbeat is a good fit.\n\nOne common use case for such leader election is monitoring. An executes an internal loop that periodically polls some API and checks for some condition. It also heartbeats on every iteration. If the condition is satisfied, the completes which lets its to handle it. If the dies, the times out after the heartbeat interval is exceeded and is retried on a different . The same pattern works for polling for new files in Amazon S3 buckets or responses in REST or other synchronous APIs.\n\n# Cancellation\nA can request an cancellation. Currently the only way for an to learn that it was cancelled is through heart beating. The heartbeat request fails with a special error indicating that the was cancelled. Then it is up to the implementation to perform all the necessary cleanup and report that it is done with it. It is up to the implementation to decide if it wants to wait for the cancellation confirmation or just proceed without waiting.\n\nAnother common case for heartbeat failure is that the that invoked it is in a completed state. In this case an is expected to perform cleanup as well.\n\n# Activity Task Routing through Task Lists\n are dispatched to through . are queues that listen on. are highly dynamic and lightweight. They don't need to be explicitly registered. And it is okay to have one per process. It is normal to have more than one type to be invoked through a single . And it is normal in some cases (like host routing) to invoke the same type on multiple .\n\nHere are some use cases for employing multiple in a single workflow:\n\n * Flow control. A that consumes from a asks for an only when it has available capacity. So are never overloaded by request spikes. If executions are requested faster than can process them, they are backlogged in the .\n * Throttling. Each can specify the maximum rate it is allowed to processes on a . It does not exceed this limit even if it has spare capacity. There is also support for global rate limiting. This limit works across all for the given . It is frequently used to limit load on a downstream service that an calls into.\n * Deploying a set of independently. Think about a service that hosts and can be deployed independently from other and . To send to this service, a separate is needed.\n *  with different capabilities. For example, on GPU boxes vs non GPU boxes. Having two separate in this case allows to pick which one to send an execution request to.\n * Routing to a specific host. For example, in the media encoding case the transform and upload have to run on the same host as the download one.\n * Routing to a specific process. For example, some load large data sets and caches it in the process. The that rely on this data set should be routed to the same process.\n * Multiple priorities. One per priority and having a pool per priority.\n * Versioning. A new backwards incompatible implementation of an might use a different .\n\n# Asynchronous Activity Completion\nBy default an is a function or a method depending on a client side library language. As soon as the function returns, an completes. But in some cases an implementation is asynchronous. For example it is forwarded to an external system through a message queue. And the reply comes through a different queue.\n\nTo support such use cases, Cadence allows implementations that do not complete upon function completions. A separate API should be used in this case to complete the . This API can be called from any process, even in a different programming language, that the original used.\n\n# Local Activities\nSome of the are very short lived and do not need the queing semantic, flow control, rate limiting and routing capabilities. For these Cadence supports so called feature. are executed in the same process as the that invoked them. Consider using for functions that are:\n\n * no longer than a few seconds\n * do not require global rate limiting\n * do not require routing to specific or pools of \n * can be implemented in the same binary as the that invokes them\n\nThe main benefit of is that they are much more efficient in utilizing Cadence service resources and have much lower latency overhead comparing to the usual invocation.",normalizedContent:"# activities\nfault-oblivious stateful code is the core abstraction of cadence. but, due to deterministic execution requirements, they are not allowed to call any external api directly. instead they orchestrate execution of . in its simplest form, a cadence is a function or an object method in one of the supported languages. cadence does not recover state in case of failures. therefore an function is allowed to contain any code without restrictions.\n\n are invoked asynchronously through . a is essentially a queue used to store an until it is picked up by an available . the processes an by invoking its implementation function. when the function returns, the reports the result back to the cadence service which in turn notifies the about completion. it is possible to implement an fully asynchronously by completing it from a different process.\n\n# timeouts\ncadence does not impose any system limit on duration. it is up to the application to choose the timeouts for its execution. these are the configurable timeouts:\n\n * scheduletostart is the maximum time from a requesting execution to a starting its execution. the usual reason for this timeout to fire is all being down or not being able to keep up with the request rate. we recommend setting this timeout to the maximum time a is willing to wait for an execution in the presence of all possible outages.\n * starttoclose is the maximum time an can execute after it was picked by a .\n * scheduletoclose is the maximum time from the requesting an execution to its completion.\n * heartbeat is the maximum time between heartbeat requests. see long running activities.\n\neither scheduletoclose or both scheduletostart and starttoclose timeouts are required.\n\n# retries\nas cadence doesn't recover an 's state and they can communicate to any external system, failures are expected. therefore, cadence supports automatic retries. any when invoked can have an associated retry policy. here are the retry policy parameters:\n\n * initialinterval is a delay before the first retry.\n * backoffcoefficient. retry policies are exponential. the coefficient specifies how fast the retry interval is growing. the coefficient of 1 means that the retry interval is always equal to the initialinterval.\n * maximuminterval specifies the maximum interval between retries. useful for coefficients more than 1.\n * maximumattempts specifies how many times to attempt to execute an in the presence of failures. if this limit is exceeded, the error is returned back to the that invoked the . not required if expirationinterval is specified.\n * expirationinterval specifies for how long to attempt executing an in the presence of failures. if this interval is exceeded, the error is returned back to the that invoked the . not required if maximumattempts is specified.\n * nonretryableerrorreasons allows you to specify errors that shouldn't be retried. for example retrying invalid arguments error doesn't make sense in some scenarios.\n\nthere are scenarios when not a single but rather the whole part of a should be retried on failure. for example, a media encoding that downloads a file to a host, processes it, and then uploads the result back to storage. in this , if the host that hosts the dies, all three should be retried on a different host. such retries should be handled by the code as they are very use case specific.\n\n# long running activities\nfor long running , we recommended that you specify a relatively short heartbeat timeout and constantly heartbeat. this way failures for even very long running can be handled in a timely manner. an that specifies the heartbeat timeout is expected to call the heartbeat method periodically from its implementation.\n\na heartbeat request can include application specific payload. this is useful to save execution progress. if an times out due to a missed heartbeat, the next attempt to execute it can access that progress and continue its execution from that point.\n\nlong running can be used as a special case of leader election. cadence timeouts use second resolution. so it is not a solution for realtime applications. but if it is okay to react to the process failure within a few seconds, then a cadence heartbeat is a good fit.\n\none common use case for such leader election is monitoring. an executes an internal loop that periodically polls some api and checks for some condition. it also heartbeats on every iteration. if the condition is satisfied, the completes which lets its to handle it. if the dies, the times out after the heartbeat interval is exceeded and is retried on a different . the same pattern works for polling for new files in amazon s3 buckets or responses in rest or other synchronous apis.\n\n# cancellation\na can request an cancellation. currently the only way for an to learn that it was cancelled is through heart beating. the heartbeat request fails with a special error indicating that the was cancelled. then it is up to the implementation to perform all the necessary cleanup and report that it is done with it. it is up to the implementation to decide if it wants to wait for the cancellation confirmation or just proceed without waiting.\n\nanother common case for heartbeat failure is that the that invoked it is in a completed state. in this case an is expected to perform cleanup as well.\n\n# activity task routing through task lists\n are dispatched to through . are queues that listen on. are highly dynamic and lightweight. they don't need to be explicitly registered. and it is okay to have one per process. it is normal to have more than one type to be invoked through a single . and it is normal in some cases (like host routing) to invoke the same type on multiple .\n\nhere are some use cases for employing multiple in a single workflow:\n\n * flow control. a that consumes from a asks for an only when it has available capacity. so are never overloaded by request spikes. if executions are requested faster than can process them, they are backlogged in the .\n * throttling. each can specify the maximum rate it is allowed to processes on a . it does not exceed this limit even if it has spare capacity. there is also support for global rate limiting. this limit works across all for the given . it is frequently used to limit load on a downstream service that an calls into.\n * deploying a set of independently. think about a service that hosts and can be deployed independently from other and . to send to this service, a separate is needed.\n *  with different capabilities. for example, on gpu boxes vs non gpu boxes. having two separate in this case allows to pick which one to send an execution request to.\n * routing to a specific host. for example, in the media encoding case the transform and upload have to run on the same host as the download one.\n * routing to a specific process. for example, some load large data sets and caches it in the process. the that rely on this data set should be routed to the same process.\n * multiple priorities. one per priority and having a pool per priority.\n * versioning. a new backwards incompatible implementation of an might use a different .\n\n# asynchronous activity completion\nby default an is a function or a method depending on a client side library language. as soon as the function returns, an completes. but in some cases an implementation is asynchronous. for example it is forwarded to an external system through a message queue. and the reply comes through a different queue.\n\nto support such use cases, cadence allows implementations that do not complete upon function completions. a separate api should be used in this case to complete the . this api can be called from any process, even in a different programming language, that the original used.\n\n# local activities\nsome of the are very short lived and do not need the queing semantic, flow control, rate limiting and routing capabilities. for these cadence supports so called feature. are executed in the same process as the that invoked them. consider using for functions that are:\n\n * no longer than a few seconds\n * do not require global rate limiting\n * do not require routing to specific or pools of \n * can be implemented in the same binary as the that invokes them\n\nthe main benefit of is that they are much more efficient in utilizing cadence service resources and have much lower latency overhead comparing to the usual invocation.",charsets:{}},{title:"Event handling",frontmatter:{layout:"default",title:"Event handling",permalink:"/docs/concepts/events",readingShow:"top"},regularPath:"/docs/02-concepts/03-events.html",relativePath:"docs/02-concepts/03-events.md",key:"v-2cb6c482",path:"/docs/concepts/events/",headers:[{level:2,title:"Event Aggregation and Correlation",slug:"event-aggregation-and-correlation",normalizedTitle:"event aggregation and correlation",charIndex:246},{level:2,title:"Human Tasks",slug:"human-tasks",normalizedTitle:"human tasks",charIndex:1864},{level:2,title:"Process Execution Alteration",slug:"process-execution-alteration",normalizedTitle:"process execution alteration",charIndex:2444},{level:2,title:"Synchronization",slug:"synchronization",normalizedTitle:"synchronization",charIndex:2961}],headersStr:"Event Aggregation and Correlation Human Tasks Process Execution Alteration Synchronization",content:"# Event handling\nFault-oblivious stateful can be about an external . A is always point to point destined to a specific instance. are always processed in the order in which they are received.\n\nThere are multiple scenarios for which are useful.\n\n# Event Aggregation and Correlation\nCadence is not a replacement for generic stream processing engines like Apache Flink or Apache Spark. But in certain scenarios it is a better fit. For example, when all that should be aggregated and correlated are always applied to to some business entity with a clear ID. And then when a certain condition is met, actions should be executed.\n\nThe main limitation is that a single Cadence has a pretty limited throughput, while the number of is practically unlimited. So if you need to aggregate per customer, and your application has 100 million customers and each customer doesn't generate more than 20 per second, then Cadence would work fine. But if you want to aggregate all for US customers then the rate of these would be beyond the single capacity.\n\nFor example, an IoT device generates and a certain sequence of indicates that the device should be reprovisioned. A instance per device would be created and each instance would manage the state machine of the device and execute reprovision when necessary.\n\nAnother use case is a customer loyalty program. Every time a customer makes a purchase, an is generated into Apache Kafka for downstream systems to process. A loyalty service Kafka consumer receives the and a customer about the purchase using the Cadence signalWorkflowExecution API. The accumulates the count of the purchases. If a specified threshold is achieved, the executes an that notifies some external service that the customer has reached the next level of loyalty program. The also executes to periodically message the customer about their current status.\n\n# Human Tasks\nA lot of business processes involve human participants. The standard Cadence pattern for implementing an external interaction is to execute an that creates a human in an external system. It can be an email with a form, or a record in some external database, or a mobile app notification. When a user changes the status of the , a is sent to the corresponding . For example, when the form is submitted, or a mobile app notification is acknowledged. Some have multiple possible actions like claim, return, complete, reject. So multiple can be sent in relation to it.\n\n# Process Execution Alteration\nSome business processes should change their behavior if some external has happened. For example, while executing an order shipment , any change in item quantity could be delivered in a form of a .\n\nAnother example is a service deployment . While rolling out new software version to a Kubernetes cluster some problem was identified. A can be used to ask the to pause while the problem is investigated. Then either a continue or a rollback can be used to execute the appropriate action.\n\n# Synchronization\nCadence are strongly consistent so they can be used as a synchronization point for executing actions. For example, there is a requirement that all messages for a single user are processed sequentially but the underlying messaging infrastructure can deliver them in parallel. The Cadence solution would be to have a per user and it when an is received. Then the would buffer all in an internal data structure and then call an for every received. See the following Stack Overflow answer for an example.",normalizedContent:"# event handling\nfault-oblivious stateful can be about an external . a is always point to point destined to a specific instance. are always processed in the order in which they are received.\n\nthere are multiple scenarios for which are useful.\n\n# event aggregation and correlation\ncadence is not a replacement for generic stream processing engines like apache flink or apache spark. but in certain scenarios it is a better fit. for example, when all that should be aggregated and correlated are always applied to to some business entity with a clear id. and then when a certain condition is met, actions should be executed.\n\nthe main limitation is that a single cadence has a pretty limited throughput, while the number of is practically unlimited. so if you need to aggregate per customer, and your application has 100 million customers and each customer doesn't generate more than 20 per second, then cadence would work fine. but if you want to aggregate all for us customers then the rate of these would be beyond the single capacity.\n\nfor example, an iot device generates and a certain sequence of indicates that the device should be reprovisioned. a instance per device would be created and each instance would manage the state machine of the device and execute reprovision when necessary.\n\nanother use case is a customer loyalty program. every time a customer makes a purchase, an is generated into apache kafka for downstream systems to process. a loyalty service kafka consumer receives the and a customer about the purchase using the cadence signalworkflowexecution api. the accumulates the count of the purchases. if a specified threshold is achieved, the executes an that notifies some external service that the customer has reached the next level of loyalty program. the also executes to periodically message the customer about their current status.\n\n# human tasks\na lot of business processes involve human participants. the standard cadence pattern for implementing an external interaction is to execute an that creates a human in an external system. it can be an email with a form, or a record in some external database, or a mobile app notification. when a user changes the status of the , a is sent to the corresponding . for example, when the form is submitted, or a mobile app notification is acknowledged. some have multiple possible actions like claim, return, complete, reject. so multiple can be sent in relation to it.\n\n# process execution alteration\nsome business processes should change their behavior if some external has happened. for example, while executing an order shipment , any change in item quantity could be delivered in a form of a .\n\nanother example is a service deployment . while rolling out new software version to a kubernetes cluster some problem was identified. a can be used to ask the to pause while the problem is investigated. then either a continue or a rollback can be used to execute the appropriate action.\n\n# synchronization\ncadence are strongly consistent so they can be used as a synchronization point for executing actions. for example, there is a requirement that all messages for a single user are processed sequentially but the underlying messaging infrastructure can deliver them in parallel. the cadence solution would be to have a per user and it when an is received. then the would buffer all in an internal data structure and then call an for every received. see the following stack overflow answer for an example.",charsets:{}},{title:"Synchronous query",frontmatter:{layout:"default",title:"Synchronous query",permalink:"/docs/concepts/queries",readingShow:"top"},regularPath:"/docs/02-concepts/04-queries.html",relativePath:"docs/02-concepts/04-queries.md",key:"v-55ad5442",path:"/docs/concepts/queries/",headers:[{level:2,title:"Stack Trace Query",slug:"stack-trace-query",normalizedTitle:"stack trace query",charIndex:980}],headersStr:"Stack Trace Query",content:"# Synchronous query\n code is stateful with the Cadence framework preserving it over various software and hardware failures. The state is constantly mutated during . To expose this internal state to the external world Cadence provides a synchronous feature. From the implementer point of view the is exposed as a synchronous callback that is invoked by external entities. Multiple such callbacks can be provided per type exposing different information to different external systems.\n\nTo execute a an external client calls a synchronous Cadence API providing , workflowID, name and optional arguments.\n\n callbacks must be read-only not mutating the state in any way. The other limitation is that the callback cannot contain any blocking code. Both above limitations rule out ability to invoke from the handlers.\n\nCadence team is currently working on implementing update feature that would be similar to in the way it is invoked, but would support state mutation and invocations.\n\n# Stack Trace Query\nThe Cadence client libraries expose some predefined out of the box. Currently the only supported built-in is stack_trace. This returns stacks of all owned threads. This is a great way to troubleshoot any in production.",normalizedContent:"# synchronous query\n code is stateful with the cadence framework preserving it over various software and hardware failures. the state is constantly mutated during . to expose this internal state to the external world cadence provides a synchronous feature. from the implementer point of view the is exposed as a synchronous callback that is invoked by external entities. multiple such callbacks can be provided per type exposing different information to different external systems.\n\nto execute a an external client calls a synchronous cadence api providing , workflowid, name and optional arguments.\n\n callbacks must be read-only not mutating the state in any way. the other limitation is that the callback cannot contain any blocking code. both above limitations rule out ability to invoke from the handlers.\n\ncadence team is currently working on implementing update feature that would be similar to in the way it is invoked, but would support state mutation and invocations.\n\n# stack trace query\nthe cadence client libraries expose some predefined out of the box. currently the only supported built-in is stack_trace. this returns stacks of all owned threads. this is a great way to troubleshoot any in production.",charsets:{}},{title:"Deployment topology",frontmatter:{layout:"default",title:"Deployment topology",permalink:"/docs/concepts/topology",readingShow:"top"},regularPath:"/docs/02-concepts/05-topology.html",relativePath:"docs/02-concepts/05-topology.md",key:"v-b430d54c",path:"/docs/concepts/topology/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:24},{level:2,title:"Cadence Service",slug:"cadence-service",normalizedTitle:"cadence service",charIndex:459},{level:2,title:"Workflow Worker",slug:"workflow-worker",normalizedTitle:"workflow worker",charIndex:1413},{level:2,title:"Activity Worker",slug:"activity-worker",normalizedTitle:"activity worker",charIndex:2482},{level:2,title:"External Clients",slug:"external-clients",normalizedTitle:"external clients",charIndex:3174}],headersStr:"Overview Cadence Service Workflow Worker Activity Worker External Clients",content:"# Deployment topology\n# Overview\nCadence is a highly scalable fault-oblivious stateful code platform. The fault-oblivious code is a next level of abstraction over commonly used techniques to achieve fault tolerance and durability.\n\nA common Cadence-based application consists of a Cadence service, and , and external clients. Note that both types of as well as external clients are roles and can be collocated in a single application process if necessary.\n\n# Cadence Service\n\n\nAt the core of Cadence is a highly scalable multitentant service. The service exposes all its functionality through a strongly typed Thrift API.\n\nInternally it depends on a persistent store. Currently, Apache Cassandra and MySQL stores are supported out of the box. For listing using complex predicates, Elasticsearch cluster can be used.\n\nCadence service is responsible for keeping state and associated durable timers. It maintains internal queues (called ) which are used to dispatch to external .\n\nCadence service is multitentant. Therefore it is expected that multiple pools of implementing different use cases connect to the same service instance. For example, at Uber a single service is used by more than a hundred applications. At the same time some external customers deploy an instance of Cadence service per application. For local development, a local Cadence service instance configured through docker-compose is used.\n\n\n\n# Workflow Worker\nCadence reuses terminology from workflow automation . So fault-oblivious stateful code is called .\n\nThe Cadence service does not execute code directly. The code is hosted by an external (from the service point of view) process. These processes receive that contain that the is expected to handle from the Cadence service, delivers them to the code, and communicates back to the service.\n\nAs code is external to the service, it can be implemented in any language that can talk service Thrift API. Currently Java and Go clients are production ready. While Python and C# clients are under development. Let us know if you are interested in contributing a client in your preferred language.\n\nThe Cadence service API doesn't impose any specific definition language. So a specific can be implemented to execute practically any existing specification. The model the Cadence team chose to support out of the box is based on the idea of durable function. Durable functions are as close as possible to application business logic with minimal plumbing required.\n\n# Activity Worker\n fault-oblivious code is immune to infrastructure failures. But it has to communicate with the imperfect external world where failures are common. All communication to the external world is done through . are pieces of code that can perform any application-specific action like calling a service, updating a database record, or downloading a file from Amazon S3. Cadence are very feature-rich compared to queuing systems. Example features are routing to specific processes, infinite retries, heartbeats, and unlimited execution time.\n\n are hosted by processes that receive from the Cadence service, invoke correspondent implementations and report back completion statuses.\n\n# External Clients\n and host and code. But to create a instance (an execution in Cadence terminology) the StartWorkflowExecution Cadence service API call should be used. Usually, are started by outside entities like UIs, microservices or CLIs.\n\nThese entities can also:\n\n * notify about asynchronous external in the form of \n * synchronously state\n * synchronously wait for a completion\n * cancel, terminate, restart, and reset \n * search for specific using list API",normalizedContent:"# deployment topology\n# overview\ncadence is a highly scalable fault-oblivious stateful code platform. the fault-oblivious code is a next level of abstraction over commonly used techniques to achieve fault tolerance and durability.\n\na common cadence-based application consists of a cadence service, and , and external clients. note that both types of as well as external clients are roles and can be collocated in a single application process if necessary.\n\n# cadence service\n\n\nat the core of cadence is a highly scalable multitentant service. the service exposes all its functionality through a strongly typed thrift api.\n\ninternally it depends on a persistent store. currently, apache cassandra and mysql stores are supported out of the box. for listing using complex predicates, elasticsearch cluster can be used.\n\ncadence service is responsible for keeping state and associated durable timers. it maintains internal queues (called ) which are used to dispatch to external .\n\ncadence service is multitentant. therefore it is expected that multiple pools of implementing different use cases connect to the same service instance. for example, at uber a single service is used by more than a hundred applications. at the same time some external customers deploy an instance of cadence service per application. for local development, a local cadence service instance configured through docker-compose is used.\n\n\n\n# workflow worker\ncadence reuses terminology from workflow automation . so fault-oblivious stateful code is called .\n\nthe cadence service does not execute code directly. the code is hosted by an external (from the service point of view) process. these processes receive that contain that the is expected to handle from the cadence service, delivers them to the code, and communicates back to the service.\n\nas code is external to the service, it can be implemented in any language that can talk service thrift api. currently java and go clients are production ready. while python and c# clients are under development. let us know if you are interested in contributing a client in your preferred language.\n\nthe cadence service api doesn't impose any specific definition language. so a specific can be implemented to execute practically any existing specification. the model the cadence team chose to support out of the box is based on the idea of durable function. durable functions are as close as possible to application business logic with minimal plumbing required.\n\n# activity worker\n fault-oblivious code is immune to infrastructure failures. but it has to communicate with the imperfect external world where failures are common. all communication to the external world is done through . are pieces of code that can perform any application-specific action like calling a service, updating a database record, or downloading a file from amazon s3. cadence are very feature-rich compared to queuing systems. example features are routing to specific processes, infinite retries, heartbeats, and unlimited execution time.\n\n are hosted by processes that receive from the cadence service, invoke correspondent implementations and report back completion statuses.\n\n# external clients\n and host and code. but to create a instance (an execution in cadence terminology) the startworkflowexecution cadence service api call should be used. usually, are started by outside entities like uis, microservices or clis.\n\nthese entities can also:\n\n * notify about asynchronous external in the form of \n * synchronously state\n * synchronously wait for a completion\n * cancel, terminate, restart, and reset \n * search for specific using list api",charsets:{}},{title:"Task lists",frontmatter:{layout:"default",title:"Task lists",permalink:"/docs/concepts/task-lists",readingShow:"top"},regularPath:"/docs/02-concepts/06-task-lists.html",relativePath:"docs/02-concepts/06-task-lists.md",key:"v-6695c940",path:"/docs/concepts/task-lists/",headersStr:null,content:"# Task lists\nWhen a invokes an , it sends the ScheduleActivityTask to the Cadence service. As a result, the service updates the state and dispatches an to a that implements the . Instead of calling the directly, an intermediate queue is used. So the service adds an to this queue and a receives the using a long poll request. Cadence calls this queue used to dispatch an .\n\nSimilarly, when a needs to handle an external , a is created. A is used to deliver it to the (also called decider).\n\nWhile Cadence are queues, they have some differences from commonly used queuing technologies. The main one is that they do not require explicit registration and are created on demand. The number of is not limited. A common use case is to have a per process and use it to deliver to the process. Another use case is to have a per pool of .\n\nThere are multiple advantages of using a to deliver instead of invoking an through a synchronous RPC:\n\n *  doesn't need to have any open ports, which is more secure.\n *  doesn't need to advertise itself through DNS or any other network discovery mechanism.\n * When all are down, messages are persisted in a waiting for the to recover.\n * A polls for a message only when it has spare capacity, so it never gets overloaded.\n * Automatic load balancing across a large number of .\n *  support server side throttling. This allows you to limit the dispatch rate to the pool of and still supports adding a with a higher rate when spikes happen.\n *  can be used to route a request to specific pools of or even a specific process.",normalizedContent:"# task lists\nwhen a invokes an , it sends the scheduleactivitytask to the cadence service. as a result, the service updates the state and dispatches an to a that implements the . instead of calling the directly, an intermediate queue is used. so the service adds an to this queue and a receives the using a long poll request. cadence calls this queue used to dispatch an .\n\nsimilarly, when a needs to handle an external , a is created. a is used to deliver it to the (also called decider).\n\nwhile cadence are queues, they have some differences from commonly used queuing technologies. the main one is that they do not require explicit registration and are created on demand. the number of is not limited. a common use case is to have a per process and use it to deliver to the process. another use case is to have a per pool of .\n\nthere are multiple advantages of using a to deliver instead of invoking an through a synchronous rpc:\n\n *  doesn't need to have any open ports, which is more secure.\n *  doesn't need to advertise itself through dns or any other network discovery mechanism.\n * when all are down, messages are persisted in a waiting for the to recover.\n * a polls for a message only when it has spare capacity, so it never gets overloaded.\n * automatic load balancing across a large number of .\n *  support server side throttling. this allows you to limit the dispatch rate to the pool of and still supports adding a with a higher rate when spikes happen.\n *  can be used to route a request to specific pools of or even a specific process.",charsets:{}},{title:"Archival",frontmatter:{layout:"default",title:"Archival",permalink:"/docs/concepts/archival",readingShow:"top"},regularPath:"/docs/02-concepts/07-archival.html",relativePath:"docs/02-concepts/07-archival.md",key:"v-3c8e9720",path:"/docs/concepts/archival/",headers:[{level:2,title:"Concepts",slug:"concepts",normalizedTitle:"concepts",charIndex:1026},{level:2,title:"Configuring Archival",slug:"configuring-archival",normalizedTitle:"configuring archival",charIndex:1457},{level:3,title:"Cluster Archival Config",slug:"cluster-archival-config",normalizedTitle:"cluster archival config",charIndex:1543},{level:3,title:"Domain Archival Config",slug:"domain-archival-config",normalizedTitle:"domain archival config",charIndex:2172},{level:2,title:"Running Locally",slug:"running-locally",normalizedTitle:"running locally",charIndex:2611},{level:2,title:"FAQ",slug:"faq",normalizedTitle:"faq",charIndex:3357},{level:3,title:"How does archival interact with global domains?",slug:"how-does-archival-interact-with-global-domains",normalizedTitle:"how does archival interact with global domains?",charIndex:3363},{level:3,title:"Can I specify multiple archival URIs?",slug:"can-i-specify-multiple-archival-uris",normalizedTitle:"can i specify multiple archival uris?",charIndex:3634},{level:3,title:"How does archival work with PII?",slug:"how-does-archival-work-with-pii",normalizedTitle:"how does archival work with pii?",charIndex:3818},{level:2,title:"Planned Future Work",slug:"planned-future-work",normalizedTitle:"planned future work",charIndex:4120}],headersStr:"Concepts Configuring Archival Cluster Archival Config Domain Archival Config Running Locally FAQ How does archival interact with global domains? Can I specify multiple archival URIs? How does archival work with PII? Planned Future Work",content:"# Archival\n is a feature that automatically moves histories from persistence to another location after the retention period. The purpose of archival is to be able to keep histories as long as needed while not overwhelming the persistence store. There are two reasons you may want to keep the histories after the retention period has past:\n\n 1. Compliance: For legal reasons histories may need to be stored for a long period of time.\n 2. Debugging: Old histories can still be accessed for debugging.\n\n is still in beta and there are three limits to its feature set:\n\n 1. Only Histories: Only histories are archived, visibility records are simply deleted after the retention period.\n 2. RunID Required: In order to access an archived history, both workflowID and runID are required.\n 3. Best Effort: There are cases in which a history can be deleted from persistence without being archived first. These cases are rare but are possible with the current state of .\n\nWork is being prioritized on to eliminate these limitations.\n\n# Concepts\n * Archiver: Archiver is the component responsible for archiving and retrieving histories. Its interface is quite generic and supports different kinds of locations: local file system, S3, Kafka, etc. Check this README for how to add a new archiver implementation.\n * URI: An URI is used to specify the location. Based on the scheme part of an URI, the corresponding archiver will be selected by the system to perform .\n\n# Configuring Archival\n is controlled by both level config and cluster level config.\n\n# Cluster Archival Config\nA Cadence cluster can be in one of three states:\n\n * Disabled: No will occur and the archivers will be not initialized on startup.\n * Paused: This state is not yet implemented. Currently setting cluster to paused is the same as setting it to disabled.\n * Enabled: will occur.\n\nEnabling the cluster for simply means histories are being archived. There is another config which controls whether histories can be accessed from . Both these configs have defaults defined in static yaml, and have dynamic config overwrites. Note, however, dynamic config will take effect only when is enabled in static yaml.\n\n# Domain Archival Config\nA includes two pieces of related config:\n\n * Status: Either enabled or disabled. If a is in the disabled state no will occur for that . A can safely switch between statuses.\n * URI: The scheme and location where histories will be archived to. When a enables for the first time URI is set and can never be mutated. If URI is not specified when first enabling a for , a default URI from static config will be used.\n\n# Running Locally\nIn order to run locally do the following:\n\n 1. ./cadence-server start\n 2. ./cadence --do samples-domain domain register --gd false --history_archival_status enabled --retention 0\n 3. Run the helloworld cadence-sample by following the README\n 4. Copy the workflowID and runID of the completed from log output\n 5. ./cadence --do samples-domain wf show --wid <workflowID> --rid <runID>\n\nIn step 2, we registered a new and enabled history feature for that . Since we didn't provide an URI when registering the new , the default URI specified in config/development.yaml is used. The default URI is file:///tmp/cadence_archival/development, so you can find the archived history under the /tmp/cadence_archival/development directory.\n\n# FAQ\n# How does archival interact with global domains?\nWhen occurs it will first run on the active side and some time later it will run on the standby side as well. Before uploading history a check is done to see if it has already been uploaded, if so it is not re-uploaded.\n\n# Can I specify multiple archival URIs?\nNo, each can only have one URI for history and one URI for visibility . Different , however, can have different URIs (with different schemes).\n\n# How does archival work with PII?\nNo cadence should ever operate on clear text PII. Cadence can be thought of as a database and just as one would not store PII in a database PII should not be stored in Cadence. This is even more important when is enabled because these histories can be kept forever.\n\n# Planned Future Work\n * Support of visibility.\n * Support accessing histories without providing runID.\n * Provide hard guarantee that no history is deleted from persistence before being archived if is enabled.\n * Implement paused state. In this state no will occur but histories also will not be deleted from persistence. Once enabled again from paused state, all skipped will occur.",normalizedContent:"# archival\n is a feature that automatically moves histories from persistence to another location after the retention period. the purpose of archival is to be able to keep histories as long as needed while not overwhelming the persistence store. there are two reasons you may want to keep the histories after the retention period has past:\n\n 1. compliance: for legal reasons histories may need to be stored for a long period of time.\n 2. debugging: old histories can still be accessed for debugging.\n\n is still in beta and there are three limits to its feature set:\n\n 1. only histories: only histories are archived, visibility records are simply deleted after the retention period.\n 2. runid required: in order to access an archived history, both workflowid and runid are required.\n 3. best effort: there are cases in which a history can be deleted from persistence without being archived first. these cases are rare but are possible with the current state of .\n\nwork is being prioritized on to eliminate these limitations.\n\n# concepts\n * archiver: archiver is the component responsible for archiving and retrieving histories. its interface is quite generic and supports different kinds of locations: local file system, s3, kafka, etc. check this readme for how to add a new archiver implementation.\n * uri: an uri is used to specify the location. based on the scheme part of an uri, the corresponding archiver will be selected by the system to perform .\n\n# configuring archival\n is controlled by both level config and cluster level config.\n\n# cluster archival config\na cadence cluster can be in one of three states:\n\n * disabled: no will occur and the archivers will be not initialized on startup.\n * paused: this state is not yet implemented. currently setting cluster to paused is the same as setting it to disabled.\n * enabled: will occur.\n\nenabling the cluster for simply means histories are being archived. there is another config which controls whether histories can be accessed from . both these configs have defaults defined in static yaml, and have dynamic config overwrites. note, however, dynamic config will take effect only when is enabled in static yaml.\n\n# domain archival config\na includes two pieces of related config:\n\n * status: either enabled or disabled. if a is in the disabled state no will occur for that . a can safely switch between statuses.\n * uri: the scheme and location where histories will be archived to. when a enables for the first time uri is set and can never be mutated. if uri is not specified when first enabling a for , a default uri from static config will be used.\n\n# running locally\nin order to run locally do the following:\n\n 1. ./cadence-server start\n 2. ./cadence --do samples-domain domain register --gd false --history_archival_status enabled --retention 0\n 3. run the helloworld cadence-sample by following the readme\n 4. copy the workflowid and runid of the completed from log output\n 5. ./cadence --do samples-domain wf show --wid <workflowid> --rid <runid>\n\nin step 2, we registered a new and enabled history feature for that . since we didn't provide an uri when registering the new , the default uri specified in config/development.yaml is used. the default uri is file:///tmp/cadence_archival/development, so you can find the archived history under the /tmp/cadence_archival/development directory.\n\n# faq\n# how does archival interact with global domains?\nwhen occurs it will first run on the active side and some time later it will run on the standby side as well. before uploading history a check is done to see if it has already been uploaded, if so it is not re-uploaded.\n\n# can i specify multiple archival uris?\nno, each can only have one uri for history and one uri for visibility . different , however, can have different uris (with different schemes).\n\n# how does archival work with pii?\nno cadence should ever operate on clear text pii. cadence can be thought of as a database and just as one would not store pii in a database pii should not be stored in cadence. this is even more important when is enabled because these histories can be kept forever.\n\n# planned future work\n * support of visibility.\n * support accessing histories without providing runid.\n * provide hard guarantee that no history is deleted from persistence before being archived if is enabled.\n * implement paused state. in this state no will occur but histories also will not be deleted from persistence. once enabled again from paused state, all skipped will occur.",charsets:{}},{title:"Cross DC replication",frontmatter:{layout:"default",title:"Cross DC replication",permalink:"/docs/concepts/cross-dc-replication",readingShow:"top"},regularPath:"/docs/02-concepts/08-cross-dc-replication.html",relativePath:"docs/02-concepts/08-cross-dc-replication.md",key:"v-d2d99830",path:"/docs/concepts/cross-dc-replication/",headers:[{level:2,title:"Global Domains Architecture",slug:"global-domains-architecture",normalizedTitle:"global domains architecture",charIndex:298},{level:2,title:"New config for Global Domains",slug:"new-config-for-global-domains",normalizedTitle:"new config for global domains",charIndex:1334},{level:3,title:"IsGlobal",slug:"isglobal",normalizedTitle:"isglobal",charIndex:1366},{level:3,title:"Clusters",slug:"clusters",normalizedTitle:"clusters",charIndex:1630},{level:3,title:"Active Cluster Name",slug:"active-cluster-name",normalizedTitle:"active cluster name",charIndex:1916},{level:3,title:"Failover Version",slug:"failover-version",normalizedTitle:"failover version",charIndex:2070},{level:2,title:"Conflict Resolution",slug:"conflict-resolution",normalizedTitle:"conflict resolution",charIndex:2366},{level:2,title:"Visibility API",slug:"visibility-api",normalizedTitle:"visibility api",charIndex:3193},{level:2,title:"CLI",slug:"cli",normalizedTitle:"cli",charIndex:3640},{level:3,title:"Query Global Domain",slug:"query-global-domain",normalizedTitle:"query global domain",charIndex:3743},{level:3,title:"Failover Global Domain",slug:"failover-global-domain",normalizedTitle:"failover global domain",charIndex:4102},{level:2,title:"FAQ",slug:"faq",normalizedTitle:"faq",charIndex:4266},{level:3,title:"What happens to outstanding activities after failover?",slug:"what-happens-to-outstanding-activities-after-failover",normalizedTitle:"what happens to outstanding activities after failover?",charIndex:4272},{level:3,title:"What happens when a start or signal API call is made to a standby cluster?",slug:"what-happens-when-a-start-or-signal-api-call-is-made-to-a-standby-cluster",normalizedTitle:"what happens when a start or signal api call is made to a standby cluster?",charIndex:4678},{level:3,title:"What is the recommended pattern to send external events to an active cluster?",slug:"what-is-the-recommended-pattern-to-send-external-events-to-an-active-cluster",normalizedTitle:"what is the recommended pattern to send external events to an active cluster?",charIndex:4951}],headersStr:"Global Domains Architecture New config for Global Domains IsGlobal Clusters Active Cluster Name Failover Version Conflict Resolution Visibility API CLI Query Global Domain Failover Global Domain FAQ What happens to outstanding activities after failover? What happens when a start or signal API call is made to a standby cluster? What is the recommended pattern to send external events to an active cluster?",content:"# Cross-DC replication\nThe Cadence Global feature provides clients with the capability to continue their from another cluster in the event of a datacenter failover. Although you can configure a Global to be replicated to any number of clusters, it is only considered active in a single cluster.\n\n# Global Domains Architecture\nCadence has introduced a new top level entity, Global , which provides support for replication of execution across clusters. Client applications need to run polling on / on all clusters. Cadence will only dispatch tasks on the current active cluster; on the standby cluster will sit idle until the Global is failed over.\n\nBecause Cadence is a service that provides highly consistent semantics, we only allow external likeStartWorkflowExecution, SignalWorkflowExecution, etc. on an active cluster. Global relies on light-weight transactions (paxos) on the local cluster (Local_Quorum) to update the state and create replication which are applied asynchronously to replicate state across clusters. If an application makes these API calls on a cluster where Global is in standby mode, Cadence will reject those calls with DomainNotActiveError, which contains the name of the current active cluster. It is the responsibility of the application to forward the external to the cluster that is currently active.\n\n# New config for Global Domains\n# IsGlobal\nThis config is used to distinguish local to the cluster from the global . It controls the creation of replication on updates allowing the state to be replicated across clusters. This is a read-only setting that can only be set when the is provisioned.\n\n# Clusters\nA list of clusters where the can fail over to, including the current active cluster. This is also a read-only setting that can only be set when the is provisioned. A re-replication feature on the roadmap will allow updating this config to add/remove clusters in the future.\n\n# Active Cluster Name\nName of the current active cluster for the Global . This config is updated each time the Global is failed over to another cluster.\n\n# Failover Version\nUnique failover version which also represents the current active cluster for Global . Cadence allows failover to be triggered from any cluster, so failover version is designed in a way to not allow conflicts if failover is mistakenly triggered simultaneously on two clusters.\n\n# Conflict Resolution\nUnlike local which provide at-most-once semantics for execution, Global can only support at-least-once semantics. Cadence XDC relies on asynchronous replication of across clusters, so in the event of a failover it is possible that gets dispatched again on the new active cluster due to a replication lag. This also means that whenever is updated after a failover by the new cluster, any previous replication for that execution cannot be applied. This results in loss of some progress made by the in the previous active cluster. During such conflict resolution, Cadence re-injects any external like to the new history before discarding replication . Even though some progress could rollback during failovers, Cadence provides the guarantee that won’t get stuck and will continue to make forward progress.\n\n# Visibility API\nAll Visibility APIs are allowed on both active and standby clusters. This enablesCadence Web to work seamlessly for Global as all visibility records for can be queried from any cluster the is replicated to. Applications making API calls directly to the Cadence Visibility API will continue to work even if a Global is in standby mode. However, they might see a lag due to replication delay when the state from a standby cluster.\n\n# CLI\nThe Cadence can also be used to the config or perform failovers. Here are some useful commands.\n\n# Query Global Domain\nThe following command can be used to describe Global metadata:\n\n$ cadence --do cadence-canary-xdc d desc\nName: cadence-canary-xdc\nDescription: cadence canary cross dc testing domain\nOwnerEmail: cadence-dev@cadenceworkflow.io\nDomainData:\nStatus: REGISTERED\nRetentionInDays: 7\nEmitMetrics: true\nActiveClusterName: dc1\nClusters: dc1, dc2\n\n\n# Failover Global Domain\nThe following command can be used to failover Global my-domain-global to the dc2 cluster:\n\n$ cadence --do my-domain-global d up --ac dc2\n\n\n# FAQ\n# What happens to outstanding activities after failover?\nCadence does not forward completions across clusters. Any outstanding will eventually timeout based on the configuration. Your application should have retry logic in place so that the gets retried and dispatched again to a after the failover to the new DC. Handling this is pretty much the same as timeout caused by a restart even without Global .\n\n# What happens when a start or signal API call is made to a standby cluster?\nCadence will reject the call and return DomainNotActiveError. It is the responsibility of the application to forward the failed call to active cluster based on information provided in the error.\n\n# What is the recommended pattern to send external events to an active cluster?\nThe recommendation at this point is to publish to a Kafka topic if they can be generated in any DC. Then, have a consumer that consumes from the aggregated Kafka topic in the same DC and sends them to Cadence. Both the Kafka consumer and Global need to be failed over together.",normalizedContent:"# cross-dc replication\nthe cadence global feature provides clients with the capability to continue their from another cluster in the event of a datacenter failover. although you can configure a global to be replicated to any number of clusters, it is only considered active in a single cluster.\n\n# global domains architecture\ncadence has introduced a new top level entity, global , which provides support for replication of execution across clusters. client applications need to run polling on / on all clusters. cadence will only dispatch tasks on the current active cluster; on the standby cluster will sit idle until the global is failed over.\n\nbecause cadence is a service that provides highly consistent semantics, we only allow external likestartworkflowexecution, signalworkflowexecution, etc. on an active cluster. global relies on light-weight transactions (paxos) on the local cluster (local_quorum) to update the state and create replication which are applied asynchronously to replicate state across clusters. if an application makes these api calls on a cluster where global is in standby mode, cadence will reject those calls with domainnotactiveerror, which contains the name of the current active cluster. it is the responsibility of the application to forward the external to the cluster that is currently active.\n\n# new config for global domains\n# isglobal\nthis config is used to distinguish local to the cluster from the global . it controls the creation of replication on updates allowing the state to be replicated across clusters. this is a read-only setting that can only be set when the is provisioned.\n\n# clusters\na list of clusters where the can fail over to, including the current active cluster. this is also a read-only setting that can only be set when the is provisioned. a re-replication feature on the roadmap will allow updating this config to add/remove clusters in the future.\n\n# active cluster name\nname of the current active cluster for the global . this config is updated each time the global is failed over to another cluster.\n\n# failover version\nunique failover version which also represents the current active cluster for global . cadence allows failover to be triggered from any cluster, so failover version is designed in a way to not allow conflicts if failover is mistakenly triggered simultaneously on two clusters.\n\n# conflict resolution\nunlike local which provide at-most-once semantics for execution, global can only support at-least-once semantics. cadence xdc relies on asynchronous replication of across clusters, so in the event of a failover it is possible that gets dispatched again on the new active cluster due to a replication lag. this also means that whenever is updated after a failover by the new cluster, any previous replication for that execution cannot be applied. this results in loss of some progress made by the in the previous active cluster. during such conflict resolution, cadence re-injects any external like to the new history before discarding replication . even though some progress could rollback during failovers, cadence provides the guarantee that won’t get stuck and will continue to make forward progress.\n\n# visibility api\nall visibility apis are allowed on both active and standby clusters. this enablescadence web to work seamlessly for global as all visibility records for can be queried from any cluster the is replicated to. applications making api calls directly to the cadence visibility api will continue to work even if a global is in standby mode. however, they might see a lag due to replication delay when the state from a standby cluster.\n\n# cli\nthe cadence can also be used to the config or perform failovers. here are some useful commands.\n\n# query global domain\nthe following command can be used to describe global metadata:\n\n$ cadence --do cadence-canary-xdc d desc\nname: cadence-canary-xdc\ndescription: cadence canary cross dc testing domain\nowneremail: cadence-dev@cadenceworkflow.io\ndomaindata:\nstatus: registered\nretentionindays: 7\nemitmetrics: true\nactiveclustername: dc1\nclusters: dc1, dc2\n\n\n# failover global domain\nthe following command can be used to failover global my-domain-global to the dc2 cluster:\n\n$ cadence --do my-domain-global d up --ac dc2\n\n\n# faq\n# what happens to outstanding activities after failover?\ncadence does not forward completions across clusters. any outstanding will eventually timeout based on the configuration. your application should have retry logic in place so that the gets retried and dispatched again to a after the failover to the new dc. handling this is pretty much the same as timeout caused by a restart even without global .\n\n# what happens when a start or signal api call is made to a standby cluster?\ncadence will reject the call and return domainnotactiveerror. it is the responsibility of the application to forward the failed call to active cluster based on information provided in the error.\n\n# what is the recommended pattern to send external events to an active cluster?\nthe recommendation at this point is to publish to a kafka topic if they can be generated in any dc. then, have a consumer that consumes from the aggregated kafka topic in the same dc and sends them to cadence. both the kafka consumer and global need to be failed over together.",charsets:{}},{title:"Search and filtering workflows",frontmatter:{layout:"default",title:"Search and filtering workflows",permalink:"/docs/concepts/search-workflows",readingShow:"top"},regularPath:"/docs/02-concepts/09-search-workflows.html",relativePath:"docs/02-concepts/09-search-workflows.md",key:"v-750c7ee2",path:"/docs/concepts/search-workflows/",headers:[{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:34},{level:2,title:"Memo vs Search Attributes",slug:"memo-vs-search-attributes",normalizedTitle:"memo vs search attributes",charIndex:665},{level:2,title:"Search Attributes (Go Client Usage)",slug:"search-attributes-go-client-usage",normalizedTitle:"search attributes (go client usage)",charIndex:2341},{level:3,title:"Allow Listing Search Attributes",slug:"allow-listing-search-attributes",normalizedTitle:"allow listing search attributes",charIndex:2693},{level:3,title:"Value Types",slug:"value-types",normalizedTitle:"value types",charIndex:4761},{level:3,title:"Limit",slug:"limit",normalizedTitle:"limit",charIndex:4970},{level:3,title:"Upsert Search Attributes in Workflow",slug:"upsert-search-attributes-in-workflow",normalizedTitle:"upsert search attributes in workflow",charIndex:5303},{level:3,title:"ContinueAsNew and Cron",slug:"continueasnew-and-cron",normalizedTitle:"continueasnew and cron",charIndex:6602},{level:2,title:"Query Capabilities",slug:"query-capabilities",normalizedTitle:"query capabilities",charIndex:6752},{level:3,title:"Supported Operators",slug:"supported-operators",normalizedTitle:"supported operators",charIndex:6931},{level:3,title:"Default Attributes",slug:"default-attributes",normalizedTitle:"default attributes",charIndex:7029},{level:3,title:"General Notes About Queries",slug:"general-notes-about-queries",normalizedTitle:"general notes about queries",charIndex:8849},{level:2,title:"Tools Support",slug:"tools-support",normalizedTitle:"tools support",charIndex:9371},{level:3,title:"CLI",slug:"cli",normalizedTitle:"cli",charIndex:456},{level:3,title:"Web UI Support",slug:"web-ui-support",normalizedTitle:"web ui support",charIndex:10768},{level:2,title:"Local Testing",slug:"local-testing",normalizedTitle:"local testing",charIndex:10930}],headersStr:"Introduction Memo vs Search Attributes Search Attributes (Go Client Usage) Allow Listing Search Attributes Value Types Limit Upsert Search Attributes in Workflow ContinueAsNew and Cron Query Capabilities Supported Operators Default Attributes General Notes About Queries Tools Support CLI Web UI Support Local Testing",content:'# Searching/Filtering Workflows\n# Introduction\nCadence supports creating with customized key-value pairs, updating the information within the code, and then listing/searching with a SQL-like . For example, you can create with keys city and age, then search all with city = seattle and age > 22.\n\nAlso note that normal properties like start time and type can be queried as well. For example, the following could be specified when listing workflows from the CLI or using the list APIs (Go, Java):\n\nWorkflowType = "main.Workflow" and CloseStatus != 0 and (StartTime > "2019-06-07T16:46:34-08:00" or CloseTime > "2019-06-07T16:46:34-08:00" order by StartTime desc)\n\n\n# Memo vs Search Attributes\nCadence offers two methods for creating with key-value pairs: memo and search attributes. Memo can only be provided on start. Also, memo data are not indexed, and are therefore not searchable. Memo data are visible when listing using the list APIs. Search attributes data are indexed so you can search by on these attributes. However, search attributes require the use of Elasticsearch.\n\nMemo and search attributes are available in the Go client in StartWorkflowOptions.\n\ntype StartWorkflowOptions struct {\n    // ...\n\n    // Memo - Optional non-indexed info that will be shown in list workflow.\n    Memo map[string]interface{}\n\n    // SearchAttributes - Optional indexed info that can be used in query of List/Scan/Count workflow APIs (only\n    // supported when Cadence server is using Elasticsearch). The key and value type must be registered on Cadence server side.\n    // Use GetSearchAttributes API to get valid key and corresponding value type.\n    SearchAttributes map[string]interface{}\n}\n\n\nIn the Java client, the WorkflowOptions.Builder has similar methods for memo and search attributes.\n\nSome important distinctions between memo and search attributes:\n\n * Memo can support all data types because it is not indexed. Search attributes only support basic data types (including String, Int, Float, Bool, Datetime) because it is indexed by Elasticsearch.\n * Memo does not restrict on key names. Search attributes require that keys are allowlisted before using them because Elasticsearch has a limit on indexed keys.\n * Memo doesn\'t require Cadence clusters to depend on Elasticsearch while search attributes only works with Elasticsearch.\n\n# Search Attributes (Go Client Usage)\nWhen using the Cadence Go client, provide key-value pairs as SearchAttributes in StartWorkflowOptions.\n\nSearchAttributes is map[string]interface{} where the keys need to be allowlisted so that Cadence knows the attribute key name and value type. The value provided in the map must be the same type as registered.\n\n# Allow Listing Search Attributes\nStart by the list of search attributes using the \n\n$ cadence --domain samples-domain cl get-search-attr\n+---------------------+------------+\n|         KEY         | VALUE TYPE |\n+---------------------+------------+\n| CloseStatus         | INT        |\n| CloseTime           | INT        |\n| CustomBoolField     | DOUBLE     |\n| CustomDatetimeField | DATETIME   |\n| CustomDomain        | KEYWORD    |\n| CustomDoubleField   | BOOL       |\n| CustomIntField      | INT        |\n| CustomKeywordField  | KEYWORD    |\n| CustomStringField   | STRING     |\n| DomainID            | KEYWORD    |\n| ExecutionTime       | INT        |\n| HistoryLength       | INT        |\n| RunID               | KEYWORD    |\n| StartTime           | INT        |\n| WorkflowID          | KEYWORD    |\n| WorkflowType        | KEYWORD    |\n+---------------------+------------+\n\n\nUse the admin to add a new search attribute:\n\ncadence --domain samples-domain adm cl asa --search_attr_key NewKey --search_attr_type 1\n\n\nThe numbers for the attribute types map as follows:\n\n * 0 = String\n * 1 = Keyword\n * 2 = Int\n * 3 = Double\n * 4 = Bool\n * 5 = DateTime\n\n# Keyword vs String\nNote that Keyword and String are concepts taken from Elasticsearch. Each word in a String is considered a searchable keyword. For a UUID, that can be problematic as Elasticsearch will index each portion of the UUID separately. To have the whole string considered as a searchable keyword, use the Keyword type.\n\nFor example, key RunID with value "2dd29ab7-2dd8-4668-83e0-89cae261cfb1"\n\n * as a Keyword will only be matched by RunID = "2dd29ab7-2dd8-4668-83e0-89cae261cfb1" (or in the future with regular expressions)\n * as a String will be matched by RunID = "2dd8", which may cause unwanted matches\n\nNote: String type can not be used in Order By .\n\nThere are some pre-allowlisted search attributes that are handy for testing:\n\n * CustomKeywordField\n * CustomIntField\n * CustomDoubleField\n * CustomBoolField\n * CustomDatetimeField\n * CustomStringField\n\nTheir types are indicated in their names.\n\n# Value Types\nHere are the Search Attribute value types and their correspondent Golang types:\n\n * Keyword = string\n * Int = int64\n * Double = float64\n * Bool = bool\n * Datetime = time.Time\n * String = string\n\n# Limit\nWe recommend limiting the number of Elasticsearch indexes by enforcing limits on the following:\n\n * Number of keys: 100 per \n * Size of value: 2kb per value\n * Total size of key and values: 40kb per \n\nCadence reserves keys like DomainID, WorkflowID, and RunID. These can only be used in list . The values are not updatable.\n\n# Upsert Search Attributes in Workflow\nUpsertSearchAttributes is used to add or update search attributes from within the code.\n\nGo samples for search attributes can be found at github.com/uber-common/cadence-samples.\n\nUpsertSearchAttributes will merge attributes to the existing map in the . Consider this example code:\n\nfunc MyWorkflow(ctx workflow.Context, input string) error {\n\n    attr1 := map[string]interface{}{\n        "CustomIntField": 1,\n        "CustomBoolField": true,\n    }\n    workflow.UpsertSearchAttributes(ctx, attr1)\n\n    attr2 := map[string]interface{}{\n        "CustomIntField": 2,\n        "CustomKeywordField": "seattle",\n    }\n    workflow.UpsertSearchAttributes(ctx, attr2)\n}\n\n\nAfter the second call to UpsertSearchAttributes, the map will contain:\n\nmap[string]interface{}{\n    "CustomIntField": 2,\n    "CustomBoolField": true,\n    "CustomKeywordField": "seattle",\n}\n\n\nThere is no support for removing a field. To achieve a similar effect, set the field to a sentinel value. For example, to remove “CustomKeywordField”, update it to “impossibleVal”. Then searching CustomKeywordField != ‘impossibleVal’ will match with CustomKeywordField not equal to "impossibleVal", which includes without the CustomKeywordField set.\n\nUse workflow.GetInfo to get current search attributes.\n\n# ContinueAsNew and Cron\nWhen performing a ContinueAsNew or using Cron, search attributes (and memo) will be carried over to the new run by default.\n\n# Query Capabilities\n by using a SQL-like where clause when listing workflows from the CLI or using the list APIs (Go, Java).\n\nNote that you will only see from one domain when .\n\n# Supported Operators\n * AND, OR, ()\n * =, !=, >, >=, <, <=\n * IN\n * BETWEEN ... AND\n * ORDER BY\n\n# Default Attributes\nThese can be found by using the get-search-attr command or the GetSearchAttributes API. The names and types are as follows:\n\nKEY                   VALUE TYPE   \nCloseStatus           INT          \nCloseTime             INT          \nCustomBoolField       DOUBLE       \nCustomDatetimeField   DATETIME     \nCustomDomain          KEYWORD      \nCustomDoubleField     BOOL         \nCustomIntField        INT          \nCustomKeywordField    KEYWORD      \nCustomStringField     STRING       \nDomainID              KEYWORD      \nExecutionTime         INT          \nHistoryLength         INT          \nRunID                 KEYWORD      \nStartTime             INT          \nWorkflowID            KEYWORD      \nWorkflowType          KEYWORD      \n\nThere are some special considerations for these attributes:\n\n * CloseStatus, CloseTime, DomainID, ExecutionTime, HistoryLength, RunID, StartTime, WorkflowID, WorkflowType are reserved by Cadence and are read-only\n * CloseStatus is a mapping of int to state: * 0 = completed\n    * 1 = failed\n    * 2 = canceled\n    * 3 = terminated\n    * 4 = continuedasnew\n    * 5 = timedout\n   \n   \n * StartTime, CloseTime and ExecutionTime are stored as INT, but support using both EpochTime in nanoseconds, and string in RFC3339 format (ex. "2006-01-02T15:04:05+07:00")\n * CloseTime, CloseStatus, HistoryLength are only present in closed \n * ExecutionTime is for Retry/Cron user to a that will run in the future\n\nTo list only open , add CloseTime = missing to the end of the .\n\nIf you use retry or the cron feature to that will start execution in a certain time range, you can add predicates on ExecutionTime. For example: ExecutionTime > 2019-01-01T10:00:00-07:00. Note that if predicates on ExecutionTime are included, only cron or a that needs to retry will be returned.\n\n# General Notes About Queries\n * Pagesize default is 1000, and cannot be larger than 10k\n * Range on Cadence timestamp (StartTime, CloseTime, ExecutionTime) cannot be larger than 9223372036854775807 (maxInt64 - 1001)\n *  by time range will have 1ms resolution\n *  column names are case sensitive\n * ListWorkflow may take longer when retrieving a large number of (10M+)\n * To retrieve a large number of without caring about order, use the ScanWorkflow API\n * To efficiently count the number of , use the CountWorkflow API\n\n# Tools Support\n# CLI\nSupport for search attributes is available as of version 0.6.0 of the Cadence server. You can also use the from the latest CLI Docker image (supported on 0.6.4 or later).\n\n# Start Workflow with Search Attributes\ncadence --do samples-domain workflow start --tl helloWorldGroup --wt main.Workflow --et 60 --dt 10 -i \'"vancexu"\' -search_attr_key \'CustomIntField | CustomKeywordField | CustomStringField |  CustomBoolField | CustomDatetimeField\' -search_attr_value \'5 | keyword1 | vancexu test | true | 2019-06-07T16:16:36-08:00\'\n\n\n# Search Workflows with List API\ncadence --do samples-domain wf list -q \'(CustomKeywordField = "keyword1" and CustomIntField >= 5) or CustomKeywordField = "keyword2"\' -psa\n\n\ncadence --do samples-domain wf list -q \'CustomKeywordField in ("keyword2", "keyword1") and CustomIntField >= 5 and CloseTime between "2018-06-07T16:16:36-08:00" and "2019-06-07T16:46:34-08:00" order by CustomDatetimeField desc\' -psa\n\n\nTo list only open , add CloseTime = missing to the end of the .\n\nNote that can support more than one type of filter:\n\ncadence --do samples-domain wf list -q \'WorkflowType = "main.Workflow" and (WorkflowID = "1645a588-4772-4dab-b276-5f9db108b3a8" or RunID = "be66519b-5f09-40cd-b2e8-20e4106244dc")\'\n\n\ncadence --do samples-domain wf list -q \'WorkflowType = "main.Workflow" StartTime > "2019-06-07T16:46:34-08:00" and CloseTime = missing\'\n\n\n# Web UI Support\n are supported in Cadence Web as of release 3.4.0. Use the "Basic/Advanced" button to switch to "Advanced" mode and type the in the search box.\n\n# Local Testing\n 1. Increase Docker memory to higher than 6GB. Navigate to Docker -> Preferences -> Advanced -> Memory\n 2. Get the Cadence Docker compose file. Run curl -O https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose-es.yml\n 3. Start Cadence Docker (which contains Apache Kafka, Apache Zookeeper, and Elasticsearch) using docker-compose -f docker-compose-es.yml up\n 4. From the Docker output log, make sure Elasticsearch and Cadence started correctly. If you encounter an insufficient disk space error, try docker system prune -a --volumes\n 5. Register a local domain and start using it. cadence --do samples-domain d re\n 6. Allowlist search attributes. cadence --do domain adm cl asa --search_attr_key NewKey --search_attr_type 1\n\nNote: starting a with search attributes but without Elasticsearch will succeed as normal, but will not be searchable and will not be shown in list results.',normalizedContent:'# searching/filtering workflows\n# introduction\ncadence supports creating with customized key-value pairs, updating the information within the code, and then listing/searching with a sql-like . for example, you can create with keys city and age, then search all with city = seattle and age > 22.\n\nalso note that normal properties like start time and type can be queried as well. for example, the following could be specified when listing workflows from the cli or using the list apis (go, java):\n\nworkflowtype = "main.workflow" and closestatus != 0 and (starttime > "2019-06-07t16:46:34-08:00" or closetime > "2019-06-07t16:46:34-08:00" order by starttime desc)\n\n\n# memo vs search attributes\ncadence offers two methods for creating with key-value pairs: memo and search attributes. memo can only be provided on start. also, memo data are not indexed, and are therefore not searchable. memo data are visible when listing using the list apis. search attributes data are indexed so you can search by on these attributes. however, search attributes require the use of elasticsearch.\n\nmemo and search attributes are available in the go client in startworkflowoptions.\n\ntype startworkflowoptions struct {\n    // ...\n\n    // memo - optional non-indexed info that will be shown in list workflow.\n    memo map[string]interface{}\n\n    // searchattributes - optional indexed info that can be used in query of list/scan/count workflow apis (only\n    // supported when cadence server is using elasticsearch). the key and value type must be registered on cadence server side.\n    // use getsearchattributes api to get valid key and corresponding value type.\n    searchattributes map[string]interface{}\n}\n\n\nin the java client, the workflowoptions.builder has similar methods for memo and search attributes.\n\nsome important distinctions between memo and search attributes:\n\n * memo can support all data types because it is not indexed. search attributes only support basic data types (including string, int, float, bool, datetime) because it is indexed by elasticsearch.\n * memo does not restrict on key names. search attributes require that keys are allowlisted before using them because elasticsearch has a limit on indexed keys.\n * memo doesn\'t require cadence clusters to depend on elasticsearch while search attributes only works with elasticsearch.\n\n# search attributes (go client usage)\nwhen using the cadence go client, provide key-value pairs as searchattributes in startworkflowoptions.\n\nsearchattributes is map[string]interface{} where the keys need to be allowlisted so that cadence knows the attribute key name and value type. the value provided in the map must be the same type as registered.\n\n# allow listing search attributes\nstart by the list of search attributes using the \n\n$ cadence --domain samples-domain cl get-search-attr\n+---------------------+------------+\n|         key         | value type |\n+---------------------+------------+\n| closestatus         | int        |\n| closetime           | int        |\n| customboolfield     | double     |\n| customdatetimefield | datetime   |\n| customdomain        | keyword    |\n| customdoublefield   | bool       |\n| customintfield      | int        |\n| customkeywordfield  | keyword    |\n| customstringfield   | string     |\n| domainid            | keyword    |\n| executiontime       | int        |\n| historylength       | int        |\n| runid               | keyword    |\n| starttime           | int        |\n| workflowid          | keyword    |\n| workflowtype        | keyword    |\n+---------------------+------------+\n\n\nuse the admin to add a new search attribute:\n\ncadence --domain samples-domain adm cl asa --search_attr_key newkey --search_attr_type 1\n\n\nthe numbers for the attribute types map as follows:\n\n * 0 = string\n * 1 = keyword\n * 2 = int\n * 3 = double\n * 4 = bool\n * 5 = datetime\n\n# keyword vs string\nnote that keyword and string are concepts taken from elasticsearch. each word in a string is considered a searchable keyword. for a uuid, that can be problematic as elasticsearch will index each portion of the uuid separately. to have the whole string considered as a searchable keyword, use the keyword type.\n\nfor example, key runid with value "2dd29ab7-2dd8-4668-83e0-89cae261cfb1"\n\n * as a keyword will only be matched by runid = "2dd29ab7-2dd8-4668-83e0-89cae261cfb1" (or in the future with regular expressions)\n * as a string will be matched by runid = "2dd8", which may cause unwanted matches\n\nnote: string type can not be used in order by .\n\nthere are some pre-allowlisted search attributes that are handy for testing:\n\n * customkeywordfield\n * customintfield\n * customdoublefield\n * customboolfield\n * customdatetimefield\n * customstringfield\n\ntheir types are indicated in their names.\n\n# value types\nhere are the search attribute value types and their correspondent golang types:\n\n * keyword = string\n * int = int64\n * double = float64\n * bool = bool\n * datetime = time.time\n * string = string\n\n# limit\nwe recommend limiting the number of elasticsearch indexes by enforcing limits on the following:\n\n * number of keys: 100 per \n * size of value: 2kb per value\n * total size of key and values: 40kb per \n\ncadence reserves keys like domainid, workflowid, and runid. these can only be used in list . the values are not updatable.\n\n# upsert search attributes in workflow\nupsertsearchattributes is used to add or update search attributes from within the code.\n\ngo samples for search attributes can be found at github.com/uber-common/cadence-samples.\n\nupsertsearchattributes will merge attributes to the existing map in the . consider this example code:\n\nfunc myworkflow(ctx workflow.context, input string) error {\n\n    attr1 := map[string]interface{}{\n        "customintfield": 1,\n        "customboolfield": true,\n    }\n    workflow.upsertsearchattributes(ctx, attr1)\n\n    attr2 := map[string]interface{}{\n        "customintfield": 2,\n        "customkeywordfield": "seattle",\n    }\n    workflow.upsertsearchattributes(ctx, attr2)\n}\n\n\nafter the second call to upsertsearchattributes, the map will contain:\n\nmap[string]interface{}{\n    "customintfield": 2,\n    "customboolfield": true,\n    "customkeywordfield": "seattle",\n}\n\n\nthere is no support for removing a field. to achieve a similar effect, set the field to a sentinel value. for example, to remove “customkeywordfield”, update it to “impossibleval”. then searching customkeywordfield != ‘impossibleval’ will match with customkeywordfield not equal to "impossibleval", which includes without the customkeywordfield set.\n\nuse workflow.getinfo to get current search attributes.\n\n# continueasnew and cron\nwhen performing a continueasnew or using cron, search attributes (and memo) will be carried over to the new run by default.\n\n# query capabilities\n by using a sql-like where clause when listing workflows from the cli or using the list apis (go, java).\n\nnote that you will only see from one domain when .\n\n# supported operators\n * and, or, ()\n * =, !=, >, >=, <, <=\n * in\n * between ... and\n * order by\n\n# default attributes\nthese can be found by using the get-search-attr command or the getsearchattributes api. the names and types are as follows:\n\nkey                   value type   \nclosestatus           int          \nclosetime             int          \ncustomboolfield       double       \ncustomdatetimefield   datetime     \ncustomdomain          keyword      \ncustomdoublefield     bool         \ncustomintfield        int          \ncustomkeywordfield    keyword      \ncustomstringfield     string       \ndomainid              keyword      \nexecutiontime         int          \nhistorylength         int          \nrunid                 keyword      \nstarttime             int          \nworkflowid            keyword      \nworkflowtype          keyword      \n\nthere are some special considerations for these attributes:\n\n * closestatus, closetime, domainid, executiontime, historylength, runid, starttime, workflowid, workflowtype are reserved by cadence and are read-only\n * closestatus is a mapping of int to state: * 0 = completed\n    * 1 = failed\n    * 2 = canceled\n    * 3 = terminated\n    * 4 = continuedasnew\n    * 5 = timedout\n   \n   \n * starttime, closetime and executiontime are stored as int, but support using both epochtime in nanoseconds, and string in rfc3339 format (ex. "2006-01-02t15:04:05+07:00")\n * closetime, closestatus, historylength are only present in closed \n * executiontime is for retry/cron user to a that will run in the future\n\nto list only open , add closetime = missing to the end of the .\n\nif you use retry or the cron feature to that will start execution in a certain time range, you can add predicates on executiontime. for example: executiontime > 2019-01-01t10:00:00-07:00. note that if predicates on executiontime are included, only cron or a that needs to retry will be returned.\n\n# general notes about queries\n * pagesize default is 1000, and cannot be larger than 10k\n * range on cadence timestamp (starttime, closetime, executiontime) cannot be larger than 9223372036854775807 (maxint64 - 1001)\n *  by time range will have 1ms resolution\n *  column names are case sensitive\n * listworkflow may take longer when retrieving a large number of (10m+)\n * to retrieve a large number of without caring about order, use the scanworkflow api\n * to efficiently count the number of , use the countworkflow api\n\n# tools support\n# cli\nsupport for search attributes is available as of version 0.6.0 of the cadence server. you can also use the from the latest cli docker image (supported on 0.6.4 or later).\n\n# start workflow with search attributes\ncadence --do samples-domain workflow start --tl helloworldgroup --wt main.workflow --et 60 --dt 10 -i \'"vancexu"\' -search_attr_key \'customintfield | customkeywordfield | customstringfield |  customboolfield | customdatetimefield\' -search_attr_value \'5 | keyword1 | vancexu test | true | 2019-06-07t16:16:36-08:00\'\n\n\n# search workflows with list api\ncadence --do samples-domain wf list -q \'(customkeywordfield = "keyword1" and customintfield >= 5) or customkeywordfield = "keyword2"\' -psa\n\n\ncadence --do samples-domain wf list -q \'customkeywordfield in ("keyword2", "keyword1") and customintfield >= 5 and closetime between "2018-06-07t16:16:36-08:00" and "2019-06-07t16:46:34-08:00" order by customdatetimefield desc\' -psa\n\n\nto list only open , add closetime = missing to the end of the .\n\nnote that can support more than one type of filter:\n\ncadence --do samples-domain wf list -q \'workflowtype = "main.workflow" and (workflowid = "1645a588-4772-4dab-b276-5f9db108b3a8" or runid = "be66519b-5f09-40cd-b2e8-20e4106244dc")\'\n\n\ncadence --do samples-domain wf list -q \'workflowtype = "main.workflow" starttime > "2019-06-07t16:46:34-08:00" and closetime = missing\'\n\n\n# web ui support\n are supported in cadence web as of release 3.4.0. use the "basic/advanced" button to switch to "advanced" mode and type the in the search box.\n\n# local testing\n 1. increase docker memory to higher than 6gb. navigate to docker -> preferences -> advanced -> memory\n 2. get the cadence docker compose file. run curl -o https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose-es.yml\n 3. start cadence docker (which contains apache kafka, apache zookeeper, and elasticsearch) using docker-compose -f docker-compose-es.yml up\n 4. from the docker output log, make sure elasticsearch and cadence started correctly. if you encounter an insufficient disk space error, try docker system prune -a --volumes\n 5. register a local domain and start using it. cadence --do samples-domain d re\n 6. allowlist search attributes. cadence --do domain adm cl asa --search_attr_key newkey --search_attr_type 1\n\nnote: starting a with search attributes but without elasticsearch will succeed as normal, but will not be searchable and will not be shown in list results.',charsets:{cjk:!0}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/concepts",readingShow:"top"},regularPath:"/docs/02-concepts/",relativePath:"docs/02-concepts/index.md",key:"v-be41a8c6",path:"/docs/concepts/",headersStr:null,content:"# Concepts\nCadence is a new developer friendly way to develop distributed applications.\n\nIt borrows the core terminology from the workflow-automation space. So its concepts include workflows and activities. can react to events and return internal state through queries.\n\nThe deployment topology explains how all these concepts are mapped to deployable software components.",normalizedContent:"# concepts\ncadence is a new developer friendly way to develop distributed applications.\n\nit borrows the core terminology from the workflow-automation space. so its concepts include workflows and activities. can react to events and return internal state through queries.\n\nthe deployment topology explains how all these concepts are mapped to deployable software components.",charsets:{}},{title:"Java hello world",frontmatter:{layout:"default",title:"Java hello world",permalink:"/docs/tutorials/java-hello-world",readingShow:"top"},regularPath:"/docs/03-video-tutorials/01-java-hello-world.html",relativePath:"docs/03-video-tutorials/01-java-hello-world.md",key:"v-546411c2",path:"/docs/tutorials/java-hello-world/",headers:[{level:2,title:"Workflow implementation",slug:"workflow-implementation",normalizedTitle:"workflow implementation",charIndex:21}],headersStr:"Workflow implementation",content:'# Java Hello World\n# Workflow implementation\nSource code:\n\npublic interface HelloWorkflow {\n    @WorkflowMethod(executionStartToCloseTimeoutSeconds = 300)\n    String getGreeting(String name);\n}\n\n\npackage com.tutorial;\n\nimport com.uber.cadence.workflow.Workflow;\n\nimport java.time.Duration;\n\npublic class HelloWorkflowImpl implements HelloWorkflow {\n    @Override\n    public String getGreeting(String name) {\n        Workflow.sleep(Duration.ofMinutes(1));\n        return "Hello " + name + "!";\n    }\n}\n\n\npackage com.tutorial;\n\nimport com.uber.cadence.worker.Worker;\n\npublic class Main {\n\n    public static void main(String[] args) {\n        Worker.Factory f = new Worker.Factory("samples-domain");\n        Worker w = f.newWorker("hello");\n        w.registerWorkflowImplementationTypes(HelloWorkflowImpl.class);\n        f.start();\n    }\n}\n\n\nCommands:\n\ncadence -do samples-domain workflow start --et 300 --tl hello --wt HelloWorkflow::getGreeting --input \\"World\\"',normalizedContent:'# java hello world\n# workflow implementation\nsource code:\n\npublic interface helloworkflow {\n    @workflowmethod(executionstarttoclosetimeoutseconds = 300)\n    string getgreeting(string name);\n}\n\n\npackage com.tutorial;\n\nimport com.uber.cadence.workflow.workflow;\n\nimport java.time.duration;\n\npublic class helloworkflowimpl implements helloworkflow {\n    @override\n    public string getgreeting(string name) {\n        workflow.sleep(duration.ofminutes(1));\n        return "hello " + name + "!";\n    }\n}\n\n\npackage com.tutorial;\n\nimport com.uber.cadence.worker.worker;\n\npublic class main {\n\n    public static void main(string[] args) {\n        worker.factory f = new worker.factory("samples-domain");\n        worker w = f.newworker("hello");\n        w.registerworkflowimplementationtypes(helloworkflowimpl.class);\n        f.start();\n    }\n}\n\n\ncommands:\n\ncadence -do samples-domain workflow start --et 300 --tl hello --wt helloworkflow::getgreeting --input \\"world\\"',charsets:{}},{title:"Getting started",frontmatter:{layout:"default",title:"Getting started",permalink:"/docs/tutorials/",readingShow:"top"},regularPath:"/docs/03-video-tutorials/",relativePath:"docs/03-video-tutorials/index.md",key:"v-0d0c6d7b",path:"/docs/tutorials/",headers:[{level:2,title:"Installing Cadence Service and UI on a Mac",slug:"installing-cadence-service-and-ui-on-a-mac",normalizedTitle:"installing cadence service and ui on a mac",charIndex:20}],headersStr:"Installing Cadence Service and UI on a Mac",content:'# Getting started\n# Installing Cadence Service and UI on a Mac\nCommands executed during the tutorial:\n\ndocker-compose up\n\ndocker run --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain register\n\ndocker run --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain describe\n\nalias cadence="docker run --rm ubercadence/cli:master --address host.docker.internal:7933"\n\ncadence --domain samples-domain domain desc\n\ncadence help\n\ncadence workflow help\n\ncadence --domain samples-domain workflow list\n\ncadence --domain samples-domain workflow help start\n\ncadence --domain samples-domain workflow start -wt test -tl test -et 300\n\ncadence --domain samples-domain workflow list -op\n\ncadence --domain samples-domain workflow terminate -wid <workflowID>',normalizedContent:'# getting started\n# installing cadence service and ui on a mac\ncommands executed during the tutorial:\n\ndocker-compose up\n\ndocker run --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain register\n\ndocker run --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain describe\n\nalias cadence="docker run --rm ubercadence/cli:master --address host.docker.internal:7933"\n\ncadence --domain samples-domain domain desc\n\ncadence help\n\ncadence workflow help\n\ncadence --domain samples-domain workflow list\n\ncadence --domain samples-domain workflow help start\n\ncadence --domain samples-domain workflow start -wt test -tl test -et 300\n\ncadence --domain samples-domain workflow list -op\n\ncadence --domain samples-domain workflow terminate -wid <workflowid>',charsets:{}},{title:"Quick start",frontmatter:{layout:"default",title:"Quick start",permalink:"/docs/java-client/quick-start",readingShow:"top"},regularPath:"/docs/04-java-client/01-quick-start.html",relativePath:"docs/04-java-client/01-quick-start.md",key:"v-745671b4",path:"/docs/java-client/quick-start/",headers:[{level:2,title:"Install Cadence Service Locally",slug:"install-cadence-service-locally",normalizedTitle:"install cadence service locally",charIndex:84},{level:3,title:"Install docker",slug:"install-docker",normalizedTitle:"install docker",charIndex:118},{level:3,title:"Run Cadence Server Using Docker Compose",slug:"run-cadence-server-using-docker-compose",normalizedTitle:"run cadence server using docker compose",charIndex:237},{level:3,title:"Register a Domain Using the CLI",slug:"register-a-domain-using-the-cli",normalizedTitle:"register a domain using the cli",charIndex:4378},{level:2,title:"Implement Hello World Java Workflow",slug:"implement-hello-world-java-workflow",normalizedTitle:"implement hello world java workflow",charIndex:5629},{level:3,title:"Include Cadence Java Client Dependency",slug:"include-cadence-java-client-dependency",normalizedTitle:"include cadence java client dependency",charIndex:5667},{level:3,title:"Implement Hello World Workflow",slug:"implement-hello-world-workflow",normalizedTitle:"implement hello world workflow",charIndex:7293},{level:3,title:"Execute Hello World Workflow using the CLI",slug:"execute-hello-world-workflow-using-the-cli",normalizedTitle:"execute hello world workflow using the cli",charIndex:8428},{level:3,title:"List Workflows and Workflow History",slug:"list-workflows-and-workflow-history",normalizedTitle:"list workflows and workflow history",charIndex:12502},{level:3,title:"Workflow ID Uniqueness",slug:"workflow-id-uniqueness",normalizedTitle:"workflow id uniqueness",charIndex:14990},{level:3,title:"CLI Help",slug:"cli-help",normalizedTitle:"cli help",charIndex:18299},{level:2,title:"Signals",slug:"signals",normalizedTitle:"signals",charIndex:20963},{level:2,title:"Query",slug:"query",normalizedTitle:"query",charIndex:25060},{level:2,title:"Activities",slug:"activities",normalizedTitle:"activities",charIndex:29625}],headersStr:"Install Cadence Service Locally Install docker Run Cadence Server Using Docker Compose Register a Domain Using the CLI Implement Hello World Java Workflow Include Cadence Java Client Dependency Implement Hello World Workflow Execute Hello World Workflow using the CLI List Workflows and Workflow History Workflow ID Uniqueness CLI Help Signals Query Activities",content:'# Quick start\nThis topic helps you install the Cadence service and implement a .\n\n# Install Cadence Service Locally\n# Install docker\nFollow the Docker installation instructions found here: https://docs.docker.com/engine/installation/\n\n# Run Cadence Server Using Docker Compose\nDownload the Cadence docker-compose file:\n\n> curl -O https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose.yml\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   675  100   675    0     0    958      0 --:--:-- --:--:-- --:--:--   958\n> ls\ndocker-compose.yml\n\n\nStart Cadence Service:\n\n> docker-compose up\nCreating network "quick_start_default" with the default driver\nPulling cadence (ubercadence/server:0.5.8)...\n0.5.8: Pulling from ubercadence/server\ndb0035920883: Pull complete\n82eed7f2d38e: Pull complete\nf81e11a89e41: Pull complete\nae3538b1ae1c: Pull complete\n23ddfb58e314: Pull complete\n52a6bbeb81b5: Pull complete\na72c7949d8ac: Pull complete\n1c3b1d477195: Pull complete\n3312d4123248: Pull complete\n5bbc95a38c5f: Pull complete\n29176d1ce1ca: Pull complete\n27ec3755f89c: Pull complete\n0a5d2a29a5e5: Pull complete\nCreating quick_start_statsd_1    ... done\nCreating quick_start_cassandra_1 ... done\nCreating quick_start_cadence_1   ... done\nCreating quick_start_cadence-web_1 ... done\nAttaching to quick_start_cassandra_1, quick_start_statsd_1, quick_start_cadence_1, quick_start_cadence-web_1\nstatsd_1       | *** Running /etc/my_init.d/00_regen_ssh_host_keys.sh...\nstatsd_1       | *** Running /etc/my_init.d/01_conf_init.sh...\ncadence_1      | + CADENCE_HOME=/cadence\ncadence_1      | + DB=cassandra\n...\n...\n...\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:38.199Z","msg":"Get dynamic config","name":"matching.longPollExpirationInterval","value":"1m0s","default-value":"1m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:38.199Z","msg":"Get dynamic config","name":"matching.updateAckInterval","value":"1m0s","default-value":"1m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:38.199Z","msg":"Get dynamic config","name":"matching.idleTasklistCheckInterval","value":"5m0s","default-value":"5m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:38.765Z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"Starting","wf-task-list-name":"cadence-archival-tl","wf-task-list-type":0,"logging-call-at":"matchingEngine.go:185"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:38.775Z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"Started","wf-task-list-name":"cadence-archival-tl","wf-task-list-type":0,"logging-call-at":"matchingEngine.go:199"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:38.891Z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"Starting","wf-task-list-name":"51f3b9fdfa7d:7feebe1f-95b2-44b8-8633-5ba7f4113508","wf-task-list-type":0,"logging-call-at":"matchingEngine.go:185"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:38.900Z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"Started","wf-task-list-name":"51f3b9fdfa7d:7feebe1f-95b2-44b8-8633-5ba7f4113508","wf-task-list-type":0,"logging-call-at":"matchingEngine.go:199"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:52.282Z","msg":"Get dynamic config","name":"history.shardUpdateMinInterval","value":"5m0s","default-value":"5m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:26:52.282Z","msg":"Get dynamic config","name":"history.emitShardDiffLog","value":"false","default-value":"false","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:27:24.903Z","msg":"Get dynamic config","name":"history.transferProcessorCompleteTransferFailureRetryCount","value":"10","default-value":"10","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06T15:27:24.905Z","msg":"Get dynamic config","name":"history.timerProcessorCompleteTimerFailureRetryCount","value":"10","default-value":"10","logging-call-at":"config.go:57"}\n\n\n# Register a Domain Using the CLI\nFrom a different console window:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain domain register -rd 1\nUnable to find image \'ubercadence/cli:master\' locally\nmaster: Pulling from ubercadence/cli\n22dc81ace0ea: Pull complete\n1a8b3c87dba3: Pull complete\n91390a1c435a: Pull complete\n07844b14977e: Pull complete\nb78396653dae: Pull complete\n5259e0c8568e: Pull complete\nbe8b5313e7cd: Pull complete\nda2cfe74be81: Pull complete\n5320bde81c0c: Pull complete\nDigest: sha256:f5e5e708347909c8d3f74c47878b201d91606994394e94eaede9a80e3b9f077b\nStatus: Downloaded newer image for ubercadence/cli:master\nDomain test-domain successfully registered.\n>\n\n\nCheck that the domain is indeed registered:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain domain describe\nName: test-domain\nDescription:\nOwnerEmail:\nDomainData: map[]\nStatus: REGISTERED\nRetentionInDays: 1\nEmitMetrics: false\nActiveClusterName: active\nClusters: active\nArchivalStatus: DISABLED\nBad binaries to reset:\n+-----------------+----------+------------+--------+\n| BINARY CHECKSUM | OPERATOR | START TIME | REASON |\n+-----------------+----------+------------+--------+\n+-----------------+----------+------------+--------+\n>\n\n\n# Implement Hello World Java Workflow\n# Include Cadence Java Client Dependency\nGo to the Maven Repository Uber Cadence Java Client Pageand find the latest version of the library. Include it as a dependency into your Java project. For example if you are using Gradle the dependency looks like:\n\ncompile group: \'com.uber.cadence\', name: \'cadence-client\', version: \'<latest_version>\'\n\n\nAlso add the following dependencies that cadence-client relies on:\n\ncompile group: \'commons-configuration\', name: \'commons-configuration\', version: \'1.9\'\ncompile group: \'ch.qos.logback\', name: \'logback-classic\', version: \'1.2.3\'\n\n\nMake sure that the following code compiles:\n\nimport com.uber.cadence.workflow.Workflow;\nimport com.uber.cadence.workflow.WorkflowMethod;\nimport org.slf4j.Logger;\n\npublic class GettingStarted {\n\n    private static Logger logger = Workflow.getLogger(GettingStarted.class);\n\n    interface HelloWorld {\n        @WorkflowMethod\n        void sayHello(String name);\n    }\n\n}\n\n\nIf you are having problems setting up the build files use theCadence Java Samples GitHub repository as a reference.\n\nAlso add the following logback config file somewhere in your classpath:\n\n<configuration>\n    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">\n        \x3c!-- encoders are assigned the type\n             ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --\x3e\n        <encoder>\n            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>\n        </encoder>\n    </appender>\n    <logger name="io.netty" level="INFO"/>\n    <root level="INFO">\n        <appender-ref ref="STDOUT" />\n    </root>\n</configuration>\n\n\n# Implement Hello World Workflow\nLet\'s add HelloWorldImpl with the sayHello method that just logs the "Hello ..." and returns.\n\nimport com.uber.cadence.worker.Worker;\nimport com.uber.cadence.workflow.Workflow;\nimport com.uber.cadence.workflow.WorkflowMethod;\nimport org.slf4j.Logger;\n\npublic class GettingStarted {\n\n    private static Logger logger = Workflow.getLogger(GettingStarted.class);\n\n    public interface HelloWorld {\n        @WorkflowMethod\n        void sayHello(String name);\n    }\n\n    public static class HelloWorldImpl implements HelloWorld {\n\n        @Override\n        public void sayHello(String name) {\n            logger.info("Hello " + name + "!");\n        }\n    }\n}\n\n\nTo link the implementation to the Cadence framework, it should be registered with a that connects to a Cadence Service. By default the connects to the locally running Cadence service.\n\npublic static void main(String[] args) {\n    Worker.Factory factory = new Worker.Factory("test-domain");\n    Worker worker = factory.newWorker("HelloWorldTaskList");\n    worker.registerWorkflowImplementationTypes(HelloWorldImpl.class);\n    factory.start();\n}\n\n\n# Execute Hello World Workflow using the CLI\nNow run the program. Following is an example log:\n\n13:35:02.575 [main] INFO  c.u.c.s.WorkflowServiceTChannel - Initialized TChannel for service cadence-frontend, LibraryVersion: 2.2.0, FeatureVersion: 1.0.0\n13:35:02.671 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'Workflow Poller taskList="HelloWorldTaskList", domain="test-domain", type="workflow"\'}, identity=45937@maxim-C02XD0AAJGH6}\n13:35:02.673 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n\n\nNo Hello printed. This is expected because a is just a code host. The has to be started to execute. Let\'s use Cadence to start the workflow:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"World\\"\nStarted Workflow Id: bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7, run Id: e7c40431-8e23-485b-9649-e8f161219efe\n\n\nThe output of the program should change to:\n\n13:35:02.575 [main] INFO  c.u.c.s.WorkflowServiceTChannel - Initialized TChannel for service cadence-frontend, LibraryVersion: 2.2.0, FeatureVersion: 1.0.0\n13:35:02.671 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'Workflow Poller taskList="HelloWorldTaskList", domain="test-domain", type="workflow"\'}, identity=45937@maxim-C02XD0AAJGH6}\n13:35:02.673 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - Hello World!\n\n\nLet\'s start another \n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"Cadence\\"\nStarted Workflow Id: d2083532-9c68-49ab-90e1-d960175377a7, run Id: 331bfa04-834b-45a7-861e-bcb9f6ddae3e\n\n\nAnd the output changed to:\n\n13:35:02.575 [main] INFO  c.u.c.s.WorkflowServiceTChannel - Initialized TChannel for service cadence-frontend, LibraryVersion: 2.2.0, FeatureVersion: 1.0.0\n13:35:02.671 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'Workflow Poller taskList="HelloWorldTaskList", domain="test-domain", type="workflow"\'}, identity=45937@maxim-C02XD0AAJGH6}\n13:35:02.673 [main] INFO  c.u.cadence.internal.worker.Poller - start(): Poller{options=PollerOptions{maximumPollRateIntervalMilliseconds=1000, maximumPollRatePerSecond=0.0, pollBackoffCoefficient=2.0, pollBackoffInitialInterval=PT0.2S, pollBackoffMaximumInterval=PT20S, pollThreadCount=1, pollThreadNamePrefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - Hello World!\n13:42:34.994 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - Hello Cadence!\n\n\n# List Workflows and Workflow History\nLet\'s list our in the \n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow list\n             WORKFLOW TYPE            |             WORKFLOW ID              |                RUN ID                | START TIME | EXECUTION TIME | END TIME\n  HelloWorld::sayHello                | d2083532-9c68-49ab-90e1-d960175377a7 | 331bfa04-834b-45a7-861e-bcb9f6ddae3e | 20:42:34   | 20:42:34       | 20:42:35\n  HelloWorld::sayHello                | bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7 | e7c40431-8e23-485b-9649-e8f161219efe | 20:40:28   | 20:40:28       | 20:40:29\n\n\nNow let\'s look at the history:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow showid 1965109f-607f-4b14-a5f2-24399a7b8fa7\n  1  WorkflowExecutionStarted    {WorkflowType:{Name:HelloWorld::sayHello},\n                                  TaskList:{Name:HelloWorldTaskList},\n                                  Input:["World"],\n                                  ExecutionStartToCloseTimeoutSeconds:3600,\n                                  TaskStartToCloseTimeoutSeconds:10,\n                                  ContinuedFailureDetails:[],\n                                  LastCompletionResult:[],\n                                  Identity:cadence-cli@linuxkit-025000000001,\n                                  Attempt:0,\n                                  FirstDecisionTaskBackoffSeconds:0}\n  2  DecisionTaskScheduled       {TaskList:{Name:HelloWorldTaskList},\n                                  StartToCloseTimeoutSeconds:10,\n                                  Attempt:0}\n  3  DecisionTaskStarted         {ScheduledEventId:2,\n                                  Identity:45937@maxim-C02XD0AAJGH6,\n                                  RequestId:481a14e5-67a4-436e-9a23-7f7fb7f87ef3}\n  4  DecisionTaskCompleted       {ExecutionContext:[],\n                                  ScheduledEventId:2,\n                                  StartedEventId:3,\n                                  Identity:45937@maxim-C02XD0AAJGH6}\n  5  WorkflowExecutionCompleted  {Result:[],\n                                  DecisionTaskCompletedEventId:4}\n\n\nEven for such a trivial , the history gives a lot of useful information. For complex this is a really useful tool for production and development troubleshooting. History can be automatically archived to a long-term blob store (for example Amazon S3) upon completion for compliance, analytical, and troubleshooting purposes.\n\n# Workflow ID Uniqueness\nBefore proceeding to a more complex implementation, let\'s take a look at the semantic. When starting a without providing an ID, the client generates one in the form of a UUID. In most real-life scenarios this is not a desired behavior. The business ID should be used instead. Here, we\'ll specify the ID when starting a workflow:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "HelloCadence1" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"Cadence\\"\nStarted Workflow Id: HelloCadence1, run Id: 75170c60-6d72-48c6-b509-7c9d9f25a8a8\n\n\nNow the list operation is more meaningful as the is our business ID:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow list\n             WORKFLOW TYPE            |             WORKFLOW ID              |                RUN ID                | START TIME | EXECUTION TIME | END TIME\n  HelloWorld::sayHello                | HelloCadence1                        | 75170c60-6d72-48c6-b509-7c9d9f25a8a8 | 21:04:46   | 21:04:46       | 21:04:46\n\n\nLet\'s try to start with the same ID:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "HelloCadence1" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"Cadence\\"\nError: Failed to create workflow.\nError Details: WorkflowExecutionAlreadyStartedError{Message: Workflow execution already finished successfully. WorkflowId: HelloCadence1, RunId: 75170c60-6d72-48c6-b509-7c9d9f25a8a8. Workflow ID reuse policy: allow duplicate workflow ID if last run failed., StartRequestId: 350a03ed-a11f-4959-a424-8ff7166ed457, RunId: 75170c60-6d72-48c6-b509-7c9d9f25a8a8}\n(\'export CADENCE_CLI_SHOW_STACKS=1\' to see stack traces)\n\n\nOops, Cadence doesn\'t let us create a with the same ID. But there are use cases when it is desired. For example if there is a need to re-execute the for a particular reason. This is achieved by specifying a special flag Workflow ID Reuse Policy. The value of 1 means AllowDuplicate:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflowidreusepolicy 1 --workflow_id "HelloCadence1" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"Cadence\\"\nStarted Workflow Id: HelloCadence1, run Id: 37a740e5-838c-4020-aed6-1111b0689c38\n\n\nAfter the second start the list is:\n\n     WORKFLOW TYPE     |             WORKFLOW ID              |                RUN ID                | START TIME | EXECUTION TIME | END TIME\n  HelloWorld::sayHello | HelloCadence1                        | 37a740e5-838c-4020-aed6-1111b0689c38 | 21:11:47   | 21:11:47       | 21:11:47\n  HelloWorld::sayHello | HelloCadence1                        | 75170c60-6d72-48c6-b509-7c9d9f25a8a8 | 21:04:46   | 21:04:46       | 21:04:46\n\n\nIt might be clear why every has two IDs: and . Because the can be reused, the uniquely identifies a particular run of a . is system generated and cannot be controlled by client code.\n\nNote that ID Reuse Policy applies only when previous the run of a is completed. Under no circumstances does Cadence allow more than one instance of an open with the same ID.\n\n# CLI Help\nYou might be asking how to discover that 1 means AllowDuplicate. It came from the help command:\n\n> docker run --network=host --rm ubercadence/cli:master workflow help start\nNAME:\n   cadence workflow start - start a new workflow execution\n\nUSAGE:\n   cadence workflow start [command options] [arguments...]\n\nOPTIONS:\n   --tasklist value, --tl value                TaskList\n   --workflow_id value, --wid value, -w value  WorkflowID\n   --workflow_type value, --wt value           WorkflowTypeName\n   --execution_timeout value, --et value       Execution start to close timeout in seconds (default: 0)\n   --decision_timeout value, --dt value        Decision task start to close timeout in seconds (default: 10)\n   --cron value                                Optional cron schedule for the workflow. Cron spec is as following:\n                                               ┌───────────── minute (0 - 59)\n                                               │ ┌───────────── hour (0 - 23)\n                                               │ │ ┌───────────── day of the month (1 - 31)\n                                               │ │ │ ┌───────────── month (1 - 12)\n                                               │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)\n                                               │ │ │ │ │\n                                               * * * * *\n   --workflowidreusepolicy value, --wrp value  Optional input to configure if the same workflow ID is allowed to be used for a new workflow execution. Available options: 0: AllowDuplicateFailedOnly, 1: AllowDuplicate, 2: RejectDuplicate (default: 0)\n   --input value, -i value                     Optional input for the workflow, in JSON format. If there are multiple parameters, concatenate them and separate by a space.\n   --input_file value, --if value              Optional input for the workflow from a JSON file. If there are multiple JSON, concatenate them and separate by a space or newline. Input from the file will be overwritten by input from the command line.\n   --memo_key value                            Optional key of memo. If there are multiple keys, concatenate them and separate by space.\n   --memo value                                Optional info that can be shown in list workflow, in JSON format. If there are multiple JSON, concatenate them and separate by a space. The order must be the same as memo_key.\n   --memo_file value                           Optional info that can be listed in list workflow, from JSON format file. If there are multiple JSON, concatenate them and separate by a space or newline. The order must be same as memo_key.\n\n\n# Signals\nSo far our is not very interesting. Let\'s change it to listen on an external and update state accordingly.\n\npublic interface HelloWorld {\n    @WorkflowMethod\n    void sayHello(String name);\n\n    @SignalMethod\n    void updateGreeting(String greeting);\n}\n\npublic static class HelloWorldImpl implements HelloWorld {\n\n    private String greeting = "Hello";\n\n    @Override\n    public void sayHello(String name) {\n        int count = 0;\n        while (!"Bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            String oldGreeting = greeting;\n            Workflow.await(() -> !Objects.equals(greeting, oldGreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @Override\n    public void updateGreeting(String greeting) {\n        this.greeting = greeting;\n    }\n}\n\n\nThe interface now has a new method annotated with @SignalMethod. It is a callback method that is invoked every time a new of "HelloWorldupdateGreeting" is delivered to a . The interface can have only one @WorkflowMethod which is a main function of the and as many methods as needed.\n\nThe updated implementation demonstrates a few important Cadence concepts. The first is that is stateful and can have fields of any complex type. Another is that the Workflow.await function that blocks until the function it receives as a parameter evaluates to true. The condition is going to be evaluated only on state changes, so it is not a busy wait in traditional sense.\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "HelloSignal" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"World\\"\nStarted Workflow Id: HelloSignal, run Id: 6fa204cb-f478-469a-9432-78060b83b6cd\n\n\nProgram output:\n\n16:53:56.120 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n\n\nLet\'s send a using \n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloSignal" --name "HelloWorld::updateGreeting" --input \\"Hi\\"\nSignal workflow succeeded.\n\n\nProgram output:\n\n16:53:56.120 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n16:54:57.901 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 2: Hi World!\n\n\nTry sending the same with the same input again. Note that the output doesn\'t change. This happens because the await condition doesn\'t unblock when it sees the same value. But a new greeting unblocks it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloSignal" --name "HelloWorld::updateGreeting" --input \\"Welcome\\"\nSignal workflow succeeded.\n\n\nProgram output:\n\n16:53:56.120 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n16:54:57.901 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 2: Hi World!\n16:56:24.400 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 3: Welcome World!\n\n\nNow shut down the and send the same again:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloSignal" --name "HelloWorld::updateGreeting" --input \\"Welcome\\"\nSignal workflow succeeded.\n\n\nNote that sending as well as starting does not need a running. The requests are queued inside the Cadence service.\n\nNow bring the back. Note that it doesn\'t log anything besides the standard startup messages. This occurs because it ignores the queued that contains the same input as the current value of greeting. Note that the restart of the didn\'t affect the . It is still blocked on the same line of code as before the failure. This is the most important feature of Cadence. The code doesn\'t need to deal with failures at all. Its state is fully recovered to its current state that includes all the local variables and threads.\n\nLet\'s look at the line where the is blocked:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow stack --workflow_id "Hello2"\nQuery result:\n"workflow-root: (BLOCKED on await)\ncom.uber.cadence.internal.sync.SyncDecisionContext.await(SyncDecisionContext.java:546)\ncom.uber.cadence.internal.sync.WorkflowInternal.await(WorkflowInternal.java:243)\ncom.uber.cadence.workflow.Workflow.await(Workflow.java:611)\ncom.uber.cadence.samples.hello.GettingStarted$HelloWorldImpl.sayHello(GettingStarted.java:32)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)"\n\n\nYes, indeed the is blocked on await. This feature works for any open , greatly simplifying troubleshooting in production. Let\'s complete the by sending a with a "Bye" greeting:\n\n16:58:22.962 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 4: Bye World!\n\n\nNote that the value of the count variable was not lost during the restart.\n\nAlso note that while a single instance is used for this walkthrough, any real production deployment has multiple instances running. So any failure or restart does not delay any because it is just migrated to any other available .\n\n# Query\nSo far we have learned that the code is fault tolerant and can update its state in reaction to external in the form of . Cadence provides a feature that supports synchronously returning any information from a to an external caller.\n\nUpdate the code to:\n\npublic interface HelloWorld {\n    @WorkflowMethod\n    void sayHello(String name);\n\n    @SignalMethod\n    void updateGreeting(String greeting);\n\n    @QueryMethod\n    int getCount();\n}\n\npublic static class HelloWorldImpl implements HelloWorld {\n\n    private String greeting = "Hello";\n    private int count = 0;\n\n    @Override\n    public void sayHello(String name) {\n        while (!"Bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            String oldGreeting = greeting;\n            Workflow.await(() -> !Objects.equals(greeting, oldGreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @Override\n    public void updateGreeting(String greeting) {\n        this.greeting = greeting;\n    }\n\n    @Override\n    public int getCount() {\n        return count;\n    }\n}\n\n\nThe new getCount method annotated with @QueryMethod was added to the interface definition. It is allowed to have multiple methods per interface.\n\nThe main restriction on the implementation of the method is that it is not allowed to modify state in any form. It also is not allowed to block its thread in any way. It usually just returns a value derived from the fields of the object. Let\'s run the updated and send a couple to it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "HelloQuery" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"World\\"\nStarted Workflow Id: HelloQuery, run Id: 1925f668-45b5-4405-8cba-74f7c68c3135\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloQuery" --name "HelloWorld::updateGreeting" --input \\"Hi\\"\nSignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloQuery" --name "HelloWorld::updateGreeting" --input \\"Welcome\\"\nSignal workflow succeeded.\n\n\nThe output:\n\n17:35:50.485 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 1: Hello World!\n17:36:10.483 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 2: Hi World!\n17:36:16.204 [workflow-root] INFO  c.u.c.samples.hello.GettingStarted - 3: Welcome World!\n\n\nNow let\'s the using the \n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "HelloQuery" --query_type "HelloWorld::getCount"\n:query:Query: result as JSON:\n3\n\n\nOne limitation of the is that it requires a process running because it is executing callback code. An interesting feature of the is that it works for completed as well. Let\'s complete the by sending "Bye" and it.\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "HelloQuery" --name "HelloWorld::updateGreeting" --input \\"Bye\\"\nSignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "HelloQuery" --query_type "HelloWorld::getCount"\n:query:Query: result as JSON:\n4\n\n\nThe method can accept parameters. This might be useful if only part of the state should be returned.\n\n# Activities\nHaving fault tolerant code that maintains state, updates it in reaction to external , and supports is already very useful. But in most practical applications, the is expected to act upon the external world. Cadence supports such externally-facing code in the form of .\n\nAn is essentially a function that can execute any code like DB updates or service calls. The is not allowed to directly call any external APIs; it can do this only through . The is essentially an orchestrator of . Let\'s change our program to print the greeting from an on every change.\n\nFirst let\'s define an interface and implement it:\n\npublic interface HelloWorldActivities {\n    @ActivityMethod(scheduleToCloseTimeoutSeconds = 100)\n    void say(String message);\n}\n\n\nThe @ActivityMethod annotation is not required, but scheduleToCloseTimeoutSeconds is required and annotation is a convenient way to specify it. It is allowed to have multiple on a single interface.\n\nActivity implementation is just a normal POJO. The out stream is passed as a parameter to the constructor to demonstrate that the activity object can have any dependencies. Examples of real application dependencies are database connections and service clients.\n\npublic class HelloWordActivitiesImpl implements HelloWorldActivities {\n    private final PrintStream out;\n\n    public HelloWordActivitiesImpl(PrintStream out) {\n        this.out = out;\n    }\n\n    @Override\n    public void say(String message) {\n        out.println(message);\n    }\n}\n\n\nLet\'s create a separate main method for the . It is common to have a single that hosts both and , but here we keep them separate to demonstrate how Cadence deals with failures. To make the implementation known to Cadence, register it with the \n\npublic class GettingStartedActivityWorker {\n\n    public static void main(String[] args) {\n        Worker.Factory factory = new Worker.Factory("test-domain");\n        Worker worker = factory.newWorker("HelloWorldTaskList");\n        worker.registerActivitiesImplementations(new HelloWordActivitiesImpl(System.out));\n        factory.start();\n    }\n}\n\n\nA single instance of an object is registered per interface type. This means that the implementation should be thread-safe since the method can be simultaneously called from multiple threads.\n\nLet\'s modify the code to invoke the instead of logging:\n\npublic static class HelloWorldImpl implements HelloWorld {\n\n    private final HelloWorldActivities activities = Workflow.newActivityStub(HelloWorldActivities.class);\n    private String greeting = "Hello";\n    private int count = 0;\n\n    @Override\n    public void sayHello(String name) {\n        while (!"Bye".equals(greeting)) {\n            activities.say(++count + ": " + greeting + " " + name + "!");\n            String oldGreeting = greeting;\n            Workflow.await(() -> !Objects.equals(greeting, oldGreeting));\n        }\n        activities.say(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @Override\n    public void updateGreeting(String greeting) {\n        this.greeting = greeting;\n    }\n\n    @Override\n    public int getCount() {\n        return count;\n    }\n}\n\n\n are invoked through a stub that implements their interface. So an invocation is just a method call on an stub.\n\nNow run the . Do not run the yet. Then start a new \n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "HelloActivityWorker" --tasklist HelloWorldTaskList --workflow_type HelloWorld::sayHello --execution_timeout 3600 --input \\"World\\"\nStarted Workflow Id: HelloActivityWorker, run Id: ff015637-b5af-43e8-b3f6-8b6c7b919b62\n\n\nThe is started, but nothing visible happens. This is expected as the is not running. What are the options to understand the currently running state?\n\nThe first option is look at the stack trace:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow stack  --workflow_id "HelloActivityWorker"\n:query:Query: result as JSON:\n"workflow-root: (BLOCKED on Feature.get)com.uber.cadence.internal.sync.CompletablePromiseImpl.get(CompletablePromiseImpl.java:71)\ncom.uber.cadence.internal.sync.ActivityStubImpl.execute(ActivityStubImpl.java:58)\ncom.uber.cadence.internal.sync.ActivityInvocationHandler.lambda$invoke$0(ActivityInvocationHandler.java:87)\ncom.uber.cadence.internal.sync.ActivityInvocationHandler$$Lambda$25/1816732716.apply(Unknown Source)\ncom.uber.cadence.internal.sync.ActivityInvocationHandler.invoke(ActivityInvocationHandler.java:94)\ncom.sun.proxy.$Proxy6.say(Unknown Source)\ncom.uber.cadence.samples.hello.GettingStarted$HelloWorldImpl.sayHello(GettingStarted.java:55)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n"\n\n\nIt shows that the code is blocked on the "say" method of a Proxy object that implements the stub. You can restart the if you want to make sure that restarting it does not change that. It works for of any duration. It is okay for the code to block on an invocation for a month for example.\n\nAnother way to see what exactly happened in the is to look at the history:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow show  --workflow_id "HelloActivityWorker"\n  1  WorkflowExecutionStarted  {WorkflowType:{Name:HelloWorld::sayHello},\n                                TaskList:{Name:HelloWorldTaskList},\n                                Input:["World"],\n                                ExecutionStartToCloseTimeoutSeconds:3600,\n                                TaskStartToCloseTimeoutSeconds:10,\n                                ContinuedFailureDetails:[],\n                                LastCompletionResult:[],\n                                Identity:cadence-cli@linuxkit-025000000001,\n                                Attempt:0,\n                                FirstDecisionTaskBackoffSeconds:0}\n  2  DecisionTaskScheduled     {TaskList:{Name:HelloWorldTaskList},\n                                StartToCloseTimeoutSeconds:10,\n                                Attempt:0}\n  3  DecisionTaskStarted       {ScheduledEventId:2,\n                                Identity:36234@maxim-C02XD0AAJGH6,\n                                RequestId:ef645576-7cee-4d2e-9892-597a08b7b01f}\n  4  DecisionTaskCompleted     {ExecutionContext:[],\n                                ScheduledEventId:2,\n                                StartedEventId:3,\n                                Identity:36234@maxim-C02XD0AAJGH6}\n  5  ActivityTaskScheduled     {ActivityId:0,\n                                ActivityType:{Name:HelloWorldActivities::say},\n                                TaskList:{Name:HelloWorldTaskList},\n                                Input:["1: Hello World!"],\n                                ScheduleToCloseTimeoutSeconds:100,\n                                ScheduleToStartTimeoutSeconds:100,\n                                StartToCloseTimeoutSeconds:100,\n                                HeartbeatTimeoutSeconds:100,\n                                DecisionTaskCompletedEventId:4}\n\n\nThe last in the history is ActivityTaskScheduled. It is recorded when invoked the , but it wasn\'t picked up by an yet.\n\nAnother useful API is DescribeWorkflowExecution which, among other information, contains the list of outstanding activities:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow describe  --workflow_id "HelloActivityWorker"\n{\n    "ExecutionConfiguration": {\n        "taskList": {\n            "name": "HelloWorldTaskList"\n        },\n        "executionStartToCloseTimeoutSeconds": 3600,\n        "taskStartToCloseTimeoutSeconds": 10,\n        "childPolicy": "TERMINATE"\n    },\n    "WorkflowExecutionInfo": {\n        "Execution": {\n            "workflowId": "HelloActivityWorker",\n            "runId": "ff015637-b5af-43e8-b3f6-8b6c7b919b62"\n        },\n        "Type": {\n            "name": "HelloWorld::sayHello"\n        },\n        "StartTime": "2019-06-08T23:56:41Z",\n        "CloseTime": "1970-01-01T00:00:00Z",\n        "CloseStatus": null,\n        "HistoryLength": 5,\n        "ParentDomainID": null,\n        "ParentExecution": null,\n        "AutoResetPoints": {}\n    },\n    "PendingActivities": [\n        {\n            "ActivityID": "0",\n            "ActivityType": {\n                "name": "HelloWorldActivities::say"\n            },\n            "State": "SCHEDULED",\n            "ScheduledTimestamp": "2019-06-08T23:57:00Z"\n        }\n    ]\n}\n\n\nLet\'s start the . It starts and immediately prints:\n\n1: Hello World!\n\n\nLet\'s look at the history:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow show  --workflow_id "HelloActivityWorker"\n   1  WorkflowExecutionStarted  {WorkflowType:{Name:HelloWorld::sayHello},\n                                TaskList:{Name:HelloWorldTaskList},\n                                Input:["World"],\n                                ExecutionStartToCloseTimeoutSeconds:3600,\n                                TaskStartToCloseTimeoutSeconds:10,\n                                ContinuedFailureDetails:[],\n                                LastCompletionResult:[],\n                                Identity:cadence-cli@linuxkit-025000000001,\n                                Attempt:0,\n                                FirstDecisionTaskBackoffSeconds:0}\n   2  DecisionTaskScheduled     {TaskList:{Name:HelloWorldTaskList},\n                                StartToCloseTimeoutSeconds:10,\n                                Attempt:0}\n   3  DecisionTaskStarted       {ScheduledEventId:2,\n                                Identity:37694@maxim-C02XD0AAJGH6,\n                                RequestId:1d7cba6d-98c8-41fd-91b1-c27dffb21c7f}\n   4  DecisionTaskCompleted     {ExecutionContext:[],\n                                ScheduledEventId:2,\n                                StartedEventId:3,\n                                Identity:37694@maxim-C02XD0AAJGH6}\n   5  ActivityTaskScheduled     {ActivityId:0,\n                                ActivityType:{Name:HelloWorldActivities::say},\n                                TaskList:{Name:HelloWorldTaskList},\n                                Input:["1: Hello World!"],\n                                ScheduleToCloseTimeoutSeconds:300,\n                                ScheduleToStartTimeoutSeconds:300,\n                                StartToCloseTimeoutSeconds:300,\n                                HeartbeatTimeoutSeconds:300,\n                                DecisionTaskCompletedEventId:4}\n   6  ActivityTaskStarted       {ScheduledEventId:5,\n                                Identity:37784@maxim-C02XD0AAJGH6,\n                                RequestId:a646d5d2-566f-4f43-92d7-6689139ce944,\n                                Attempt:0}\n   7  ActivityTaskCompleted     {Result:[], ScheduledEventId:5,\n                                StartedEventId:6,\n                                Identity:37784@maxim-C02XD0AAJGH6}\n   8  DecisionTaskScheduled     {TaskList:{Name:maxim-C02XD0AAJGH6:fd3a85ed-752d-4662-a49d-2665b7667c8a},\n                                StartToCloseTimeoutSeconds:10, Attempt:0}\n   9  DecisionTaskStarted       {ScheduledEventId:8,\n                                Identity:fd3a85ed-752d-4662-a49d-2665b7667c8a,\n                                RequestId:601ef30a-0d1b-4400-b034-65b8328ad34c}\n  10  DecisionTaskCompleted     {ExecutionContext:[],\n                                ScheduledEventId:8,\n                                StartedEventId:9,\n                                Identity:37694@maxim-C02XD0AAJGH6}\n\n\nActivityTaskStarted is recorded when the is picked up by an . The Identity field contains the ID of the (you can set it to any value on startup).\n\nActivityTaskCompleted is recorded when completes. It contains the result of the execution.\n\nLet\'s look at various failure scenarios. Modify timeout:\n\npublic interface HelloWorldActivities {\n    @ActivityMethod(scheduleToCloseTimeoutSeconds = 100)\n    void say(String message);\n}\n\npublic class HelloWordActivitiesImpl implements HelloWorldActivities {\n    private final PrintStream out;\n\n    public HelloWordActivitiesImpl(PrintStream out) {\n        this.out = out;\n    }\n\n    @Override\n    public void say(String message) {\n        out.println(message);\n    }\n}\n\n\n(To be continued ...)',normalizedContent:'# quick start\nthis topic helps you install the cadence service and implement a .\n\n# install cadence service locally\n# install docker\nfollow the docker installation instructions found here: https://docs.docker.com/engine/installation/\n\n# run cadence server using docker compose\ndownload the cadence docker-compose file:\n\n> curl -o https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose.yml\n  % total    % received % xferd  average speed   time    time     time  current\n                                 dload  upload   total   spent    left  speed\n100   675  100   675    0     0    958      0 --:--:-- --:--:-- --:--:--   958\n> ls\ndocker-compose.yml\n\n\nstart cadence service:\n\n> docker-compose up\ncreating network "quick_start_default" with the default driver\npulling cadence (ubercadence/server:0.5.8)...\n0.5.8: pulling from ubercadence/server\ndb0035920883: pull complete\n82eed7f2d38e: pull complete\nf81e11a89e41: pull complete\nae3538b1ae1c: pull complete\n23ddfb58e314: pull complete\n52a6bbeb81b5: pull complete\na72c7949d8ac: pull complete\n1c3b1d477195: pull complete\n3312d4123248: pull complete\n5bbc95a38c5f: pull complete\n29176d1ce1ca: pull complete\n27ec3755f89c: pull complete\n0a5d2a29a5e5: pull complete\ncreating quick_start_statsd_1    ... done\ncreating quick_start_cassandra_1 ... done\ncreating quick_start_cadence_1   ... done\ncreating quick_start_cadence-web_1 ... done\nattaching to quick_start_cassandra_1, quick_start_statsd_1, quick_start_cadence_1, quick_start_cadence-web_1\nstatsd_1       | *** running /etc/my_init.d/00_regen_ssh_host_keys.sh...\nstatsd_1       | *** running /etc/my_init.d/01_conf_init.sh...\ncadence_1      | + cadence_home=/cadence\ncadence_1      | + db=cassandra\n...\n...\n...\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:38.199z","msg":"get dynamic config","name":"matching.longpollexpirationinterval","value":"1m0s","default-value":"1m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:38.199z","msg":"get dynamic config","name":"matching.updateackinterval","value":"1m0s","default-value":"1m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:38.199z","msg":"get dynamic config","name":"matching.idletasklistcheckinterval","value":"5m0s","default-value":"5m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:38.765z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"starting","wf-task-list-name":"cadence-archival-tl","wf-task-list-type":0,"logging-call-at":"matchingengine.go:185"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:38.775z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"started","wf-task-list-name":"cadence-archival-tl","wf-task-list-type":0,"logging-call-at":"matchingengine.go:199"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:38.891z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"starting","wf-task-list-name":"51f3b9fdfa7d:7feebe1f-95b2-44b8-8633-5ba7f4113508","wf-task-list-type":0,"logging-call-at":"matchingengine.go:185"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:38.900z","msg":"message is empty","service":"cadence-matching","component":"matching-engine","lifecycle":"started","wf-task-list-name":"51f3b9fdfa7d:7feebe1f-95b2-44b8-8633-5ba7f4113508","wf-task-list-type":0,"logging-call-at":"matchingengine.go:199"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:52.282z","msg":"get dynamic config","name":"history.shardupdatemininterval","value":"5m0s","default-value":"5m0s","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:26:52.282z","msg":"get dynamic config","name":"history.emitsharddifflog","value":"false","default-value":"false","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:27:24.903z","msg":"get dynamic config","name":"history.transferprocessorcompletetransferfailureretrycount","value":"10","default-value":"10","logging-call-at":"config.go:57"}\ncadence_1      | {"level":"info","ts":"2019-06-06t15:27:24.905z","msg":"get dynamic config","name":"history.timerprocessorcompletetimerfailureretrycount","value":"10","default-value":"10","logging-call-at":"config.go:57"}\n\n\n# register a domain using the cli\nfrom a different console window:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain domain register -rd 1\nunable to find image \'ubercadence/cli:master\' locally\nmaster: pulling from ubercadence/cli\n22dc81ace0ea: pull complete\n1a8b3c87dba3: pull complete\n91390a1c435a: pull complete\n07844b14977e: pull complete\nb78396653dae: pull complete\n5259e0c8568e: pull complete\nbe8b5313e7cd: pull complete\nda2cfe74be81: pull complete\n5320bde81c0c: pull complete\ndigest: sha256:f5e5e708347909c8d3f74c47878b201d91606994394e94eaede9a80e3b9f077b\nstatus: downloaded newer image for ubercadence/cli:master\ndomain test-domain successfully registered.\n>\n\n\ncheck that the domain is indeed registered:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain domain describe\nname: test-domain\ndescription:\nowneremail:\ndomaindata: map[]\nstatus: registered\nretentionindays: 1\nemitmetrics: false\nactiveclustername: active\nclusters: active\narchivalstatus: disabled\nbad binaries to reset:\n+-----------------+----------+------------+--------+\n| binary checksum | operator | start time | reason |\n+-----------------+----------+------------+--------+\n+-----------------+----------+------------+--------+\n>\n\n\n# implement hello world java workflow\n# include cadence java client dependency\ngo to the maven repository uber cadence java client pageand find the latest version of the library. include it as a dependency into your java project. for example if you are using gradle the dependency looks like:\n\ncompile group: \'com.uber.cadence\', name: \'cadence-client\', version: \'<latest_version>\'\n\n\nalso add the following dependencies that cadence-client relies on:\n\ncompile group: \'commons-configuration\', name: \'commons-configuration\', version: \'1.9\'\ncompile group: \'ch.qos.logback\', name: \'logback-classic\', version: \'1.2.3\'\n\n\nmake sure that the following code compiles:\n\nimport com.uber.cadence.workflow.workflow;\nimport com.uber.cadence.workflow.workflowmethod;\nimport org.slf4j.logger;\n\npublic class gettingstarted {\n\n    private static logger logger = workflow.getlogger(gettingstarted.class);\n\n    interface helloworld {\n        @workflowmethod\n        void sayhello(string name);\n    }\n\n}\n\n\nif you are having problems setting up the build files use thecadence java samples github repository as a reference.\n\nalso add the following logback config file somewhere in your classpath:\n\n<configuration>\n    <appender name="stdout" class="ch.qos.logback.core.consoleappender">\n        \x3c!-- encoders are assigned the type\n             ch.qos.logback.classic.encoder.patternlayoutencoder by default --\x3e\n        <encoder>\n            <pattern>%d{hh:mm:ss.sss} [%thread] %-5level %logger{36} - %msg%n</pattern>\n        </encoder>\n    </appender>\n    <logger name="io.netty" level="info"/>\n    <root level="info">\n        <appender-ref ref="stdout" />\n    </root>\n</configuration>\n\n\n# implement hello world workflow\nlet\'s add helloworldimpl with the sayhello method that just logs the "hello ..." and returns.\n\nimport com.uber.cadence.worker.worker;\nimport com.uber.cadence.workflow.workflow;\nimport com.uber.cadence.workflow.workflowmethod;\nimport org.slf4j.logger;\n\npublic class gettingstarted {\n\n    private static logger logger = workflow.getlogger(gettingstarted.class);\n\n    public interface helloworld {\n        @workflowmethod\n        void sayhello(string name);\n    }\n\n    public static class helloworldimpl implements helloworld {\n\n        @override\n        public void sayhello(string name) {\n            logger.info("hello " + name + "!");\n        }\n    }\n}\n\n\nto link the implementation to the cadence framework, it should be registered with a that connects to a cadence service. by default the connects to the locally running cadence service.\n\npublic static void main(string[] args) {\n    worker.factory factory = new worker.factory("test-domain");\n    worker worker = factory.newworker("helloworldtasklist");\n    worker.registerworkflowimplementationtypes(helloworldimpl.class);\n    factory.start();\n}\n\n\n# execute hello world workflow using the cli\nnow run the program. following is an example log:\n\n13:35:02.575 [main] info  c.u.c.s.workflowservicetchannel - initialized tchannel for service cadence-frontend, libraryversion: 2.2.0, featureversion: 1.0.0\n13:35:02.671 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'workflow poller tasklist="helloworldtasklist", domain="test-domain", type="workflow"\'}, identity=45937@maxim-c02xd0aajgh6}\n13:35:02.673 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n\n\nno hello printed. this is expected because a is just a code host. the has to be started to execute. let\'s use cadence to start the workflow:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"world\\"\nstarted workflow id: bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7, run id: e7c40431-8e23-485b-9649-e8f161219efe\n\n\nthe output of the program should change to:\n\n13:35:02.575 [main] info  c.u.c.s.workflowservicetchannel - initialized tchannel for service cadence-frontend, libraryversion: 2.2.0, featureversion: 1.0.0\n13:35:02.671 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'workflow poller tasklist="helloworldtasklist", domain="test-domain", type="workflow"\'}, identity=45937@maxim-c02xd0aajgh6}\n13:35:02.673 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] info  c.u.c.samples.hello.gettingstarted - hello world!\n\n\nlet\'s start another \n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"cadence\\"\nstarted workflow id: d2083532-9c68-49ab-90e1-d960175377a7, run id: 331bfa04-834b-45a7-861e-bcb9f6ddae3e\n\n\nand the output changed to:\n\n13:35:02.575 [main] info  c.u.c.s.workflowservicetchannel - initialized tchannel for service cadence-frontend, libraryversion: 2.2.0, featureversion: 1.0.0\n13:35:02.671 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'workflow poller tasklist="helloworldtasklist", domain="test-domain", type="workflow"\'}, identity=45937@maxim-c02xd0aajgh6}\n13:35:02.673 [main] info  c.u.cadence.internal.worker.poller - start(): poller{options=polleroptions{maximumpollrateintervalmilliseconds=1000, maximumpollratepersecond=0.0, pollbackoffcoefficient=2.0, pollbackoffinitialinterval=pt0.2s, pollbackoffmaximuminterval=pt20s, pollthreadcount=1, pollthreadnameprefix=\'null\'}, identity=81b8d0ac-ff89-47e8-b842-3dd26337feea}\n13:40:28.308 [workflow-root] info  c.u.c.samples.hello.gettingstarted - hello world!\n13:42:34.994 [workflow-root] info  c.u.c.samples.hello.gettingstarted - hello cadence!\n\n\n# list workflows and workflow history\nlet\'s list our in the \n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow list\n             workflow type            |             workflow id              |                run id                | start time | execution time | end time\n  helloworld::sayhello                | d2083532-9c68-49ab-90e1-d960175377a7 | 331bfa04-834b-45a7-861e-bcb9f6ddae3e | 20:42:34   | 20:42:34       | 20:42:35\n  helloworld::sayhello                | bcacfabd-9f9a-46ac-9b25-83bcea5d7fd7 | e7c40431-8e23-485b-9649-e8f161219efe | 20:40:28   | 20:40:28       | 20:40:29\n\n\nnow let\'s look at the history:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow showid 1965109f-607f-4b14-a5f2-24399a7b8fa7\n  1  workflowexecutionstarted    {workflowtype:{name:helloworld::sayhello},\n                                  tasklist:{name:helloworldtasklist},\n                                  input:["world"],\n                                  executionstarttoclosetimeoutseconds:3600,\n                                  taskstarttoclosetimeoutseconds:10,\n                                  continuedfailuredetails:[],\n                                  lastcompletionresult:[],\n                                  identity:cadence-cli@linuxkit-025000000001,\n                                  attempt:0,\n                                  firstdecisiontaskbackoffseconds:0}\n  2  decisiontaskscheduled       {tasklist:{name:helloworldtasklist},\n                                  starttoclosetimeoutseconds:10,\n                                  attempt:0}\n  3  decisiontaskstarted         {scheduledeventid:2,\n                                  identity:45937@maxim-c02xd0aajgh6,\n                                  requestid:481a14e5-67a4-436e-9a23-7f7fb7f87ef3}\n  4  decisiontaskcompleted       {executioncontext:[],\n                                  scheduledeventid:2,\n                                  startedeventid:3,\n                                  identity:45937@maxim-c02xd0aajgh6}\n  5  workflowexecutioncompleted  {result:[],\n                                  decisiontaskcompletedeventid:4}\n\n\neven for such a trivial , the history gives a lot of useful information. for complex this is a really useful tool for production and development troubleshooting. history can be automatically archived to a long-term blob store (for example amazon s3) upon completion for compliance, analytical, and troubleshooting purposes.\n\n# workflow id uniqueness\nbefore proceeding to a more complex implementation, let\'s take a look at the semantic. when starting a without providing an id, the client generates one in the form of a uuid. in most real-life scenarios this is not a desired behavior. the business id should be used instead. here, we\'ll specify the id when starting a workflow:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "hellocadence1" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"cadence\\"\nstarted workflow id: hellocadence1, run id: 75170c60-6d72-48c6-b509-7c9d9f25a8a8\n\n\nnow the list operation is more meaningful as the is our business id:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow list\n             workflow type            |             workflow id              |                run id                | start time | execution time | end time\n  helloworld::sayhello                | hellocadence1                        | 75170c60-6d72-48c6-b509-7c9d9f25a8a8 | 21:04:46   | 21:04:46       | 21:04:46\n\n\nlet\'s try to start with the same id:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "hellocadence1" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"cadence\\"\nerror: failed to create workflow.\nerror details: workflowexecutionalreadystartederror{message: workflow execution already finished successfully. workflowid: hellocadence1, runid: 75170c60-6d72-48c6-b509-7c9d9f25a8a8. workflow id reuse policy: allow duplicate workflow id if last run failed., startrequestid: 350a03ed-a11f-4959-a424-8ff7166ed457, runid: 75170c60-6d72-48c6-b509-7c9d9f25a8a8}\n(\'export cadence_cli_show_stacks=1\' to see stack traces)\n\n\noops, cadence doesn\'t let us create a with the same id. but there are use cases when it is desired. for example if there is a need to re-execute the for a particular reason. this is achieved by specifying a special flag workflow id reuse policy. the value of 1 means allowduplicate:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflowidreusepolicy 1 --workflow_id "hellocadence1" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"cadence\\"\nstarted workflow id: hellocadence1, run id: 37a740e5-838c-4020-aed6-1111b0689c38\n\n\nafter the second start the list is:\n\n     workflow type     |             workflow id              |                run id                | start time | execution time | end time\n  helloworld::sayhello | hellocadence1                        | 37a740e5-838c-4020-aed6-1111b0689c38 | 21:11:47   | 21:11:47       | 21:11:47\n  helloworld::sayhello | hellocadence1                        | 75170c60-6d72-48c6-b509-7c9d9f25a8a8 | 21:04:46   | 21:04:46       | 21:04:46\n\n\nit might be clear why every has two ids: and . because the can be reused, the uniquely identifies a particular run of a . is system generated and cannot be controlled by client code.\n\nnote that id reuse policy applies only when previous the run of a is completed. under no circumstances does cadence allow more than one instance of an open with the same id.\n\n# cli help\nyou might be asking how to discover that 1 means allowduplicate. it came from the help command:\n\n> docker run --network=host --rm ubercadence/cli:master workflow help start\nname:\n   cadence workflow start - start a new workflow execution\n\nusage:\n   cadence workflow start [command options] [arguments...]\n\noptions:\n   --tasklist value, --tl value                tasklist\n   --workflow_id value, --wid value, -w value  workflowid\n   --workflow_type value, --wt value           workflowtypename\n   --execution_timeout value, --et value       execution start to close timeout in seconds (default: 0)\n   --decision_timeout value, --dt value        decision task start to close timeout in seconds (default: 10)\n   --cron value                                optional cron schedule for the workflow. cron spec is as following:\n                                               ┌───────────── minute (0 - 59)\n                                               │ ┌───────────── hour (0 - 23)\n                                               │ │ ┌───────────── day of the month (1 - 31)\n                                               │ │ │ ┌───────────── month (1 - 12)\n                                               │ │ │ │ ┌───────────── day of the week (0 - 6) (sunday to saturday)\n                                               │ │ │ │ │\n                                               * * * * *\n   --workflowidreusepolicy value, --wrp value  optional input to configure if the same workflow id is allowed to be used for a new workflow execution. available options: 0: allowduplicatefailedonly, 1: allowduplicate, 2: rejectduplicate (default: 0)\n   --input value, -i value                     optional input for the workflow, in json format. if there are multiple parameters, concatenate them and separate by a space.\n   --input_file value, --if value              optional input for the workflow from a json file. if there are multiple json, concatenate them and separate by a space or newline. input from the file will be overwritten by input from the command line.\n   --memo_key value                            optional key of memo. if there are multiple keys, concatenate them and separate by space.\n   --memo value                                optional info that can be shown in list workflow, in json format. if there are multiple json, concatenate them and separate by a space. the order must be the same as memo_key.\n   --memo_file value                           optional info that can be listed in list workflow, from json format file. if there are multiple json, concatenate them and separate by a space or newline. the order must be same as memo_key.\n\n\n# signals\nso far our is not very interesting. let\'s change it to listen on an external and update state accordingly.\n\npublic interface helloworld {\n    @workflowmethod\n    void sayhello(string name);\n\n    @signalmethod\n    void updategreeting(string greeting);\n}\n\npublic static class helloworldimpl implements helloworld {\n\n    private string greeting = "hello";\n\n    @override\n    public void sayhello(string name) {\n        int count = 0;\n        while (!"bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            string oldgreeting = greeting;\n            workflow.await(() -> !objects.equals(greeting, oldgreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @override\n    public void updategreeting(string greeting) {\n        this.greeting = greeting;\n    }\n}\n\n\nthe interface now has a new method annotated with @signalmethod. it is a callback method that is invoked every time a new of "helloworldupdategreeting" is delivered to a . the interface can have only one @workflowmethod which is a main function of the and as many methods as needed.\n\nthe updated implementation demonstrates a few important cadence concepts. the first is that is stateful and can have fields of any complex type. another is that the workflow.await function that blocks until the function it receives as a parameter evaluates to true. the condition is going to be evaluated only on state changes, so it is not a busy wait in traditional sense.\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "hellosignal" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"world\\"\nstarted workflow id: hellosignal, run id: 6fa204cb-f478-469a-9432-78060b83b6cd\n\n\nprogram output:\n\n16:53:56.120 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n\n\nlet\'s send a using \n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "hellosignal" --name "helloworld::updategreeting" --input \\"hi\\"\nsignal workflow succeeded.\n\n\nprogram output:\n\n16:53:56.120 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n16:54:57.901 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 2: hi world!\n\n\ntry sending the same with the same input again. note that the output doesn\'t change. this happens because the await condition doesn\'t unblock when it sees the same value. but a new greeting unblocks it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "hellosignal" --name "helloworld::updategreeting" --input \\"welcome\\"\nsignal workflow succeeded.\n\n\nprogram output:\n\n16:53:56.120 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n16:54:57.901 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 2: hi world!\n16:56:24.400 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 3: welcome world!\n\n\nnow shut down the and send the same again:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "hellosignal" --name "helloworld::updategreeting" --input \\"welcome\\"\nsignal workflow succeeded.\n\n\nnote that sending as well as starting does not need a running. the requests are queued inside the cadence service.\n\nnow bring the back. note that it doesn\'t log anything besides the standard startup messages. this occurs because it ignores the queued that contains the same input as the current value of greeting. note that the restart of the didn\'t affect the . it is still blocked on the same line of code as before the failure. this is the most important feature of cadence. the code doesn\'t need to deal with failures at all. its state is fully recovered to its current state that includes all the local variables and threads.\n\nlet\'s look at the line where the is blocked:\n\n> docker run --network=host --rm ubercadence/cli:master --do test-domain workflow stack --workflow_id "hello2"\nquery result:\n"workflow-root: (blocked on await)\ncom.uber.cadence.internal.sync.syncdecisioncontext.await(syncdecisioncontext.java:546)\ncom.uber.cadence.internal.sync.workflowinternal.await(workflowinternal.java:243)\ncom.uber.cadence.workflow.workflow.await(workflow.java:611)\ncom.uber.cadence.samples.hello.gettingstarted$helloworldimpl.sayhello(gettingstarted.java:32)\nsun.reflect.nativemethodaccessorimpl.invoke0(native method)\nsun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62)"\n\n\nyes, indeed the is blocked on await. this feature works for any open , greatly simplifying troubleshooting in production. let\'s complete the by sending a with a "bye" greeting:\n\n16:58:22.962 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 4: bye world!\n\n\nnote that the value of the count variable was not lost during the restart.\n\nalso note that while a single instance is used for this walkthrough, any real production deployment has multiple instances running. so any failure or restart does not delay any because it is just migrated to any other available .\n\n# query\nso far we have learned that the code is fault tolerant and can update its state in reaction to external in the form of . cadence provides a feature that supports synchronously returning any information from a to an external caller.\n\nupdate the code to:\n\npublic interface helloworld {\n    @workflowmethod\n    void sayhello(string name);\n\n    @signalmethod\n    void updategreeting(string greeting);\n\n    @querymethod\n    int getcount();\n}\n\npublic static class helloworldimpl implements helloworld {\n\n    private string greeting = "hello";\n    private int count = 0;\n\n    @override\n    public void sayhello(string name) {\n        while (!"bye".equals(greeting)) {\n            logger.info(++count + ": " + greeting + " " + name + "!");\n            string oldgreeting = greeting;\n            workflow.await(() -> !objects.equals(greeting, oldgreeting));\n        }\n        logger.info(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @override\n    public void updategreeting(string greeting) {\n        this.greeting = greeting;\n    }\n\n    @override\n    public int getcount() {\n        return count;\n    }\n}\n\n\nthe new getcount method annotated with @querymethod was added to the interface definition. it is allowed to have multiple methods per interface.\n\nthe main restriction on the implementation of the method is that it is not allowed to modify state in any form. it also is not allowed to block its thread in any way. it usually just returns a value derived from the fields of the object. let\'s run the updated and send a couple to it:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "helloquery" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"world\\"\nstarted workflow id: helloquery, run id: 1925f668-45b5-4405-8cba-74f7c68c3135\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "helloquery" --name "helloworld::updategreeting" --input \\"hi\\"\nsignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "helloquery" --name "helloworld::updategreeting" --input \\"welcome\\"\nsignal workflow succeeded.\n\n\nthe output:\n\n17:35:50.485 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 1: hello world!\n17:36:10.483 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 2: hi world!\n17:36:16.204 [workflow-root] info  c.u.c.samples.hello.gettingstarted - 3: welcome world!\n\n\nnow let\'s the using the \n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "helloquery" --query_type "helloworld::getcount"\n:query:query: result as json:\n3\n\n\none limitation of the is that it requires a process running because it is executing callback code. an interesting feature of the is that it works for completed as well. let\'s complete the by sending "bye" and it.\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow signal --workflow_id "helloquery" --name "helloworld::updategreeting" --input \\"bye\\"\nsignal workflow succeeded.\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow query --workflow_id "helloquery" --query_type "helloworld::getcount"\n:query:query: result as json:\n4\n\n\nthe method can accept parameters. this might be useful if only part of the state should be returned.\n\n# activities\nhaving fault tolerant code that maintains state, updates it in reaction to external , and supports is already very useful. but in most practical applications, the is expected to act upon the external world. cadence supports such externally-facing code in the form of .\n\nan is essentially a function that can execute any code like db updates or service calls. the is not allowed to directly call any external apis; it can do this only through . the is essentially an orchestrator of . let\'s change our program to print the greeting from an on every change.\n\nfirst let\'s define an interface and implement it:\n\npublic interface helloworldactivities {\n    @activitymethod(scheduletoclosetimeoutseconds = 100)\n    void say(string message);\n}\n\n\nthe @activitymethod annotation is not required, but scheduletoclosetimeoutseconds is required and annotation is a convenient way to specify it. it is allowed to have multiple on a single interface.\n\nactivity implementation is just a normal pojo. the out stream is passed as a parameter to the constructor to demonstrate that the activity object can have any dependencies. examples of real application dependencies are database connections and service clients.\n\npublic class hellowordactivitiesimpl implements helloworldactivities {\n    private final printstream out;\n\n    public hellowordactivitiesimpl(printstream out) {\n        this.out = out;\n    }\n\n    @override\n    public void say(string message) {\n        out.println(message);\n    }\n}\n\n\nlet\'s create a separate main method for the . it is common to have a single that hosts both and , but here we keep them separate to demonstrate how cadence deals with failures. to make the implementation known to cadence, register it with the \n\npublic class gettingstartedactivityworker {\n\n    public static void main(string[] args) {\n        worker.factory factory = new worker.factory("test-domain");\n        worker worker = factory.newworker("helloworldtasklist");\n        worker.registeractivitiesimplementations(new hellowordactivitiesimpl(system.out));\n        factory.start();\n    }\n}\n\n\na single instance of an object is registered per interface type. this means that the implementation should be thread-safe since the method can be simultaneously called from multiple threads.\n\nlet\'s modify the code to invoke the instead of logging:\n\npublic static class helloworldimpl implements helloworld {\n\n    private final helloworldactivities activities = workflow.newactivitystub(helloworldactivities.class);\n    private string greeting = "hello";\n    private int count = 0;\n\n    @override\n    public void sayhello(string name) {\n        while (!"bye".equals(greeting)) {\n            activities.say(++count + ": " + greeting + " " + name + "!");\n            string oldgreeting = greeting;\n            workflow.await(() -> !objects.equals(greeting, oldgreeting));\n        }\n        activities.say(++count + ": " + greeting + " " + name + "!");\n    }\n\n    @override\n    public void updategreeting(string greeting) {\n        this.greeting = greeting;\n    }\n\n    @override\n    public int getcount() {\n        return count;\n    }\n}\n\n\n are invoked through a stub that implements their interface. so an invocation is just a method call on an stub.\n\nnow run the . do not run the yet. then start a new \n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow start  --workflow_id "helloactivityworker" --tasklist helloworldtasklist --workflow_type helloworld::sayhello --execution_timeout 3600 --input \\"world\\"\nstarted workflow id: helloactivityworker, run id: ff015637-b5af-43e8-b3f6-8b6c7b919b62\n\n\nthe is started, but nothing visible happens. this is expected as the is not running. what are the options to understand the currently running state?\n\nthe first option is look at the stack trace:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow stack  --workflow_id "helloactivityworker"\n:query:query: result as json:\n"workflow-root: (blocked on feature.get)com.uber.cadence.internal.sync.completablepromiseimpl.get(completablepromiseimpl.java:71)\ncom.uber.cadence.internal.sync.activitystubimpl.execute(activitystubimpl.java:58)\ncom.uber.cadence.internal.sync.activityinvocationhandler.lambda$invoke$0(activityinvocationhandler.java:87)\ncom.uber.cadence.internal.sync.activityinvocationhandler$$lambda$25/1816732716.apply(unknown source)\ncom.uber.cadence.internal.sync.activityinvocationhandler.invoke(activityinvocationhandler.java:94)\ncom.sun.proxy.$proxy6.say(unknown source)\ncom.uber.cadence.samples.hello.gettingstarted$helloworldimpl.sayhello(gettingstarted.java:55)\nsun.reflect.nativemethodaccessorimpl.invoke0(native method)\nsun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62)\n"\n\n\nit shows that the code is blocked on the "say" method of a proxy object that implements the stub. you can restart the if you want to make sure that restarting it does not change that. it works for of any duration. it is okay for the code to block on an invocation for a month for example.\n\nanother way to see what exactly happened in the is to look at the history:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow show  --workflow_id "helloactivityworker"\n  1  workflowexecutionstarted  {workflowtype:{name:helloworld::sayhello},\n                                tasklist:{name:helloworldtasklist},\n                                input:["world"],\n                                executionstarttoclosetimeoutseconds:3600,\n                                taskstarttoclosetimeoutseconds:10,\n                                continuedfailuredetails:[],\n                                lastcompletionresult:[],\n                                identity:cadence-cli@linuxkit-025000000001,\n                                attempt:0,\n                                firstdecisiontaskbackoffseconds:0}\n  2  decisiontaskscheduled     {tasklist:{name:helloworldtasklist},\n                                starttoclosetimeoutseconds:10,\n                                attempt:0}\n  3  decisiontaskstarted       {scheduledeventid:2,\n                                identity:36234@maxim-c02xd0aajgh6,\n                                requestid:ef645576-7cee-4d2e-9892-597a08b7b01f}\n  4  decisiontaskcompleted     {executioncontext:[],\n                                scheduledeventid:2,\n                                startedeventid:3,\n                                identity:36234@maxim-c02xd0aajgh6}\n  5  activitytaskscheduled     {activityid:0,\n                                activitytype:{name:helloworldactivities::say},\n                                tasklist:{name:helloworldtasklist},\n                                input:["1: hello world!"],\n                                scheduletoclosetimeoutseconds:100,\n                                scheduletostarttimeoutseconds:100,\n                                starttoclosetimeoutseconds:100,\n                                heartbeattimeoutseconds:100,\n                                decisiontaskcompletedeventid:4}\n\n\nthe last in the history is activitytaskscheduled. it is recorded when invoked the , but it wasn\'t picked up by an yet.\n\nanother useful api is describeworkflowexecution which, among other information, contains the list of outstanding activities:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow describe  --workflow_id "helloactivityworker"\n{\n    "executionconfiguration": {\n        "tasklist": {\n            "name": "helloworldtasklist"\n        },\n        "executionstarttoclosetimeoutseconds": 3600,\n        "taskstarttoclosetimeoutseconds": 10,\n        "childpolicy": "terminate"\n    },\n    "workflowexecutioninfo": {\n        "execution": {\n            "workflowid": "helloactivityworker",\n            "runid": "ff015637-b5af-43e8-b3f6-8b6c7b919b62"\n        },\n        "type": {\n            "name": "helloworld::sayhello"\n        },\n        "starttime": "2019-06-08t23:56:41z",\n        "closetime": "1970-01-01t00:00:00z",\n        "closestatus": null,\n        "historylength": 5,\n        "parentdomainid": null,\n        "parentexecution": null,\n        "autoresetpoints": {}\n    },\n    "pendingactivities": [\n        {\n            "activityid": "0",\n            "activitytype": {\n                "name": "helloworldactivities::say"\n            },\n            "state": "scheduled",\n            "scheduledtimestamp": "2019-06-08t23:57:00z"\n        }\n    ]\n}\n\n\nlet\'s start the . it starts and immediately prints:\n\n1: hello world!\n\n\nlet\'s look at the history:\n\ncadence: docker run --network=host --rm ubercadence/cli:master --do test-domain workflow show  --workflow_id "helloactivityworker"\n   1  workflowexecutionstarted  {workflowtype:{name:helloworld::sayhello},\n                                tasklist:{name:helloworldtasklist},\n                                input:["world"],\n                                executionstarttoclosetimeoutseconds:3600,\n                                taskstarttoclosetimeoutseconds:10,\n                                continuedfailuredetails:[],\n                                lastcompletionresult:[],\n                                identity:cadence-cli@linuxkit-025000000001,\n                                attempt:0,\n                                firstdecisiontaskbackoffseconds:0}\n   2  decisiontaskscheduled     {tasklist:{name:helloworldtasklist},\n                                starttoclosetimeoutseconds:10,\n                                attempt:0}\n   3  decisiontaskstarted       {scheduledeventid:2,\n                                identity:37694@maxim-c02xd0aajgh6,\n                                requestid:1d7cba6d-98c8-41fd-91b1-c27dffb21c7f}\n   4  decisiontaskcompleted     {executioncontext:[],\n                                scheduledeventid:2,\n                                startedeventid:3,\n                                identity:37694@maxim-c02xd0aajgh6}\n   5  activitytaskscheduled     {activityid:0,\n                                activitytype:{name:helloworldactivities::say},\n                                tasklist:{name:helloworldtasklist},\n                                input:["1: hello world!"],\n                                scheduletoclosetimeoutseconds:300,\n                                scheduletostarttimeoutseconds:300,\n                                starttoclosetimeoutseconds:300,\n                                heartbeattimeoutseconds:300,\n                                decisiontaskcompletedeventid:4}\n   6  activitytaskstarted       {scheduledeventid:5,\n                                identity:37784@maxim-c02xd0aajgh6,\n                                requestid:a646d5d2-566f-4f43-92d7-6689139ce944,\n                                attempt:0}\n   7  activitytaskcompleted     {result:[], scheduledeventid:5,\n                                startedeventid:6,\n                                identity:37784@maxim-c02xd0aajgh6}\n   8  decisiontaskscheduled     {tasklist:{name:maxim-c02xd0aajgh6:fd3a85ed-752d-4662-a49d-2665b7667c8a},\n                                starttoclosetimeoutseconds:10, attempt:0}\n   9  decisiontaskstarted       {scheduledeventid:8,\n                                identity:fd3a85ed-752d-4662-a49d-2665b7667c8a,\n                                requestid:601ef30a-0d1b-4400-b034-65b8328ad34c}\n  10  decisiontaskcompleted     {executioncontext:[],\n                                scheduledeventid:8,\n                                startedeventid:9,\n                                identity:37694@maxim-c02xd0aajgh6}\n\n\nactivitytaskstarted is recorded when the is picked up by an . the identity field contains the id of the (you can set it to any value on startup).\n\nactivitytaskcompleted is recorded when completes. it contains the result of the execution.\n\nlet\'s look at various failure scenarios. modify timeout:\n\npublic interface helloworldactivities {\n    @activitymethod(scheduletoclosetimeoutseconds = 100)\n    void say(string message);\n}\n\npublic class hellowordactivitiesimpl implements helloworldactivities {\n    private final printstream out;\n\n    public hellowordactivitiesimpl(printstream out) {\n        this.out = out;\n    }\n\n    @override\n    public void say(string message) {\n        out.println(message);\n    }\n}\n\n\n(to be continued ...)',charsets:{cjk:!0}},{title:"Workflow interface",frontmatter:{layout:"default",title:"Workflow interface",permalink:"/docs/java-client/workflow-interface",readingShow:"top"},regularPath:"/docs/04-java-client/02-workflow-interface.html",relativePath:"docs/04-java-client/02-workflow-interface.md",key:"v-3d11f802",path:"/docs/java-client/workflow-interface/",headersStr:null,content:'# Workflow interface\n encapsulates the orchestration of and child . It can also answer synchronous and receive external (also known as ).\n\nA must define an interface class. All of its methods must have one of the following annotations:\n\n * @WorkflowMethod indicates an entry point to a . It contains parameters such as timeouts and a . Required parameters (such as executionStartToCloseTimeoutSeconds) that are not specified through the annotation must be provided at runtime.\n * @SignalMethod indicates a method that reacts to external . It must have a void return type.\n * @QueryMethod indicates a method that reacts to synchronous requests.\n\nYou can have more than one method with the same annotation (except @WorkflowMethod). For example:\n\npublic interface FileProcessingWorkflow {\n\n    @WorkflowMethod(executionStartToCloseTimeoutSeconds = 10, taskList = "file-processing")\n    String processFile(Arguments args);\n\n    @QueryMethod(name="history")\n    List<String> getHistory();\n\n    @QueryMethod(name="status")\n    String getStatus();\n\n    @SignalMethod\n    void retryNow();\n\n    @SignalMethod\n    void abandon();\n}\n\n\nWe recommended that you use a single value type argument for methods. In this way, adding new arguments as fields to the value type is a backwards-compatible change.',normalizedContent:'# workflow interface\n encapsulates the orchestration of and child . it can also answer synchronous and receive external (also known as ).\n\na must define an interface class. all of its methods must have one of the following annotations:\n\n * @workflowmethod indicates an entry point to a . it contains parameters such as timeouts and a . required parameters (such as executionstarttoclosetimeoutseconds) that are not specified through the annotation must be provided at runtime.\n * @signalmethod indicates a method that reacts to external . it must have a void return type.\n * @querymethod indicates a method that reacts to synchronous requests.\n\nyou can have more than one method with the same annotation (except @workflowmethod). for example:\n\npublic interface fileprocessingworkflow {\n\n    @workflowmethod(executionstarttoclosetimeoutseconds = 10, tasklist = "file-processing")\n    string processfile(arguments args);\n\n    @querymethod(name="history")\n    list<string> gethistory();\n\n    @querymethod(name="status")\n    string getstatus();\n\n    @signalmethod\n    void retrynow();\n\n    @signalmethod\n    void abandon();\n}\n\n\nwe recommended that you use a single value type argument for methods. in this way, adding new arguments as fields to the value type is a backwards-compatible change.',charsets:{}},{title:"Implementing workflows",frontmatter:{layout:"default",title:"Implementing workflows",permalink:"/docs/java-client/implementing-workflows",readingShow:"top"},regularPath:"/docs/04-java-client/03-implementing-workflows.html",relativePath:"docs/04-java-client/03-implementing-workflows.md",key:"v-264670c2",path:"/docs/java-client/implementing-workflows/",headers:[{level:2,title:"Calling Activities",slug:"calling-activities",normalizedTitle:"calling activities",charIndex:513},{level:2,title:"Calling Activities Asynchronously",slug:"calling-activities-asynchronously",normalizedTitle:"calling activities asynchronously",charIndex:2715},{level:2,title:"Child Workflows",slug:"child-workflows",normalizedTitle:"child workflows",charIndex:5577},{level:2,title:"Workflow Implementation Constraints",slug:"workflow-implementation-constraints",normalizedTitle:"workflow implementation constraints",charIndex:8481}],headersStr:"Calling Activities Calling Activities Asynchronously Child Workflows Workflow Implementation Constraints",content:'# Implementing workflows\nA implementation implements a interface. Each time a new is started, a new instance of the implementation object is created. Then, one of the methods (depending on which type has been started) annotated with @WorkflowMethod is invoked. As soon as this method returns, the is closed. While is open, it can receive calls to and methods. No additional calls to methods are allowed. The object is stateful, so and methods can communicate with the other parts of the through object fields.\n\n# Calling Activities\nWorkflow.newActivityStub returns a client-side stub that implements an interface. It takes type and options as arguments. options are needed only if some of the required timeouts are not specified through the @ActivityMethod annotation.\n\nCalling a method on this interface invokes an that implements this method. An invocation synchronously blocks until the completes, fails, or times out. Even if execution takes a few months, the code still sees it as a single synchronous invocation. It doesn\'t matter what happens to the processes that host the . The business logic code just sees a single method call.\n\npublic class FileProcessingWorkflowImpl implements FileProcessingWorkflow {\n\n    private final FileProcessingActivities activities;\n\n    public FileProcessingWorkflowImpl() {\n        this.activities = Workflow.newActivityStub(FileProcessingActivities.class);\n    }\n\n    @Override\n    public void processFile(Arguments args) {\n        String localName = null;\n        String processedName = null;\n        try {\n            localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n            processedName = activities.processFile(localName);\n            activities.upload(args.getTargetBucketName(), args.getTargetFilename(), processedName);\n        } finally {\n            if (localName != null) { // File was downloaded.\n                activities.deleteLocalFile(localName);\n            }\n            if (processedName != null) { // File was processed.\n                activities.deleteLocalFile(processedName);\n            }\n        }\n    }\n    ...\n}\n\n\nIf different need different options, like timeouts or a , multiple client-side stubs can be created with different options.\n\npublic FileProcessingWorkflowImpl() {\n    ActivityOptions options1 = new ActivityOptions.Builder()\n             .setTaskList("taskList1")\n             .build();\n    this.store1 = Workflow.newActivityStub(FileProcessingActivities.class, options1);\n\n    ActivityOptions options2 = new ActivityOptions.Builder()\n             .setTaskList("taskList2")\n             .build();\n    this.store2 = Workflow.newActivityStub(FileProcessingActivities.class, options2);\n}\n\n\n# Calling Activities Asynchronously\nSometimes need to perform certain operations in parallel. The Async class static methods allow you to invoke any asynchronously. The calls return a Promise result immediately.Promise is similar to both Java Future and CompletionStage. The Promise get blocks until a result is available. It also exposes the thenApply and handle methods. See the Promise JavaDoc for technical details about differences with Future.\n\nTo convert a synchronous call:\n\nString localName = activities.download(sourceBucket, sourceFile);\n\n\nTo asynchronous style, the method reference is passed to Async.function or Async.procedurefollowed by arguments:\n\nPromise<String> localNamePromise = Async.function(activities::download, sourceBucket, sourceFile);\n\n\nThen to wait synchronously for the result:\n\nString localName = localNamePromise.get();\n\n\nHere is the above example rewritten to call download and upload in parallel on multiple files:\n\npublic void processFile(Arguments args) {\n    List<Promise<String>> localNamePromises = new ArrayList<>();\n    List<String> processedNames = null;\n    try {\n        // Download all files in parallel.\n        for (String sourceFilename : args.getSourceFilenames()) {\n            Promise<String> localName = Async.function(activities::download,\n                args.getSourceBucketName(), sourceFilename);\n            localNamePromises.add(localName);\n        }\n        // allOf converts a list of promises to a single promise that contains a list\n        // of each promise value.\n        Promise<List<String>> localNamesPromise = Promise.allOf(localNamePromises);\n\n        // All code until the next line wasn\'t blocking.\n        // The promise get is a blocking call.\n        List<String> localNames = localNamesPromise.get();\n        processedNames = activities.processFiles(localNames);\n\n        // Upload all results in parallel.\n        List<Promise<Void>> uploadedList = new ArrayList<>();\n        for (String processedName : processedNames) {\n            Promise<Void> uploaded = Async.procedure(activities::upload,\n                args.getTargetBucketName(), args.getTargetFilename(), processedName);\n            uploadedList.add(uploaded);\n        }\n        // Wait for all uploads to complete.\n        Promise<?> allUploaded = Promise.allOf(uploadedList);\n        allUploaded.get(); // blocks until all promises are ready.\n    } finally {\n        for (Promise<String> localNamePromise : localNamePromises) {\n            // Skip files that haven\'t completed downloading.\n            if (localNamePromise.isCompleted()) {\n                activities.deleteLocalFile(localNamePromise.get());\n            }\n        }\n        if (processedNames != null) {\n            for (String processedName : processedNames) {\n                activities.deleteLocalFile(processedName);\n            }\n        }\n    }\n}\n\n\n# Child Workflows\nBesides , a can also orchestrate other .\n\nWorkflow.newChildWorkflowStub returns a client-side stub that implements a child interface. It takes a child type and optional child options as arguments. options may be needed to override the timeouts and if they differ from the ones defined in the @WorkflowMethod annotation or parent .\n\nThe first call to the child stub must always be to a method annotated with @WorkflowMethod. Similar to , a call can be made synchronous or asynchronous by using Async#function or Async#procedure. The synchronous call blocks until a child completes. The asynchronous call returns a Promise that can be used to wait for the completion. After an async call returns the stub, it can be used to send to the child by calling methods annotated with @SignalMethod. a child by calling methods annotated with @QueryMethodfrom within code is not supported. However, can be done from using the provided WorkflowClient stub.\n\npublic interface GreetingChild {\n   @WorkflowMethod\n   String composeGreeting(String greeting, String name);\n}\n\npublic static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n   @Override\n   public String getGreeting(String name) {\n       GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n\n       // This is a blocking call that returns only after child has completed.\n       return child.composeGreeting("Hello", name );\n   }\n}\n\n\nRunning two children in parallel:\n\npublic static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n    @Override\n    public String getGreeting(String name) {\n\n        // Workflows are stateful, so a new stub must be created for each new child.\n        GreetingChild child1 = Workflow.newChildWorkflowStub(GreetingChild.class);\n        Promise<String> greeting1 = Async.function(child1::composeGreeting, "Hello", name);\n\n        // Both children will run concurrently.\n        GreetingChild child2 = Workflow.newChildWorkflowStub(GreetingChild.class);\n        Promise<String> greeting2 = Async.function(child2::composeGreeting, "Bye", name);\n\n        // Do something else here.\n        ...\n        return "First: " + greeting1.get() + ", second: " + greeting2.get();\n    }\n}\n\n\nTo send a to a child, call a method annotated with @SignalMethod:\n\npublic interface GreetingChild {\n    @WorkflowMethod\n    String composeGreeting(String greeting, String name);\n\n    @SignalMethod\n    void updateName(String name);\n}\n\npublic static class GreetingWorkflowImpl implements GreetingWorkflow {\n\n    @Override\n    public String getGreeting(String name) {\n        GreetingChild child = Workflow.newChildWorkflowStub(GreetingChild.class);\n        Promise<String> greeting = Async.function(child::composeGreeting, "Hello", name);\n        child.updateName("Cadence");\n        return greeting.get();\n    }\n}\n\n\nCalling methods annotated with @QueryMethod is not allowed from within code.\n\n# Workflow Implementation Constraints\nCadence uses the Microsoft Azure Event Sourcing pattern to recover the state of a object including its threads and local variable values. In essence, every time a state has to be restored, its code is re-executed from the beginning. When replaying, side effects (such as invocations) are ignored because they are already recorded in the . When writing logic, the replay is not visible, so the code should be written since it executes only once. This design puts the following constraints on the implementation:\n\n * Do not use any mutable global variables because multiple instances of are executed in parallel.\n * Do not call any non-deterministic functions like non seeded random or UUID.randomUUID() directly from the code.\n\nAlways do the following in :\n\n * Don’t perform any IO or service calls as they are not usually deterministic. Use for this.\n * Only use Workflow.currentTimeMillis() to get the current time inside a .\n * Do not use native Java Thread or any other multi-threaded classes like ThreadPoolExecutor. Use Async.function or Async.procedureto execute code asynchronously.\n * Don\'t use any synchronization, locks, and other standard Java blocking concurrency-related classes besides those provided by the Workflow class. There is no need in explicit synchronization because multi-threaded code inside a is executed one thread at a time and under a global lock. * Call WorkflowThread.sleep instead of Thread.sleep.\n    * Use Promise and CompletablePromise instead of Future and CompletableFuture.\n    * Use WorkflowQueue instead of BlockingQueue.\n   \n   \n * Use Workflow.getVersion when making any changes to the code. Without this, any deployment of updated code might break already open .\n * Don’t access configuration APIs directly from a because changes in the configuration might affect a path. Pass it as an argument to a function or use an to load it.\n\n method arguments and return values are serializable to a byte array using the providedDataConverterinterface. The default implementation uses JSON serializer, but you can use any alternative serialization mechanism.\n\nThe values passed to through invocation parameters or returned through a result value are recorded in the execution history. The entire execution history is transferred from the Cadence service to with every that the logic needs to process. A large execution history can thus adversely impact the performance of your . Therefore, be mindful of the amount of data that you transfer via invocation parameters or return values. Otherwise, no additional limitations exist on implementations.',normalizedContent:'# implementing workflows\na implementation implements a interface. each time a new is started, a new instance of the implementation object is created. then, one of the methods (depending on which type has been started) annotated with @workflowmethod is invoked. as soon as this method returns, the is closed. while is open, it can receive calls to and methods. no additional calls to methods are allowed. the object is stateful, so and methods can communicate with the other parts of the through object fields.\n\n# calling activities\nworkflow.newactivitystub returns a client-side stub that implements an interface. it takes type and options as arguments. options are needed only if some of the required timeouts are not specified through the @activitymethod annotation.\n\ncalling a method on this interface invokes an that implements this method. an invocation synchronously blocks until the completes, fails, or times out. even if execution takes a few months, the code still sees it as a single synchronous invocation. it doesn\'t matter what happens to the processes that host the . the business logic code just sees a single method call.\n\npublic class fileprocessingworkflowimpl implements fileprocessingworkflow {\n\n    private final fileprocessingactivities activities;\n\n    public fileprocessingworkflowimpl() {\n        this.activities = workflow.newactivitystub(fileprocessingactivities.class);\n    }\n\n    @override\n    public void processfile(arguments args) {\n        string localname = null;\n        string processedname = null;\n        try {\n            localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n            processedname = activities.processfile(localname);\n            activities.upload(args.gettargetbucketname(), args.gettargetfilename(), processedname);\n        } finally {\n            if (localname != null) { // file was downloaded.\n                activities.deletelocalfile(localname);\n            }\n            if (processedname != null) { // file was processed.\n                activities.deletelocalfile(processedname);\n            }\n        }\n    }\n    ...\n}\n\n\nif different need different options, like timeouts or a , multiple client-side stubs can be created with different options.\n\npublic fileprocessingworkflowimpl() {\n    activityoptions options1 = new activityoptions.builder()\n             .settasklist("tasklist1")\n             .build();\n    this.store1 = workflow.newactivitystub(fileprocessingactivities.class, options1);\n\n    activityoptions options2 = new activityoptions.builder()\n             .settasklist("tasklist2")\n             .build();\n    this.store2 = workflow.newactivitystub(fileprocessingactivities.class, options2);\n}\n\n\n# calling activities asynchronously\nsometimes need to perform certain operations in parallel. the async class static methods allow you to invoke any asynchronously. the calls return a promise result immediately.promise is similar to both java future and completionstage. the promise get blocks until a result is available. it also exposes the thenapply and handle methods. see the promise javadoc for technical details about differences with future.\n\nto convert a synchronous call:\n\nstring localname = activities.download(sourcebucket, sourcefile);\n\n\nto asynchronous style, the method reference is passed to async.function or async.procedurefollowed by arguments:\n\npromise<string> localnamepromise = async.function(activities::download, sourcebucket, sourcefile);\n\n\nthen to wait synchronously for the result:\n\nstring localname = localnamepromise.get();\n\n\nhere is the above example rewritten to call download and upload in parallel on multiple files:\n\npublic void processfile(arguments args) {\n    list<promise<string>> localnamepromises = new arraylist<>();\n    list<string> processednames = null;\n    try {\n        // download all files in parallel.\n        for (string sourcefilename : args.getsourcefilenames()) {\n            promise<string> localname = async.function(activities::download,\n                args.getsourcebucketname(), sourcefilename);\n            localnamepromises.add(localname);\n        }\n        // allof converts a list of promises to a single promise that contains a list\n        // of each promise value.\n        promise<list<string>> localnamespromise = promise.allof(localnamepromises);\n\n        // all code until the next line wasn\'t blocking.\n        // the promise get is a blocking call.\n        list<string> localnames = localnamespromise.get();\n        processednames = activities.processfiles(localnames);\n\n        // upload all results in parallel.\n        list<promise<void>> uploadedlist = new arraylist<>();\n        for (string processedname : processednames) {\n            promise<void> uploaded = async.procedure(activities::upload,\n                args.gettargetbucketname(), args.gettargetfilename(), processedname);\n            uploadedlist.add(uploaded);\n        }\n        // wait for all uploads to complete.\n        promise<?> alluploaded = promise.allof(uploadedlist);\n        alluploaded.get(); // blocks until all promises are ready.\n    } finally {\n        for (promise<string> localnamepromise : localnamepromises) {\n            // skip files that haven\'t completed downloading.\n            if (localnamepromise.iscompleted()) {\n                activities.deletelocalfile(localnamepromise.get());\n            }\n        }\n        if (processednames != null) {\n            for (string processedname : processednames) {\n                activities.deletelocalfile(processedname);\n            }\n        }\n    }\n}\n\n\n# child workflows\nbesides , a can also orchestrate other .\n\nworkflow.newchildworkflowstub returns a client-side stub that implements a child interface. it takes a child type and optional child options as arguments. options may be needed to override the timeouts and if they differ from the ones defined in the @workflowmethod annotation or parent .\n\nthe first call to the child stub must always be to a method annotated with @workflowmethod. similar to , a call can be made synchronous or asynchronous by using async#function or async#procedure. the synchronous call blocks until a child completes. the asynchronous call returns a promise that can be used to wait for the completion. after an async call returns the stub, it can be used to send to the child by calling methods annotated with @signalmethod. a child by calling methods annotated with @querymethodfrom within code is not supported. however, can be done from using the provided workflowclient stub.\n\npublic interface greetingchild {\n   @workflowmethod\n   string composegreeting(string greeting, string name);\n}\n\npublic static class greetingworkflowimpl implements greetingworkflow {\n\n   @override\n   public string getgreeting(string name) {\n       greetingchild child = workflow.newchildworkflowstub(greetingchild.class);\n\n       // this is a blocking call that returns only after child has completed.\n       return child.composegreeting("hello", name );\n   }\n}\n\n\nrunning two children in parallel:\n\npublic static class greetingworkflowimpl implements greetingworkflow {\n\n    @override\n    public string getgreeting(string name) {\n\n        // workflows are stateful, so a new stub must be created for each new child.\n        greetingchild child1 = workflow.newchildworkflowstub(greetingchild.class);\n        promise<string> greeting1 = async.function(child1::composegreeting, "hello", name);\n\n        // both children will run concurrently.\n        greetingchild child2 = workflow.newchildworkflowstub(greetingchild.class);\n        promise<string> greeting2 = async.function(child2::composegreeting, "bye", name);\n\n        // do something else here.\n        ...\n        return "first: " + greeting1.get() + ", second: " + greeting2.get();\n    }\n}\n\n\nto send a to a child, call a method annotated with @signalmethod:\n\npublic interface greetingchild {\n    @workflowmethod\n    string composegreeting(string greeting, string name);\n\n    @signalmethod\n    void updatename(string name);\n}\n\npublic static class greetingworkflowimpl implements greetingworkflow {\n\n    @override\n    public string getgreeting(string name) {\n        greetingchild child = workflow.newchildworkflowstub(greetingchild.class);\n        promise<string> greeting = async.function(child::composegreeting, "hello", name);\n        child.updatename("cadence");\n        return greeting.get();\n    }\n}\n\n\ncalling methods annotated with @querymethod is not allowed from within code.\n\n# workflow implementation constraints\ncadence uses the microsoft azure event sourcing pattern to recover the state of a object including its threads and local variable values. in essence, every time a state has to be restored, its code is re-executed from the beginning. when replaying, side effects (such as invocations) are ignored because they are already recorded in the . when writing logic, the replay is not visible, so the code should be written since it executes only once. this design puts the following constraints on the implementation:\n\n * do not use any mutable global variables because multiple instances of are executed in parallel.\n * do not call any non-deterministic functions like non seeded random or uuid.randomuuid() directly from the code.\n\nalways do the following in :\n\n * don’t perform any io or service calls as they are not usually deterministic. use for this.\n * only use workflow.currenttimemillis() to get the current time inside a .\n * do not use native java thread or any other multi-threaded classes like threadpoolexecutor. use async.function or async.procedureto execute code asynchronously.\n * don\'t use any synchronization, locks, and other standard java blocking concurrency-related classes besides those provided by the workflow class. there is no need in explicit synchronization because multi-threaded code inside a is executed one thread at a time and under a global lock. * call workflowthread.sleep instead of thread.sleep.\n    * use promise and completablepromise instead of future and completablefuture.\n    * use workflowqueue instead of blockingqueue.\n   \n   \n * use workflow.getversion when making any changes to the code. without this, any deployment of updated code might break already open .\n * don’t access configuration apis directly from a because changes in the configuration might affect a path. pass it as an argument to a function or use an to load it.\n\n method arguments and return values are serializable to a byte array using the provideddataconverterinterface. the default implementation uses json serializer, but you can use any alternative serialization mechanism.\n\nthe values passed to through invocation parameters or returned through a result value are recorded in the execution history. the entire execution history is transferred from the cadence service to with every that the logic needs to process. a large execution history can thus adversely impact the performance of your . therefore, be mindful of the amount of data that you transfer via invocation parameters or return values. otherwise, no additional limitations exist on implementations.',charsets:{}},{title:"Starting workflows",frontmatter:{layout:"default",title:"Starting workflows",permalink:"/docs/java-client/starting-workflow-executions",readingShow:"top"},regularPath:"/docs/04-java-client/04-starting-workflow-executions.html",relativePath:"docs/04-java-client/04-starting-workflow-executions.md",key:"v-11997e3c",path:"/docs/java-client/starting-workflow-executions/",headersStr:null,content:'# Starting workflow executions\nA interface that executes a requires initializing a WorkflowClient instance, creating a client side stub to the , and then calling a method annotated with @WorkflowMethod.\n\nWorkflowClient workflowClient = WorkflowClient.newClient(cadenceServiceHost, cadenceServicePort, domain);\n// Create a workflow stub.\nFileProcessingWorkflow workflow = workflowClient.newWorkflowStub(FileProcessingWorkflow.class);\n\n\nThere are two ways to start asynchronously and synchronously. Asynchronous start initiates a and immediately returns to the caller. This is the most common way to start in production code. Synchronous invocation starts a and then waits for its completion. If the process that started the crashes or stops waiting, the continues executing. Because are potentially long running, and crashes of clients happen, this is not very commonly found in production use.\n\nAsynchronous start:\n\n// Returns as soon as the workflow starts.\nWorkflowExecution workflowExecution = WorkflowClient.start(workflow::processFile, workflowArgs);\n\nSystem.out.println("Started process file workflow with workflowId=\\"" + workflowExecution.getWorkflowId()\n                    + "\\" and runId=\\"" + workflowExecution.getRunId() + "\\"");\n\n\nSynchronous start:\n\n// Start a workflow and then wait for a result.\n// Note that if the waiting process is killed, the workflow will continue execution.\nString result = workflow.processFile(workflowArgs);\n\n\nIf you need to wait for a completion after an asynchronous start, the most straightforward way is to call the blocking version again. If WorkflowOptions.WorkflowIdReusePolicy is not AllowDuplicate, then instead of throwing DuplicateWorkflowException, it reconnects to an existing and waits for its completion. The following example shows how to do this from a different process than the one that started the . All this process needs is a WorkflowID.\n\nWorkflowExecution execution = new WorkflowExecution().setWorkflowId(workflowId);\nFileProcessingWorkflow workflow = workflowClient.newWorkflowStub(execution);\n// Returns result potentially waiting for workflow to complete.\nString result = workflow.processFile(workflowArgs);',normalizedContent:'# starting workflow executions\na interface that executes a requires initializing a workflowclient instance, creating a client side stub to the , and then calling a method annotated with @workflowmethod.\n\nworkflowclient workflowclient = workflowclient.newclient(cadenceservicehost, cadenceserviceport, domain);\n// create a workflow stub.\nfileprocessingworkflow workflow = workflowclient.newworkflowstub(fileprocessingworkflow.class);\n\n\nthere are two ways to start asynchronously and synchronously. asynchronous start initiates a and immediately returns to the caller. this is the most common way to start in production code. synchronous invocation starts a and then waits for its completion. if the process that started the crashes or stops waiting, the continues executing. because are potentially long running, and crashes of clients happen, this is not very commonly found in production use.\n\nasynchronous start:\n\n// returns as soon as the workflow starts.\nworkflowexecution workflowexecution = workflowclient.start(workflow::processfile, workflowargs);\n\nsystem.out.println("started process file workflow with workflowid=\\"" + workflowexecution.getworkflowid()\n                    + "\\" and runid=\\"" + workflowexecution.getrunid() + "\\"");\n\n\nsynchronous start:\n\n// start a workflow and then wait for a result.\n// note that if the waiting process is killed, the workflow will continue execution.\nstring result = workflow.processfile(workflowargs);\n\n\nif you need to wait for a completion after an asynchronous start, the most straightforward way is to call the blocking version again. if workflowoptions.workflowidreusepolicy is not allowduplicate, then instead of throwing duplicateworkflowexception, it reconnects to an existing and waits for its completion. the following example shows how to do this from a different process than the one that started the . all this process needs is a workflowid.\n\nworkflowexecution execution = new workflowexecution().setworkflowid(workflowid);\nfileprocessingworkflow workflow = workflowclient.newworkflowstub(execution);\n// returns result potentially waiting for workflow to complete.\nstring result = workflow.processfile(workflowargs);',charsets:{}},{title:"Activity interface",frontmatter:{layout:"default",title:"Activity interface",permalink:"/docs/java-client/activity-interface",readingShow:"top"},regularPath:"/docs/04-java-client/05-activity-interface.html",relativePath:"docs/04-java-client/05-activity-interface.md",key:"v-5a20c23c",path:"/docs/java-client/activity-interface/",headersStr:null,content:"# Activity interface\nAn is a manifestation of a particular in the business logic.\n\n are defined as methods of a plain Java interface. Each method defines a single type. A single can use more than one interface and call more that one method from the same interface. The only requirement is that method arguments and return values are serializable to a byte array using the providedDataConverterinterface. The default implementation uses a JSON serializer, but an alternative implementation can be easily configured.\n\nFollowing is an example of an interface that defines four activities:\n\npublic interface FileProcessingActivities {\n\n    void upload(String bucketName, String localName, String targetName);\n\n    String download(String bucketName, String remoteName);\n\n    @ActivityMethod(scheduleToCloseTimeoutSeconds = 2)\n    String processFile(String localName);\n\n    void deleteLocalFile(String fileName);\n}\n\n\n\nWe recommend to use a single value type argument for methods. In this way, adding new arguments as fields to the value type is a backwards-compatible change.\n\nAn optional @ActivityMethod annotation can be used to specify options like timeouts or a . Required options that are not specified through the annotation must be specified at runtime.",normalizedContent:"# activity interface\nan is a manifestation of a particular in the business logic.\n\n are defined as methods of a plain java interface. each method defines a single type. a single can use more than one interface and call more that one method from the same interface. the only requirement is that method arguments and return values are serializable to a byte array using the provideddataconverterinterface. the default implementation uses a json serializer, but an alternative implementation can be easily configured.\n\nfollowing is an example of an interface that defines four activities:\n\npublic interface fileprocessingactivities {\n\n    void upload(string bucketname, string localname, string targetname);\n\n    string download(string bucketname, string remotename);\n\n    @activitymethod(scheduletoclosetimeoutseconds = 2)\n    string processfile(string localname);\n\n    void deletelocalfile(string filename);\n}\n\n\n\nwe recommend to use a single value type argument for methods. in this way, adding new arguments as fields to the value type is a backwards-compatible change.\n\nan optional @activitymethod annotation can be used to specify options like timeouts or a . required options that are not specified through the annotation must be specified at runtime.",charsets:{}},{title:"Implementing activities",frontmatter:{layout:"default",title:"Implementing activities",permalink:"/docs/java-client/implementing-activities",readingShow:"top"},regularPath:"/docs/04-java-client/06-implementing-activities.html",relativePath:"docs/04-java-client/06-implementing-activities.md",key:"v-056557ea",path:"/docs/java-client/implementing-activities/",headers:[{level:2,title:"Accessing Activity Info",slug:"accessing-activity-info",normalizedTitle:"accessing activity info",charIndex:1517},{level:2,title:"Asynchronous Activity Completion",slug:"asynchronous-activity-completion",normalizedTitle:"asynchronous activity completion",charIndex:2510},{level:2,title:"Activity Heart Beating",slug:"activity-heart-beating",normalizedTitle:"activity heart beating",charIndex:3924}],headersStr:"Accessing Activity Info Asynchronous Activity Completion Activity Heart Beating",content:'# Implementing activities\n implementation is an implementation of an interface. A single instance of the implementation is shared across multiple simultaneous invocations. Therefore, the implementation code must be thread safe.\n\nThe values passed to through invocation parameters or returned through a result value are recorded in the execution history. The entire execution history is transferred from the Cadence service to when a state needs to recover. A large execution history can thus adversely impact the performance of your . Therefore, be mindful of the amount of data you transfer via invocation parameters or return values. Otherwise, no additional limitations exist on implementations.\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    private final AmazonS3 s3Client;\n\n    private final String localDirectory;\n\n    void upload(String bucketName, String localName, String targetName) {\n        File f = new File(localName);\n        s3Client.putObject(bucket, remoteName, f);\n    }\n\n    String download(String bucketName, String remoteName, String localName) {\n        // Implementation omitted for brevity.\n        return downloadFileFromS3(bucketName, remoteName, localDirectory + localName);\n    }\n\n    String processFile(String localName) {\n        // Implementation omitted for brevity.\n        return compressFile(localName);\n    }\n\n    void deleteLocalFile(String fileName) {\n        File f = new File(localDirectory + fileName);\n        f.delete();\n    }\n}\n\n\n# Accessing Activity Info\nThe Activityclass provides static getters to access information about the that invoked it. Note that this information is stored in a thread local variable. Therefore, calls to accessors succeed only in the thread that invoked the function.\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    @Override\n    public String download(String bucketName, String remoteName, String localName) {\n        log.info("domain=" +  Activity.getDomain());\n        WorkflowExecution execution = Activity.getWorkflowExecution();\n        log.info("workflowId=" + execution.getWorkflowId());\n        log.info("runId=" + execution.getRunId());\n        ActivityTask activityTask = Activity.getTask();\n        log.info("activityId=" + activityTask.getActivityId());\n        log.info("activityTimeout=" + activityTask.getStartToCloseTimeoutSeconds());\n        return downloadFileFromS3(bucketName, remoteName, localDirectory + localName);\n    }\n    ...\n}\n\n\n# Asynchronous Activity Completion\nSometimes an lifecycle goes beyond a synchronous method invocation. For example, a request can be put in a queue and later a reply comes and is picked up by a different process. The whole request-reply interaction can be modeled as a single Cadence .\n\nTo indicate that an should not be completed upon its method return, call Activity.doNotCompleteOnReturn() from the original thread. Then later, when replies come, complete the using ActivityCompletionClient. To correlate invocation with completion, use either TaskToken or and IDs.\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    public String download(String bucketName, String remoteName, String localName) {\n        byte[] taskToken = Activity.getTaskToken(); // Used to correlate reply.\n        asyncDownloadFileFromS3(taskToken, bucketName, remoteName, localDirectory + localName);\n        Activity.doNotCompleteOnReturn();\n        return "ignored"; // Return value is ignored when doNotCompleteOnReturn was called.\n    }\n    ...\n}\n\n\nWhen the download is complete, the download service potentially calls back from a different process:\n\npublic <R> void completeActivity(byte[] taskToken, R result) {\n    completionClient.complete(taskToken, result);\n}\n\npublic void failActivity(byte[] taskToken, Exception failure) {\n    completionClient.completeExceptionally(taskToken, failure);\n}\n\n\n# Activity Heart Beating\nSome are long running. To react to a crash quickly, use a heartbeat mechanism. The Activity.heartbeat function lets the Cadence service know that the is still alive. You can piggybackdetails on an heartbeat. If an times out, the last value of details is included in the ActivityTimeoutException delivered to a . Then the can pass the details to the next invocation. This acts as a periodic checkpoint mechanism for the progress of an .\n\npublic class FileProcessingActivitiesImpl implements FileProcessingActivities {\n\n    @Override\n    public String download(String bucketName, String remoteName, String localName) {\n        InputStream inputStream = openInputStream(file);\n        try {\n            byte[] bytes = new byte[MAX_BUFFER_SIZE];\n            while ((read = inputStream.read(bytes)) != -1) {\n                totalRead += read;\n                f.write(bytes, 0, read);\n                /*\n                 * Let the service know about the download progress.\n                 */\n                Activity.heartbeat(totalRead);\n            }\n        } finally {\n            inputStream.close();\n        }\n    }\n    ...\n}',normalizedContent:'# implementing activities\n implementation is an implementation of an interface. a single instance of the implementation is shared across multiple simultaneous invocations. therefore, the implementation code must be thread safe.\n\nthe values passed to through invocation parameters or returned through a result value are recorded in the execution history. the entire execution history is transferred from the cadence service to when a state needs to recover. a large execution history can thus adversely impact the performance of your . therefore, be mindful of the amount of data you transfer via invocation parameters or return values. otherwise, no additional limitations exist on implementations.\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    private final amazons3 s3client;\n\n    private final string localdirectory;\n\n    void upload(string bucketname, string localname, string targetname) {\n        file f = new file(localname);\n        s3client.putobject(bucket, remotename, f);\n    }\n\n    string download(string bucketname, string remotename, string localname) {\n        // implementation omitted for brevity.\n        return downloadfilefroms3(bucketname, remotename, localdirectory + localname);\n    }\n\n    string processfile(string localname) {\n        // implementation omitted for brevity.\n        return compressfile(localname);\n    }\n\n    void deletelocalfile(string filename) {\n        file f = new file(localdirectory + filename);\n        f.delete();\n    }\n}\n\n\n# accessing activity info\nthe activityclass provides static getters to access information about the that invoked it. note that this information is stored in a thread local variable. therefore, calls to accessors succeed only in the thread that invoked the function.\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    @override\n    public string download(string bucketname, string remotename, string localname) {\n        log.info("domain=" +  activity.getdomain());\n        workflowexecution execution = activity.getworkflowexecution();\n        log.info("workflowid=" + execution.getworkflowid());\n        log.info("runid=" + execution.getrunid());\n        activitytask activitytask = activity.gettask();\n        log.info("activityid=" + activitytask.getactivityid());\n        log.info("activitytimeout=" + activitytask.getstarttoclosetimeoutseconds());\n        return downloadfilefroms3(bucketname, remotename, localdirectory + localname);\n    }\n    ...\n}\n\n\n# asynchronous activity completion\nsometimes an lifecycle goes beyond a synchronous method invocation. for example, a request can be put in a queue and later a reply comes and is picked up by a different process. the whole request-reply interaction can be modeled as a single cadence .\n\nto indicate that an should not be completed upon its method return, call activity.donotcompleteonreturn() from the original thread. then later, when replies come, complete the using activitycompletionclient. to correlate invocation with completion, use either tasktoken or and ids.\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    public string download(string bucketname, string remotename, string localname) {\n        byte[] tasktoken = activity.gettasktoken(); // used to correlate reply.\n        asyncdownloadfilefroms3(tasktoken, bucketname, remotename, localdirectory + localname);\n        activity.donotcompleteonreturn();\n        return "ignored"; // return value is ignored when donotcompleteonreturn was called.\n    }\n    ...\n}\n\n\nwhen the download is complete, the download service potentially calls back from a different process:\n\npublic <r> void completeactivity(byte[] tasktoken, r result) {\n    completionclient.complete(tasktoken, result);\n}\n\npublic void failactivity(byte[] tasktoken, exception failure) {\n    completionclient.completeexceptionally(tasktoken, failure);\n}\n\n\n# activity heart beating\nsome are long running. to react to a crash quickly, use a heartbeat mechanism. the activity.heartbeat function lets the cadence service know that the is still alive. you can piggybackdetails on an heartbeat. if an times out, the last value of details is included in the activitytimeoutexception delivered to a . then the can pass the details to the next invocation. this acts as a periodic checkpoint mechanism for the progress of an .\n\npublic class fileprocessingactivitiesimpl implements fileprocessingactivities {\n\n    @override\n    public string download(string bucketname, string remotename, string localname) {\n        inputstream inputstream = openinputstream(file);\n        try {\n            byte[] bytes = new byte[max_buffer_size];\n            while ((read = inputstream.read(bytes)) != -1) {\n                totalread += read;\n                f.write(bytes, 0, read);\n                /*\n                 * let the service know about the download progress.\n                 */\n                activity.heartbeat(totalread);\n            }\n        } finally {\n            inputstream.close();\n        }\n    }\n    ...\n}',charsets:{}},{title:"Versioning",frontmatter:{layout:"default",title:"Versioning",permalink:"/docs/java-client/versioning",readingShow:"top"},regularPath:"/docs/04-java-client/07-versioning.html",relativePath:"docs/04-java-client/07-versioning.md",key:"v-ee26987c",path:"/docs/java-client/versioning/",headersStr:null,content:'# Versioning\nAs outlined in the Workflow Implementation Constraints section, code has to be deterministic by taking the same code path when replaying history . Any code change that affects the order in which are generated breaks this assumption. The solution that allows updating code of already running is to keep both the old and new code. When replaying, use the code version that the were generated with and when executing a new code path, always take the new code.\n\nUse the Workflow.getVersion function to return a version of the code that should be executed and then use the returned value to pick a correct branch. Let\'s look at an example.\n\npublic void processFile(Arguments args) {\n    String localName = null;\n    String processedName = null;\n    try {\n        localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n        processedName = activities.processFile(localName);\n        activities.upload(args.getTargetBucketName(), args.getTargetFilename(), processedName);\n    } finally {\n        if (localName != null) { // File was downloaded.\n            activities.deleteLocalFile(localName);\n        }\n        if (processedName != null) { // File was processed.\n            activities.deleteLocalFile(processedName);\n        }\n    }\n}\n\n\nNow we decide to calculate the processed file checksum and pass it to upload. The correct way to implement this change is:\n\npublic void processFile(Arguments args) {\n    String localName = null;\n    String processedName = null;\n    try {\n        localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n        processedName = activities.processFile(localName);\n        int version = Workflow.getVersion("checksumAdded", Workflow.DEFAULT_VERSION, 1);\n        if (version == Workflow.DEFAULT_VERSION) {\n            activities.upload(args.getTargetBucketName(), args.getTargetFilename(), processedName);\n        } else {\n            long checksum = activities.calculateChecksum(processedName);\n            activities.uploadWithChecksum(\n                args.getTargetBucketName(), args.getTargetFilename(), processedName, checksum);\n        }\n    } finally {\n        if (localName != null) { // File was downloaded.\n            activities.deleteLocalFile(localName);\n        }\n        if (processedName != null) { // File was processed.\n            activities.deleteLocalFile(processedName);\n        }\n    }\n}\n\n\nLater, when all that use the old version are completed, the old branch can be removed.\n\npublic void processFile(Arguments args) {\n    String localName = null;\n    String processedName = null;\n    try {\n        localName = activities.download(args.getSourceBucketName(), args.getSourceFilename());\n        processedName = activities.processFile(localName);\n        // getVersion call is left here to ensure that any attempt to replay history\n        // for a different version fails. It can be removed later when there is no possibility\n        // of this happening.\n        Workflow.getVersion("checksumAdded", 1, 1);\n        long checksum = activities.calculateChecksum(processedName);\n        activities.uploadWithChecksum(\n            args.getTargetBucketName(), args.getTargetFilename(), processedName, checksum);\n    } finally {\n        if (localName != null) { // File was downloaded.\n            activities.deleteLocalFile(localName);\n        }\n        if (processedName != null) { // File was processed.\n            activities.deleteLocalFile(processedName);\n        }\n    }\n}\n\n\nThe ID that is passed to the getVersion call identifies the change. Each change is expected to have its own ID. But if a change spawns multiple places in the code and the new code should be either executed in all of them or in none of them, then they have to share the ID.',normalizedContent:'# versioning\nas outlined in the workflow implementation constraints section, code has to be deterministic by taking the same code path when replaying history . any code change that affects the order in which are generated breaks this assumption. the solution that allows updating code of already running is to keep both the old and new code. when replaying, use the code version that the were generated with and when executing a new code path, always take the new code.\n\nuse the workflow.getversion function to return a version of the code that should be executed and then use the returned value to pick a correct branch. let\'s look at an example.\n\npublic void processfile(arguments args) {\n    string localname = null;\n    string processedname = null;\n    try {\n        localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n        processedname = activities.processfile(localname);\n        activities.upload(args.gettargetbucketname(), args.gettargetfilename(), processedname);\n    } finally {\n        if (localname != null) { // file was downloaded.\n            activities.deletelocalfile(localname);\n        }\n        if (processedname != null) { // file was processed.\n            activities.deletelocalfile(processedname);\n        }\n    }\n}\n\n\nnow we decide to calculate the processed file checksum and pass it to upload. the correct way to implement this change is:\n\npublic void processfile(arguments args) {\n    string localname = null;\n    string processedname = null;\n    try {\n        localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n        processedname = activities.processfile(localname);\n        int version = workflow.getversion("checksumadded", workflow.default_version, 1);\n        if (version == workflow.default_version) {\n            activities.upload(args.gettargetbucketname(), args.gettargetfilename(), processedname);\n        } else {\n            long checksum = activities.calculatechecksum(processedname);\n            activities.uploadwithchecksum(\n                args.gettargetbucketname(), args.gettargetfilename(), processedname, checksum);\n        }\n    } finally {\n        if (localname != null) { // file was downloaded.\n            activities.deletelocalfile(localname);\n        }\n        if (processedname != null) { // file was processed.\n            activities.deletelocalfile(processedname);\n        }\n    }\n}\n\n\nlater, when all that use the old version are completed, the old branch can be removed.\n\npublic void processfile(arguments args) {\n    string localname = null;\n    string processedname = null;\n    try {\n        localname = activities.download(args.getsourcebucketname(), args.getsourcefilename());\n        processedname = activities.processfile(localname);\n        // getversion call is left here to ensure that any attempt to replay history\n        // for a different version fails. it can be removed later when there is no possibility\n        // of this happening.\n        workflow.getversion("checksumadded", 1, 1);\n        long checksum = activities.calculatechecksum(processedname);\n        activities.uploadwithchecksum(\n            args.gettargetbucketname(), args.gettargetfilename(), processedname, checksum);\n    } finally {\n        if (localname != null) { // file was downloaded.\n            activities.deletelocalfile(localname);\n        }\n        if (processedname != null) { // file was processed.\n            activities.deletelocalfile(processedname);\n        }\n    }\n}\n\n\nthe id that is passed to the getversion call identifies the change. each change is expected to have its own id. but if a change spawns multiple places in the code and the new code should be either executed in all of them or in none of them, then they have to share the id.',charsets:{}},{title:"Distributed CRON",frontmatter:{layout:"default",title:"Distributed CRON",permalink:"/docs/java-client/distributed-cron",readingShow:"top"},regularPath:"/docs/04-java-client/08-distributed-cron.html",relativePath:"docs/04-java-client/08-distributed-cron.md",key:"v-5951033c",path:"/docs/java-client/distributed-cron/",headers:[{level:2,title:"Convert an existing cron workflow",slug:"convert-an-existing-cron-workflow",normalizedTitle:"convert an existing cron workflow",charIndex:1998},{level:2,title:"Retrieve last successful result",slug:"retrieve-last-successful-result",normalizedTitle:"retrieve last successful result",charIndex:2460}],headersStr:"Convert an existing cron workflow Retrieve last successful result",content:"# Distributed CRON\nIt is relatively straightforward to turn any Cadence into a Cron . All you need is to supply a cron schedule when starting the using the CronSchedule parameter ofStartWorkflowOptions.\n\nYou can also start a using the Cadence with an optional cron schedule using the --cron argument.\n\nFor with CronSchedule:\n\n * CronSchedule is based on UTC time. For example cron schedule \"15 8 * * *\" will run daily at 8:15am UTC.\n * If a failed and a RetryPolicy is supplied to the StartWorkflowOptions as well, the will retry based on the RetryPolicy. While the is retrying, the server will not schedule the next cron run.\n * Cadence server only schedules the next cron run after the current run is completed. If the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * Cron will not stop until they are terminated or cancelled.\n\nCadence supports the standard cron spec:\n\n// CronSchedule - Optional cron schedule for workflow. If a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. The scheduling will be based on UTC time. The schedule for the next run only happens\n// after the current run is completed/failed/timeout. If a RetryPolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. While the workflow is retrying, it won't\n// schedule its next run. If the next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. Cron workflow will not stop until it is terminated or cancelled (by returning cadence.CanceledError).\n// The cron spec is as follows:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\nCronSchedule string\n\n\nThe crontab guru site is useful for testing your cron expressions.\n\n# Convert an existing cron workflow\nBefore CronSchedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then returnContinueAsNew. One problem with that implementation is that if the fails or times out, the cron would stop.\n\nTo convert those to make use of Cadence CronSchedule, all you need is to remove the delay timer and return without usingContinueAsNew. Then start the with the desired CronSchedule.\n\n# Retrieve last successful result\nSometimes it is useful to obtain the progress of previous successful runs. This is supported by two new APIs in the client library:HasLastCompletionResult and GetLastCompletionResult. Below is an example of how to use this in Java:\n\npublic String cronWorkflow() {\n    String lastProcessedFileName = Workflow.getLastCompletionResult(String.class);\n\n    // Process work starting from the lastProcessedFileName.\n    // Business logic implementation goes here.\n    // Updates lastProcessedFileName to the new value.\n\n    return lastProcessedFileName;\n}\n\n\nNote that this works even if one of the cron schedule runs failed. The next schedule will still get the last successful result if it ever successfully completed at least once. For example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day's run using these APIs.",normalizedContent:"# distributed cron\nit is relatively straightforward to turn any cadence into a cron . all you need is to supply a cron schedule when starting the using the cronschedule parameter ofstartworkflowoptions.\n\nyou can also start a using the cadence with an optional cron schedule using the --cron argument.\n\nfor with cronschedule:\n\n * cronschedule is based on utc time. for example cron schedule \"15 8 * * *\" will run daily at 8:15am utc.\n * if a failed and a retrypolicy is supplied to the startworkflowoptions as well, the will retry based on the retrypolicy. while the is retrying, the server will not schedule the next cron run.\n * cadence server only schedules the next cron run after the current run is completed. if the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * cron will not stop until they are terminated or cancelled.\n\ncadence supports the standard cron spec:\n\n// cronschedule - optional cron schedule for workflow. if a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. the scheduling will be based on utc time. the schedule for the next run only happens\n// after the current run is completed/failed/timeout. if a retrypolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. while the workflow is retrying, it won't\n// schedule its next run. if the next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. cron workflow will not stop until it is terminated or cancelled (by returning cadence.cancelederror).\n// the cron spec is as follows:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (sunday to saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\ncronschedule string\n\n\nthe crontab guru site is useful for testing your cron expressions.\n\n# convert an existing cron workflow\nbefore cronschedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then returncontinueasnew. one problem with that implementation is that if the fails or times out, the cron would stop.\n\nto convert those to make use of cadence cronschedule, all you need is to remove the delay timer and return without usingcontinueasnew. then start the with the desired cronschedule.\n\n# retrieve last successful result\nsometimes it is useful to obtain the progress of previous successful runs. this is supported by two new apis in the client library:haslastcompletionresult and getlastcompletionresult. below is an example of how to use this in java:\n\npublic string cronworkflow() {\n    string lastprocessedfilename = workflow.getlastcompletionresult(string.class);\n\n    // process work starting from the lastprocessedfilename.\n    // business logic implementation goes here.\n    // updates lastprocessedfilename to the new value.\n\n    return lastprocessedfilename;\n}\n\n\nnote that this works even if one of the cron schedule runs failed. the next schedule will still get the last successful result if it ever successfully completed at least once. for example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day's run using these apis.",charsets:{}},{title:"Worker service",frontmatter:{layout:"default",title:"Worker service",permalink:"/docs/go-client/workers",readingShow:"top"},regularPath:"/docs/05-go-client/01-workers.html",relativePath:"docs/05-go-client/01-workers.md",key:"v-e9a63714",path:"/docs/go-client/workers/",headersStr:null,content:'# Worker service\nA or service is a service that hosts the and implementations. The polls the Cadence service for , performs those , and communicates execution results back to the Cadence service. services are developed, deployed, and operated by Cadence customers.\n\nYou can run a Cadence in a new or an existing service. Use the framework APIs to start the Cadence and link in all and implementations that you require the service to execute.\n\npackage main\n\nimport (\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/worker"\n\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/api/transport"\n    "go.uber.org/yarpc/transport/tchannel"\n)\n\nvar HostPort = "127.0.0.1:7933"\nvar Domain = "SimpleDomain"\nvar TaskListName = "SimpleWorker"\nvar ClientName = "SimpleWorker"\nvar CadenceService = "cadence-frontend"\n\nfunc main() {\n    startWorker(buildLogger(), buildCadenceClient())\n}\n\nfunc buildLogger() *zap.Logger {\n    config := zap.NewDevelopmentConfig()\n    config.Level.SetLevel(zapcore.InfoLevel)\n\n    var err error\n    logger, err := config.Build()\n    if err != nil {\n        panic("Failed to setup logger")\n    }\n\n    return logger\n}\n\nfunc buildCadenceClient() workflowserviceclient.Interface {\n    ch, err := tchannel.NewChannelTransport(tchannel.ServiceName(ClientName))\n    if err != nil {\n        panic("Failed to setup tchannel")\n    }\n    dispatcher := yarpc.NewDispatcher(yarpc.Config{\n        Name: ClientName,\n        Outbounds: yarpc.Outbounds{\n            CadenceService: {Unary: ch.NewSingleOutbound(HostPort)},\n        },\n    })\n    if err := dispatcher.Start(); err != nil {\n        panic("Failed to start dispatcher")\n    }\n\n    return workflowserviceclient.New(dispatcher.ClientConfig(CadenceService))\n}\n\nfunc startWorker(logger *zap.Logger, service workflowserviceclient.Interface) {\n    // TaskListName identifies set of client workflows, activities, and workers.\n    // It could be your group or client or application name.\n    workerOptions := worker.Options{\n        Logger:       logger,\n        MetricsScope: tally.NewTestScope(TaskListName, map[string]string{}),\n    }\n\n    worker := worker.New(\n        service,\n        Domain,\n        TaskListName,\n        workerOptions)\n    err := worker.Start()\n    if err != nil {\n        panic("Failed to start worker")\n    }\n\n    logger.Info("Started Worker.", zap.String("worker", TaskListName))\n}',normalizedContent:'# worker service\na or service is a service that hosts the and implementations. the polls the cadence service for , performs those , and communicates execution results back to the cadence service. services are developed, deployed, and operated by cadence customers.\n\nyou can run a cadence in a new or an existing service. use the framework apis to start the cadence and link in all and implementations that you require the service to execute.\n\npackage main\n\nimport (\n\n    "go.uber.org/cadence/.gen/go/cadence"\n    "go.uber.org/cadence/.gen/go/cadence/workflowserviceclient"\n    "go.uber.org/cadence/worker"\n\n    "github.com/uber-go/tally"\n    "go.uber.org/zap"\n    "go.uber.org/zap/zapcore"\n    "go.uber.org/yarpc"\n    "go.uber.org/yarpc/api/transport"\n    "go.uber.org/yarpc/transport/tchannel"\n)\n\nvar hostport = "127.0.0.1:7933"\nvar domain = "simpledomain"\nvar tasklistname = "simpleworker"\nvar clientname = "simpleworker"\nvar cadenceservice = "cadence-frontend"\n\nfunc main() {\n    startworker(buildlogger(), buildcadenceclient())\n}\n\nfunc buildlogger() *zap.logger {\n    config := zap.newdevelopmentconfig()\n    config.level.setlevel(zapcore.infolevel)\n\n    var err error\n    logger, err := config.build()\n    if err != nil {\n        panic("failed to setup logger")\n    }\n\n    return logger\n}\n\nfunc buildcadenceclient() workflowserviceclient.interface {\n    ch, err := tchannel.newchanneltransport(tchannel.servicename(clientname))\n    if err != nil {\n        panic("failed to setup tchannel")\n    }\n    dispatcher := yarpc.newdispatcher(yarpc.config{\n        name: clientname,\n        outbounds: yarpc.outbounds{\n            cadenceservice: {unary: ch.newsingleoutbound(hostport)},\n        },\n    })\n    if err := dispatcher.start(); err != nil {\n        panic("failed to start dispatcher")\n    }\n\n    return workflowserviceclient.new(dispatcher.clientconfig(cadenceservice))\n}\n\nfunc startworker(logger *zap.logger, service workflowserviceclient.interface) {\n    // tasklistname identifies set of client workflows, activities, and workers.\n    // it could be your group or client or application name.\n    workeroptions := worker.options{\n        logger:       logger,\n        metricsscope: tally.newtestscope(tasklistname, map[string]string{}),\n    }\n\n    worker := worker.new(\n        service,\n        domain,\n        tasklistname,\n        workeroptions)\n    err := worker.start()\n    if err != nil {\n        panic("failed to start worker")\n    }\n\n    logger.info("started worker.", zap.string("worker", tasklistname))\n}',charsets:{}},{title:"Creating workflows",frontmatter:{layout:"default",title:"Creating workflows",permalink:"/docs/go-client/create-workflows",readingShow:"top"},regularPath:"/docs/05-go-client/02-create-workflows.html",relativePath:"docs/05-go-client/02-create-workflows.md",key:"v-d91dcabc",path:"/docs/go-client/create-workflows/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:965},{level:2,title:"Declaration",slug:"declaration",normalizedTitle:"declaration",charIndex:1986},{level:2,title:"Implementation",slug:"implementation",normalizedTitle:"implementation",charIndex:932},{level:3,title:"Special Cadence client library functions and types",slug:"special-cadence-client-library-functions-and-types",normalizedTitle:"special cadence client library functions and types",charIndex:4731},{level:3,title:"Failing a workflow",slug:"failing-a-workflow",normalizedTitle:"failing a workflow",charIndex:5520},{level:2,title:"Registration",slug:"registration",normalizedTitle:"registration",charIndex:5653}],headersStr:"Overview Declaration Implementation Special Cadence client library functions and types Failing a workflow Registration",content:'# Creating workflows\nThe is the implementation of the coordination logic. The Cadence programming framework (aka client library) allows you to write the coordination logic as simple procedural code that uses standard Go data modeling. The client library takes care of the communication between the service and the Cadence service, and ensures state persistence between even in case of failures. Furthermore, any particular execution is not tied to a particular machine. Different steps of the coordination logic can end up executing on different instances, with the framework ensuring that the necessary state is recreated on the executing the step.\n\nHowever, in order to facilitate this operational model, both the Cadence programming framework and the managed service impose some requirements and restrictions on the implementation of the coordination logic. The details of these requirements and restrictions are described in theImplementation section below.\n\n# Overview\nThe sample code below shows a simple implementation of a that executes one . The also passes the sole parameter it receives as part of its initialization as a parameter to the .\n\npackage sample\n\nimport (\n    "time"\n\n    "go.uber.org/cadence/workflow"\n)\n\nfunc init() {\n    workflow.Register(SimpleWorkflow)\n}\n\nfunc SimpleWorkflow(ctx workflow.Context, value string) error {\n    ao := workflow.ActivityOptions{\n        TaskList:               "sampleTaskList",\n        ScheduleToCloseTimeout: time.Second * 60,\n        ScheduleToStartTimeout: time.Second * 60,\n        StartToCloseTimeout:    time.Second * 60,\n        HeartbeatTimeout:       time.Second * 10,\n        WaitForCancellation:    false,\n    }\n    ctx = workflow.WithActivityOptions(ctx, ao)\n\n    future := workflow.ExecuteActivity(ctx, SimpleActivity, value)\n    var result string\n    if err := future.Get(ctx, &result); err != nil {\n        return err\n    }\n    workflow.GetLogger(ctx).Info("Done", zap.String("result", result))\n    return nil\n}\n\n\n# Declaration\nIn the Cadence programing model, a is implemented with a function. The function declaration specifies the parameters the accepts as well as any values it might return.\n\nfunc SimpleWorkflow(ctx workflow.Context, value string) error\n\n\nLet’s deconstruct the declaration above:\n\n * The first parameter to the function is ctx workflow.Context. This is a required parameter for all functions and is used by the Cadence client library to pass execution context. Virtually all the client library functions that are callable from the functions require this ctx parameter. This context parameter is the same concept as the standardcontext.Context provided by Go. The only difference between workflow.Context andcontext.Context is that the Done() function in workflow.Context returnsworkflow.Channel instead the standard go chan.\n * The second parameter, string, is a custom parameter that can be used to pass data into the on start. A can have one or more such parameters. All parameters to a function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers.\n * Since it only declares error as the return value, this means that the does not return a value. The error return value is used to indicate an error was encountered during execution and the should be terminated.\n\n# Implementation\nIn order to support the synchronous and sequential programming model for the implementation, there are certain restrictions and requirements on how the implementation must behave in order to guarantee correctness. The requirements are that:\n\n * Execution must be deterministic\n * Execution must be idempotent\n\nA straightforward way to think about these requirements is that the code is as follows:\n\n *  code can only read and manipulate local state or state received as return values from Cadence client library functions.\n *  code should not affect changes in external systems other than through invocation of .\n *  code should interact with time only through the functions provided by the Cadence client library (i.e. workflow.Now(), workflow.Sleep()).\n *  code should not create and interact with goroutines directly, it should instead use the functions provided by the Cadence client library (i.e., workflow.Go() instead of go,workflow.Channel instead of chan, workflow.Selector instead of select).\n *  code should do all logging via the logger provided by the Cadence client library (i.e., workflow.GetLogger()).\n *  code should not iterate over maps using range because the order of map iteration is randomized.\n\nNow that we have laid the ground rules, we can take a look at some of the special functions and types used for writing Cadence and how to implement some common patterns.\n\n# Special Cadence client library functions and types\nThe Cadence client library provides a number of functions and types as alternatives to some native Go functions and types. Usage of these replacement functions/types is necessary in order to ensure that the code execution is deterministic and repeatable within an execution context.\n\nCoroutine related constructs:\n\n * workflow.Go : This is a replacement for the the go statement.\n * workflow.Channel : This is a replacement for the native chan type. Cadence provides support for both buffered and unbuffered channels.\n * workflow.Selector : This is a replacement for the select statement.\n\nTime related functions:\n\n * workflow.Now() : This is a replacement for time.Now().\n * workflow.Sleep() : This is a replacement for time.Sleep().\n\n# Failing a workflow\nTo mark a as failed, all that needs to happen is for the function to return an error via the err return value.\n\n# Registration\nFor some client code to be able to invoke a type, the process needs to be aware of all the implementations it has access to. A is registered with the following call:\n\nworkflow.Register(SimpleWorkflow)\n\n\nThis call essentially creates an in-memory mapping inside the process between the fully qualified function name and the implementation. It is safe to call this registration method from an init() function. If the receives for a type it does not know, it will fail that . However, the failure of the will not cause the entire to fail.',normalizedContent:'# creating workflows\nthe is the implementation of the coordination logic. the cadence programming framework (aka client library) allows you to write the coordination logic as simple procedural code that uses standard go data modeling. the client library takes care of the communication between the service and the cadence service, and ensures state persistence between even in case of failures. furthermore, any particular execution is not tied to a particular machine. different steps of the coordination logic can end up executing on different instances, with the framework ensuring that the necessary state is recreated on the executing the step.\n\nhowever, in order to facilitate this operational model, both the cadence programming framework and the managed service impose some requirements and restrictions on the implementation of the coordination logic. the details of these requirements and restrictions are described in theimplementation section below.\n\n# overview\nthe sample code below shows a simple implementation of a that executes one . the also passes the sole parameter it receives as part of its initialization as a parameter to the .\n\npackage sample\n\nimport (\n    "time"\n\n    "go.uber.org/cadence/workflow"\n)\n\nfunc init() {\n    workflow.register(simpleworkflow)\n}\n\nfunc simpleworkflow(ctx workflow.context, value string) error {\n    ao := workflow.activityoptions{\n        tasklist:               "sampletasklist",\n        scheduletoclosetimeout: time.second * 60,\n        scheduletostarttimeout: time.second * 60,\n        starttoclosetimeout:    time.second * 60,\n        heartbeattimeout:       time.second * 10,\n        waitforcancellation:    false,\n    }\n    ctx = workflow.withactivityoptions(ctx, ao)\n\n    future := workflow.executeactivity(ctx, simpleactivity, value)\n    var result string\n    if err := future.get(ctx, &result); err != nil {\n        return err\n    }\n    workflow.getlogger(ctx).info("done", zap.string("result", result))\n    return nil\n}\n\n\n# declaration\nin the cadence programing model, a is implemented with a function. the function declaration specifies the parameters the accepts as well as any values it might return.\n\nfunc simpleworkflow(ctx workflow.context, value string) error\n\n\nlet’s deconstruct the declaration above:\n\n * the first parameter to the function is ctx workflow.context. this is a required parameter for all functions and is used by the cadence client library to pass execution context. virtually all the client library functions that are callable from the functions require this ctx parameter. this context parameter is the same concept as the standardcontext.context provided by go. the only difference between workflow.context andcontext.context is that the done() function in workflow.context returnsworkflow.channel instead the standard go chan.\n * the second parameter, string, is a custom parameter that can be used to pass data into the on start. a can have one or more such parameters. all parameters to a function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers.\n * since it only declares error as the return value, this means that the does not return a value. the error return value is used to indicate an error was encountered during execution and the should be terminated.\n\n# implementation\nin order to support the synchronous and sequential programming model for the implementation, there are certain restrictions and requirements on how the implementation must behave in order to guarantee correctness. the requirements are that:\n\n * execution must be deterministic\n * execution must be idempotent\n\na straightforward way to think about these requirements is that the code is as follows:\n\n *  code can only read and manipulate local state or state received as return values from cadence client library functions.\n *  code should not affect changes in external systems other than through invocation of .\n *  code should interact with time only through the functions provided by the cadence client library (i.e. workflow.now(), workflow.sleep()).\n *  code should not create and interact with goroutines directly, it should instead use the functions provided by the cadence client library (i.e., workflow.go() instead of go,workflow.channel instead of chan, workflow.selector instead of select).\n *  code should do all logging via the logger provided by the cadence client library (i.e., workflow.getlogger()).\n *  code should not iterate over maps using range because the order of map iteration is randomized.\n\nnow that we have laid the ground rules, we can take a look at some of the special functions and types used for writing cadence and how to implement some common patterns.\n\n# special cadence client library functions and types\nthe cadence client library provides a number of functions and types as alternatives to some native go functions and types. usage of these replacement functions/types is necessary in order to ensure that the code execution is deterministic and repeatable within an execution context.\n\ncoroutine related constructs:\n\n * workflow.go : this is a replacement for the the go statement.\n * workflow.channel : this is a replacement for the native chan type. cadence provides support for both buffered and unbuffered channels.\n * workflow.selector : this is a replacement for the select statement.\n\ntime related functions:\n\n * workflow.now() : this is a replacement for time.now().\n * workflow.sleep() : this is a replacement for time.sleep().\n\n# failing a workflow\nto mark a as failed, all that needs to happen is for the function to return an error via the err return value.\n\n# registration\nfor some client code to be able to invoke a type, the process needs to be aware of all the implementations it has access to. a is registered with the following call:\n\nworkflow.register(simpleworkflow)\n\n\nthis call essentially creates an in-memory mapping inside the process between the fully qualified function name and the implementation. it is safe to call this registration method from an init() function. if the receives for a type it does not know, it will fail that . however, the failure of the will not cause the entire to fail.',charsets:{}},{title:"Activity overview",frontmatter:{layout:"default",title:"Activity overview",permalink:"/docs/go-client/activities",readingShow:"top"},regularPath:"/docs/05-go-client/03-activities.html",relativePath:"docs/05-go-client/03-activities.md",key:"v-241aa182",path:"/docs/go-client/activities/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:1159},{level:3,title:"Declaration",slug:"declaration",normalizedTitle:"declaration",charIndex:1846},{level:3,title:"Implementation",slug:"implementation",normalizedTitle:"implementation",charIndex:2970},{level:3,title:"Registration",slug:"registration",normalizedTitle:"registration",charIndex:4506},{level:2,title:"Failing an Activity",slug:"failing-an-activity",normalizedTitle:"failing an activity",charIndex:4909}],headersStr:"Overview Declaration Implementation Registration Failing an Activity",content:'# Activity overview\nAn is the implementation of a particular in the business logic.\n\n are implemented as functions. Data can be passed directly to an via function parameters. The parameters can be either basic types or structs, with the only requirement being that the parameters must be serializable. Though it is not required, we recommend that the first parameter of an function is of type context.Context, in order to allow the to interact with other framework methods. The function must return an error value, and can optionally return a result value. The result value can be either a basic type or a struct with the only requirement being that it is serializable.\n\nThe values passed to through invocation parameters or returned through the result value are recorded in the execution history. The entire execution history is transferred from the Cadence service to with every that the logic needs to process. A large execution history can thus adversely impact the performance of your . Therefore, be mindful of the amount of data you transfer via invocation parameters or return values. Otherwise, no additional limitations exist on implementations.\n\n# Overview\nThe following example demonstrates a simple that accepts a string parameter, appends a word to it, and then returns a result.\n\npackage simple\n\nimport (\n    "context"\n\n    "go.uber.org/cadence/activity"\n    "go.uber.org/zap"\n)\n\nfunc init() {\n    activity.Register(SimpleActivity)\n}\n\n// SimpleActivity is a sample Cadence activity function that takes one parameter and\n// returns a string containing the parameter value.\nfunc SimpleActivity(ctx context.Context, value string) (string, error) {\n    activity.GetLogger(ctx).Info("SimpleActivity called.", zap.String("Value", value))\n    return "Processed: " + value, nil\n}\n\n\nLet\'s take a look at each component of this activity.\n\n# Declaration\nIn the Cadence programing model, an is implemented with a function. The function declaration specifies the parameters the accepts as well as any values it might return. An function can take zero or many specific parameters and can return one or two values. It must always at least return an error value. The function can accept as parameters and return as results any serializable type.\n\nfunc SimpleActivity(ctx context.Context, value string) (string, error)\n\nThe first parameter to the function is context.Context. This is an optional parameter and can be omitted. This parameter is the standard Go context. The second string parameter is a custom specific parameter that can be used to pass data into the on start. An can have one or more such parameters. All parameters to an function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers. The declares two return values: string and error. The string return value is used to return the result of the . The error return value is used to indicate that an error was encountered during execution.\n\n# Implementation\nYou can write implementation code in the same way that you would any other Go service code. Additionally, you can use the usual loggers and metrics controllers, and the standard Go concurrency constructs.\n\n# Heart Beating\nFor long-running , Cadence provides an API for the code to report both liveness and progress back to the Cadence managed service.\n\nprogress := 0\nfor hasWork {\n    // Send heartbeat message to the server.\n    cadence.RecordActivityHeartbeat(ctx, progress)\n    // Do some work.\n    ...\n    progress++\n}\n\n\nWhen an times out due to a missed heartbeat, the last value of the details (progress in the above sample) is returned from the cadence.ExecuteActivity function as the details field of TimeoutErrorwith TimeoutType_HEARTBEAT.\n\nYou can also heartbeat an from an external source:\n\n// Instantiate a Cadence service client.\ncadence.Client client = cadence.NewClient(...)\n\n// Record heartbeat.\nerr := client.RecordActivityHeartbeat(taskToken, details)\n\n\nThe parameters of the RecordActivityHeartbeat function are:\n\n * taskToken: The value of the binary TaskToken field of the ActivityInfo struct retrieved inside the .\n * details: The serializable payload containing progress information.\n\n# Cancellation\nWhen an is cancelled, or its has completed or failed, the context passed into its function is cancelled, which sets its channel’s closed state to Done. An can use that to perform any necessary cleanup and abort its execution. Cancellation is only delivered to that call RecordActivityHeartbeat.\n\n# Registration\nTo make the visible to the process hosting it, the must be registered via a call to activity.Register.\n\nfunc init() {\n    activity.Register(SimpleActivity)\n}\n\n\nThis call creates an in-memory mapping inside the process between the fully qualified function name and the implementation. If a receives a request to start an execution for an type it does not know, it will fail that request.\n\n# Failing an Activity\nTo mark an as failed, the function must return an error via the error return value.',normalizedContent:'# activity overview\nan is the implementation of a particular in the business logic.\n\n are implemented as functions. data can be passed directly to an via function parameters. the parameters can be either basic types or structs, with the only requirement being that the parameters must be serializable. though it is not required, we recommend that the first parameter of an function is of type context.context, in order to allow the to interact with other framework methods. the function must return an error value, and can optionally return a result value. the result value can be either a basic type or a struct with the only requirement being that it is serializable.\n\nthe values passed to through invocation parameters or returned through the result value are recorded in the execution history. the entire execution history is transferred from the cadence service to with every that the logic needs to process. a large execution history can thus adversely impact the performance of your . therefore, be mindful of the amount of data you transfer via invocation parameters or return values. otherwise, no additional limitations exist on implementations.\n\n# overview\nthe following example demonstrates a simple that accepts a string parameter, appends a word to it, and then returns a result.\n\npackage simple\n\nimport (\n    "context"\n\n    "go.uber.org/cadence/activity"\n    "go.uber.org/zap"\n)\n\nfunc init() {\n    activity.register(simpleactivity)\n}\n\n// simpleactivity is a sample cadence activity function that takes one parameter and\n// returns a string containing the parameter value.\nfunc simpleactivity(ctx context.context, value string) (string, error) {\n    activity.getlogger(ctx).info("simpleactivity called.", zap.string("value", value))\n    return "processed: " + value, nil\n}\n\n\nlet\'s take a look at each component of this activity.\n\n# declaration\nin the cadence programing model, an is implemented with a function. the function declaration specifies the parameters the accepts as well as any values it might return. an function can take zero or many specific parameters and can return one or two values. it must always at least return an error value. the function can accept as parameters and return as results any serializable type.\n\nfunc simpleactivity(ctx context.context, value string) (string, error)\n\nthe first parameter to the function is context.context. this is an optional parameter and can be omitted. this parameter is the standard go context. the second string parameter is a custom specific parameter that can be used to pass data into the on start. an can have one or more such parameters. all parameters to an function must be serializable, which essentially means that params can’t be channels, functions, variadic, or unsafe pointers. the declares two return values: string and error. the string return value is used to return the result of the . the error return value is used to indicate that an error was encountered during execution.\n\n# implementation\nyou can write implementation code in the same way that you would any other go service code. additionally, you can use the usual loggers and metrics controllers, and the standard go concurrency constructs.\n\n# heart beating\nfor long-running , cadence provides an api for the code to report both liveness and progress back to the cadence managed service.\n\nprogress := 0\nfor haswork {\n    // send heartbeat message to the server.\n    cadence.recordactivityheartbeat(ctx, progress)\n    // do some work.\n    ...\n    progress++\n}\n\n\nwhen an times out due to a missed heartbeat, the last value of the details (progress in the above sample) is returned from the cadence.executeactivity function as the details field of timeouterrorwith timeouttype_heartbeat.\n\nyou can also heartbeat an from an external source:\n\n// instantiate a cadence service client.\ncadence.client client = cadence.newclient(...)\n\n// record heartbeat.\nerr := client.recordactivityheartbeat(tasktoken, details)\n\n\nthe parameters of the recordactivityheartbeat function are:\n\n * tasktoken: the value of the binary tasktoken field of the activityinfo struct retrieved inside the .\n * details: the serializable payload containing progress information.\n\n# cancellation\nwhen an is cancelled, or its has completed or failed, the context passed into its function is cancelled, which sets its channel’s closed state to done. an can use that to perform any necessary cleanup and abort its execution. cancellation is only delivered to that call recordactivityheartbeat.\n\n# registration\nto make the visible to the process hosting it, the must be registered via a call to activity.register.\n\nfunc init() {\n    activity.register(simpleactivity)\n}\n\n\nthis call creates an in-memory mapping inside the process between the fully qualified function name and the implementation. if a receives a request to start an execution for an type it does not know, it will fail that request.\n\n# failing an activity\nto mark an as failed, the function must return an error via the error return value.',charsets:{}},{title:"Executing activities",frontmatter:{layout:"default",title:"Executing activities",permalink:"/docs/go-client/execute-activity",readingShow:"top"},regularPath:"/docs/05-go-client/04-execute-activity.html",relativePath:"docs/05-go-client/04-execute-activity.md",key:"v-7109c462",path:"/docs/go-client/execute-activity/",headers:[{level:2,title:"Activity options",slug:"activity-options",normalizedTitle:"activity options",charIndex:794},{level:2,title:"Activity timeouts",slug:"activity-timeouts",normalizedTitle:"activity timeouts",charIndex:1278},{level:2,title:"ExecuteActivity call",slug:"executeactivity-call",normalizedTitle:"executeactivity call",charIndex:2478}],headersStr:"Activity options Activity timeouts ExecuteActivity call",content:'# Executing activities\nThe primary responsibility of a implementation is to schedule for execution. The most straightforward way to do this is via the library method workflow.ExecuteActivity. The following sample code demonstrates making this call:\n\nao := cadence.ActivityOptions{\n    TaskList:               "sampleTaskList",\n    ScheduleToCloseTimeout: time.Second * 60,\n    ScheduleToStartTimeout: time.Second * 60,\n    StartToCloseTimeout:    time.Second * 60,\n    HeartbeatTimeout:       time.Second * 10,\n    WaitForCancellation:    false,\n}\nctx = cadence.WithActivityOptions(ctx, ao)\n\nfuture := workflow.ExecuteActivity(ctx, SimpleActivity, value)\nvar result string\nif err := future.Get(ctx, &result); err != nil {\n    return err\n}\n\n\nLet\'s take a look at each component of this call.\n\n# Activity options\nBefore calling workflow.ExecuteActivity(), you must configure ActivityOptions for the invocation. These options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. The child context is then passed into the workflow.ExecuteActivity() call. If multiple are sharing the same option values, then the same context instance can be used when calling workflow.ExecuteActivity().\n\n# Activity timeouts\nThere can be various kinds of timeouts associated with an . Cadence guarantees that are executed at most once, so an either succeeds or fails with one of the following timeouts:\n\nTimeout                  Description                                                                                                                                                                   \nStartToCloseTimeout      Maximum time that a worker can take to process a task after it has received the task.                                                                                         \nScheduleToStartTimeout   Time a task can wait to be picked up by an after a schedules it. If there are no workers available to process this task for the specified duration, the task will time out.   \nScheduleToCloseTimeout   Time a task can take to complete after it is scheduled by a . This is usually greater than the sum of StartToClose and ScheduleToStart timeouts.                              \nHeartbeatTimeout         If a task doesn\'t heartbeat to the Cadence service for this duration, it will be considered to have failed. This is useful for long-running tasks.                            \n\n# ExecuteActivity call\nThe first parameter in the call is the required cadence.Context object. This type is a copy ofcontext.Context with the Done() method returning cadence.Channel instead of the native Go chan.\n\nThe second parameter is the function that we registered as an function. This parameter can also be a string representing the fully qualified name of the function. The benefit of passing in the actual function object is that the framework can validate parameters.\n\nThe remaining parameters are passed to the as part of the call. In our example, we have a single parameter: value. This list of parameters must match the list of parameters declared by the function. The Cadence client library will validate this.\n\nThe method call returns immediately and returns a cadence.Future. This allows you to execute more code without having to wait for the scheduled to complete.\n\nWhen you are ready to process the results of the , call the Get() method on the future object returned. The parameters to this method are the ctx object we passed to theworkflow.ExecuteActivity() call and an output parameter that will receive the output of the. The type of the output parameter must match the type of the return value declared by the function. The Get() method will block until the completes and results are available.\n\nYou can retrieve the result value returned by workflow.ExecuteActivity() from the future and use it like any normal result from a synchronous function call. The following sample code demonstrates how you can use the result if it is a string value:\n\nvar result string\nif err := future.Get(ctx1, &result); err != nil {\n    return err\n}\n\nswitch result {\ncase "apple":\n    // Do something.\ncase "banana":\n    // Do something.\ndefault:\n    return err\n}\n\n\nIn this example, we called the Get() method on the returned future immediately after workflow.ExecuteActivity(). However, this is not necessary. If you want to execute multiple in parallel, you can repeatedly call workflow.ExecuteActivity(), store the returned futures, and then wait for all to complete by calling the Get() methods of the future at a later time.\n\nTo implement more complex wait conditions on returned future objects, use the cadence.Selector class.',normalizedContent:'# executing activities\nthe primary responsibility of a implementation is to schedule for execution. the most straightforward way to do this is via the library method workflow.executeactivity. the following sample code demonstrates making this call:\n\nao := cadence.activityoptions{\n    tasklist:               "sampletasklist",\n    scheduletoclosetimeout: time.second * 60,\n    scheduletostarttimeout: time.second * 60,\n    starttoclosetimeout:    time.second * 60,\n    heartbeattimeout:       time.second * 10,\n    waitforcancellation:    false,\n}\nctx = cadence.withactivityoptions(ctx, ao)\n\nfuture := workflow.executeactivity(ctx, simpleactivity, value)\nvar result string\nif err := future.get(ctx, &result); err != nil {\n    return err\n}\n\n\nlet\'s take a look at each component of this call.\n\n# activity options\nbefore calling workflow.executeactivity(), you must configure activityoptions for the invocation. these options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. the child context is then passed into the workflow.executeactivity() call. if multiple are sharing the same option values, then the same context instance can be used when calling workflow.executeactivity().\n\n# activity timeouts\nthere can be various kinds of timeouts associated with an . cadence guarantees that are executed at most once, so an either succeeds or fails with one of the following timeouts:\n\ntimeout                  description                                                                                                                                                                   \nstarttoclosetimeout      maximum time that a worker can take to process a task after it has received the task.                                                                                         \nscheduletostarttimeout   time a task can wait to be picked up by an after a schedules it. if there are no workers available to process this task for the specified duration, the task will time out.   \nscheduletoclosetimeout   time a task can take to complete after it is scheduled by a . this is usually greater than the sum of starttoclose and scheduletostart timeouts.                              \nheartbeattimeout         if a task doesn\'t heartbeat to the cadence service for this duration, it will be considered to have failed. this is useful for long-running tasks.                            \n\n# executeactivity call\nthe first parameter in the call is the required cadence.context object. this type is a copy ofcontext.context with the done() method returning cadence.channel instead of the native go chan.\n\nthe second parameter is the function that we registered as an function. this parameter can also be a string representing the fully qualified name of the function. the benefit of passing in the actual function object is that the framework can validate parameters.\n\nthe remaining parameters are passed to the as part of the call. in our example, we have a single parameter: value. this list of parameters must match the list of parameters declared by the function. the cadence client library will validate this.\n\nthe method call returns immediately and returns a cadence.future. this allows you to execute more code without having to wait for the scheduled to complete.\n\nwhen you are ready to process the results of the , call the get() method on the future object returned. the parameters to this method are the ctx object we passed to theworkflow.executeactivity() call and an output parameter that will receive the output of the. the type of the output parameter must match the type of the return value declared by the function. the get() method will block until the completes and results are available.\n\nyou can retrieve the result value returned by workflow.executeactivity() from the future and use it like any normal result from a synchronous function call. the following sample code demonstrates how you can use the result if it is a string value:\n\nvar result string\nif err := future.get(ctx1, &result); err != nil {\n    return err\n}\n\nswitch result {\ncase "apple":\n    // do something.\ncase "banana":\n    // do something.\ndefault:\n    return err\n}\n\n\nin this example, we called the get() method on the returned future immediately after workflow.executeactivity(). however, this is not necessary. if you want to execute multiple in parallel, you can repeatedly call workflow.executeactivity(), store the returned futures, and then wait for all to complete by calling the get() methods of the future at a later time.\n\nto implement more complex wait conditions on returned future objects, use the cadence.selector class.',charsets:{}},{title:"Child workflows",frontmatter:{layout:"default",title:"Child workflows",permalink:"/docs/go-client/child-workflows",readingShow:"top"},regularPath:"/docs/05-go-client/05-child-workflows.html",relativePath:"docs/05-go-client/05-child-workflows.md",key:"v-30ee6212",path:"/docs/go-client/child-workflows/",headersStr:null,content:'# Child workflows\nworkflow.ExecuteChildWorkflow enables the scheduling of other from within a \'s implementation. The parent has the ability to monitor and impact the lifecycle of the child, similar to the way it does for an that it invoked.\n\ncwo := workflow.ChildWorkflowOptions{\n    // Do not specify WorkflowID if you want Cadence to generate a unique ID for the child execution.\n    WorkflowID:                   "BID-SIMPLE-CHILD-WORKFLOW",\n    ExecutionStartToCloseTimeout: time.Minute * 30,\n}\nctx = workflow.WithChildWorkflowOptions(ctx, cwo)\n\nvar result string\nfuture := workflow.ExecuteChildWorkflow(ctx, SimpleChildWorkflow, value)\nif err := future.Get(ctx, &result); err != nil {\n    workflow.GetLogger(ctx).Error("SimpleChildWorkflow failed.", zap.Error(err))\n    return err\n}\n\n\nLet\'s take a look at each component of this call.\n\nBefore calling workflow.ExecuteChildworkflow(), you must configure ChildWorkflowOptions for the invocation. These options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. The child context is then passed into the workflow.ExecuteChildWorkflow() call. If multiple are sharing the same option values, then the same context instance can be used when calling workflow.ExecuteChildworkflow().\n\nThe first parameter in the call is the required cadence.Context object. This type is a copy ofcontext.Context with the Done() method returning cadence.Channel instead of the native Go chan.\n\nThe second parameter is the function that we registered as a function. This parameter can also be a string representing the fully qualified name of the function. The benefit of this is that when you pass in the actual function object, the framework can validate parameters.\n\nThe remaining parameters are passed to the as part of the call. In our example, we have a single parameter: value. This list of parameters must match the list of parameters declared by the function.\n\nThe method call returns immediately and returns a cadence.Future. This allows you to execute more code without having to wait for the scheduled to complete.\n\nWhen you are ready to process the results of the , call the Get() method on the returned future object. The parameters to this method is the ctx object we passed to theworkflow.ExecuteChildWorkflow() call and an output parameter that will receive the output of the. The type of the output parameter must match the type of the return value declared by the function. The Get() method will block until the completes and results are available.\n\nThe workflow.ExecuteChildWorkflow() function is similar to workflow.ExecuteActivity(). All of the patterns described for using workflow.ExecuteActivity() apply to the workflow.ExecuteChildWorkflow()function as well.\n\nWhen a parent is cancelled by the user, the child can be cancelled or abandoned based on a configurable child policy.',normalizedContent:'# child workflows\nworkflow.executechildworkflow enables the scheduling of other from within a \'s implementation. the parent has the ability to monitor and impact the lifecycle of the child, similar to the way it does for an that it invoked.\n\ncwo := workflow.childworkflowoptions{\n    // do not specify workflowid if you want cadence to generate a unique id for the child execution.\n    workflowid:                   "bid-simple-child-workflow",\n    executionstarttoclosetimeout: time.minute * 30,\n}\nctx = workflow.withchildworkflowoptions(ctx, cwo)\n\nvar result string\nfuture := workflow.executechildworkflow(ctx, simplechildworkflow, value)\nif err := future.get(ctx, &result); err != nil {\n    workflow.getlogger(ctx).error("simplechildworkflow failed.", zap.error(err))\n    return err\n}\n\n\nlet\'s take a look at each component of this call.\n\nbefore calling workflow.executechildworkflow(), you must configure childworkflowoptions for the invocation. these options customize various execution timeouts, and are passed in by creating a child context from the initial context and overwriting the desired values. the child context is then passed into the workflow.executechildworkflow() call. if multiple are sharing the same option values, then the same context instance can be used when calling workflow.executechildworkflow().\n\nthe first parameter in the call is the required cadence.context object. this type is a copy ofcontext.context with the done() method returning cadence.channel instead of the native go chan.\n\nthe second parameter is the function that we registered as a function. this parameter can also be a string representing the fully qualified name of the function. the benefit of this is that when you pass in the actual function object, the framework can validate parameters.\n\nthe remaining parameters are passed to the as part of the call. in our example, we have a single parameter: value. this list of parameters must match the list of parameters declared by the function.\n\nthe method call returns immediately and returns a cadence.future. this allows you to execute more code without having to wait for the scheduled to complete.\n\nwhen you are ready to process the results of the , call the get() method on the returned future object. the parameters to this method is the ctx object we passed to theworkflow.executechildworkflow() call and an output parameter that will receive the output of the. the type of the output parameter must match the type of the return value declared by the function. the get() method will block until the completes and results are available.\n\nthe workflow.executechildworkflow() function is similar to workflow.executeactivity(). all of the patterns described for using workflow.executeactivity() apply to the workflow.executechildworkflow()function as well.\n\nwhen a parent is cancelled by the user, the child can be cancelled or abandoned based on a configurable child policy.',charsets:{}},{title:"Activity and workflow retries",frontmatter:{layout:"default",title:"Activity and workflow retries",permalink:"/docs/go-client/retries",readingShow:"top"},regularPath:"/docs/05-go-client/06-retries.html",relativePath:"docs/05-go-client/06-retries.md",key:"v-63bf2e6c",path:"/docs/go-client/retries/",headersStr:null,content:"# Activity and workflow retries\n and can fail due to various intermediate conditions. In those cases, we want to retry the failed or child or even the parent . This can be achieved by supplying an optional retry policy. A retry policy looks like the following:\n\n// RetryPolicy defines the retry policy.\nRetryPolicy struct {\n    // Backoff interval for the first retry. If coefficient is 1.0 then it is used for all retries.\n    // Required, no default value.\n    InitialInterval time.Duration\n\n    // Coefficient used to calculate the next retry backoff interval.\n    // The next retry interval is previous interval multiplied by this coefficient.\n    // Must be 1 or larger. Default is 2.0.\n    BackoffCoefficient float64\n\n    // Maximum backoff interval between retries. Exponential backoff leads to interval increase.\n    // This value is the cap of the interval. Default is 100x of initial interval.\n    MaximumInterval time.Duration\n\n    // Maximum time to retry. Either ExpirationInterval or MaximumAttempts is required.\n    // When exceeded the retries stop even if maximum retries is not reached yet.\n    ExpirationInterval time.Duration\n\n    // Maximum number of attempts. When exceeded the retries stop even if not expired yet.\n    // If not set or set to 0, it means unlimited, and relies on ExpirationInterval to stop.\n    // Either MaximumAttempts or ExpirationInterval is required.\n    MaximumAttempts int32\n\n    // Non-Retriable errors. This is optional. Cadence server will stop retry if error reason matches this list.\n    // Error reason for custom error is specified when your activity/workflow returns cadence.NewCustomError(reason).\n    // Error reason for panic error is \"cadenceInternal:Panic\".\n    // Error reason for any other error is \"cadenceInternal:Generic\".\n    // Error reason for timeouts is: \"cadenceInternal:Timeout TIMEOUT_TYPE\". TIMEOUT_TYPE could be START_TO_CLOSE or HEARTBEAT.\n    // Note that cancellation is not a failure, so it won't be retried.\n    NonRetriableErrorReasons []string\n}\n\n\nTo enable retry, supply a custom retry policy to ActivityOptions or ChildWorkflowOptionswhen you execute them.\n\nexpiration := time.Minute * 10\nretryPolicy := &cadence.RetryPolicy{\n    InitialInterval:    time.Second,\n    BackoffCoefficient: 2,\n    MaximumInterval:    expiration,\n    ExpirationInterval: time.Minute * 10,\n    MaximumAttempts:    5,\n}\nao := workflow.ActivityOptions{\n    ScheduleToStartTimeout: expiration,\n    StartToCloseTimeout:    expiration,\n    HeartbeatTimeout:       time.Second * 30,\n    RetryPolicy:            retryPolicy, // Enable retry.\n}\nctx = workflow.WithActivityOptions(ctx, ao)\nactivityFuture := workflow.ExecuteActivity(ctx, SampleActivity, params)\n\n\nIf heartbeat its progress before it failed, the retry attempt will contain the progress so implementation could resume from failed progress like:\n\nfunc SampleActivity(ctx context.Context, inputArg InputParams) error {\n    startIdx := inputArg.StartIndex\n    if activity.HasHeartbeatDetails(ctx) {\n        // Recover from finished progress.\n        var finishedIndex int\n        if err := activity.GetHeartbeatDetails(ctx, &finishedIndex); err == nil {\n            startIdx = finishedIndex + 1 // Start from next one.\n        }\n    }\n\n    // Normal activity logic...\n    for i:=startIdx; i<inputArg.EndIdx; i++ {\n        // Code for processing item i goes here...\n        activity.RecordHeartbeat(ctx, i) // Report progress.\n    }\n}\n\n\nLike retry for an , you need to supply a retry policy for ChildWorkflowOptions to enable retry for a child . To enable retry for a parent , supply a retry policy when you start a via StartWorkflowOptions.\n\nThere are some subtle changes to 's history when RetryPolicy is used. For an with RetryPolicy:\n\n * The ActivityTaskScheduledEvent will have extended ScheduleToStartTimeout and ScheduleToCloseTimeout. These two timeouts will be overwritten by the server to be as long as the retry policy's ExpirationInterval. If the ExpirationIntervalis not specified, it will be overwritten to the 's timeout.\n * The ActivityTaskStartedEvent will not show up in history until the is completed or failed with no more retry. This is to avoid recording the ActivityTaskStarted but later it failed and retried. Using the DescribeWorkflowExecutionAPI will return the PendingActivityInfo and it will contain attemptCount if it is retrying.\n\nFor a with RetryPolicy:\n\n * If a failed and needs to retry, the will be closed with a ContinueAsNew . The will have the ContinueAsNewInitiator set to RetryPolicy and the new RunID for the next retry attempt.\n * The new attempt will be created immediately. But the first won't be scheduled until the backoff duration which is also recorded in the new run's WorkflowExecutionStartedEventAttributes as firstDecisionTaskBackoffSeconds.",normalizedContent:"# activity and workflow retries\n and can fail due to various intermediate conditions. in those cases, we want to retry the failed or child or even the parent . this can be achieved by supplying an optional retry policy. a retry policy looks like the following:\n\n// retrypolicy defines the retry policy.\nretrypolicy struct {\n    // backoff interval for the first retry. if coefficient is 1.0 then it is used for all retries.\n    // required, no default value.\n    initialinterval time.duration\n\n    // coefficient used to calculate the next retry backoff interval.\n    // the next retry interval is previous interval multiplied by this coefficient.\n    // must be 1 or larger. default is 2.0.\n    backoffcoefficient float64\n\n    // maximum backoff interval between retries. exponential backoff leads to interval increase.\n    // this value is the cap of the interval. default is 100x of initial interval.\n    maximuminterval time.duration\n\n    // maximum time to retry. either expirationinterval or maximumattempts is required.\n    // when exceeded the retries stop even if maximum retries is not reached yet.\n    expirationinterval time.duration\n\n    // maximum number of attempts. when exceeded the retries stop even if not expired yet.\n    // if not set or set to 0, it means unlimited, and relies on expirationinterval to stop.\n    // either maximumattempts or expirationinterval is required.\n    maximumattempts int32\n\n    // non-retriable errors. this is optional. cadence server will stop retry if error reason matches this list.\n    // error reason for custom error is specified when your activity/workflow returns cadence.newcustomerror(reason).\n    // error reason for panic error is \"cadenceinternal:panic\".\n    // error reason for any other error is \"cadenceinternal:generic\".\n    // error reason for timeouts is: \"cadenceinternal:timeout timeout_type\". timeout_type could be start_to_close or heartbeat.\n    // note that cancellation is not a failure, so it won't be retried.\n    nonretriableerrorreasons []string\n}\n\n\nto enable retry, supply a custom retry policy to activityoptions or childworkflowoptionswhen you execute them.\n\nexpiration := time.minute * 10\nretrypolicy := &cadence.retrypolicy{\n    initialinterval:    time.second,\n    backoffcoefficient: 2,\n    maximuminterval:    expiration,\n    expirationinterval: time.minute * 10,\n    maximumattempts:    5,\n}\nao := workflow.activityoptions{\n    scheduletostarttimeout: expiration,\n    starttoclosetimeout:    expiration,\n    heartbeattimeout:       time.second * 30,\n    retrypolicy:            retrypolicy, // enable retry.\n}\nctx = workflow.withactivityoptions(ctx, ao)\nactivityfuture := workflow.executeactivity(ctx, sampleactivity, params)\n\n\nif heartbeat its progress before it failed, the retry attempt will contain the progress so implementation could resume from failed progress like:\n\nfunc sampleactivity(ctx context.context, inputarg inputparams) error {\n    startidx := inputarg.startindex\n    if activity.hasheartbeatdetails(ctx) {\n        // recover from finished progress.\n        var finishedindex int\n        if err := activity.getheartbeatdetails(ctx, &finishedindex); err == nil {\n            startidx = finishedindex + 1 // start from next one.\n        }\n    }\n\n    // normal activity logic...\n    for i:=startidx; i<inputarg.endidx; i++ {\n        // code for processing item i goes here...\n        activity.recordheartbeat(ctx, i) // report progress.\n    }\n}\n\n\nlike retry for an , you need to supply a retry policy for childworkflowoptions to enable retry for a child . to enable retry for a parent , supply a retry policy when you start a via startworkflowoptions.\n\nthere are some subtle changes to 's history when retrypolicy is used. for an with retrypolicy:\n\n * the activitytaskscheduledevent will have extended scheduletostarttimeout and scheduletoclosetimeout. these two timeouts will be overwritten by the server to be as long as the retry policy's expirationinterval. if the expirationintervalis not specified, it will be overwritten to the 's timeout.\n * the activitytaskstartedevent will not show up in history until the is completed or failed with no more retry. this is to avoid recording the activitytaskstarted but later it failed and retried. using the describeworkflowexecutionapi will return the pendingactivityinfo and it will contain attemptcount if it is retrying.\n\nfor a with retrypolicy:\n\n * if a failed and needs to retry, the will be closed with a continueasnew . the will have the continueasnewinitiator set to retrypolicy and the new runid for the next retry attempt.\n * the new attempt will be created immediately. but the first won't be scheduled until the backoff duration which is also recorded in the new run's workflowexecutionstartedeventattributes as firstdecisiontaskbackoffseconds.",charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/java-client",readingShow:"top"},regularPath:"/docs/04-java-client/",relativePath:"docs/04-java-client/index.md",key:"v-651b4e0a",path:"/docs/java-client/",headersStr:null,content:"# Java client\nThe following are important links for the Cadence Java client:\n\n * GitHub project: https://github.com/uber/cadence-java-client\n * Samples: https://github.com/uber/cadence-java-samples\n * JavaDoc documentation: https://www.javadoc.io/doc/com.uber.cadence/cadence-client",normalizedContent:"# java client\nthe following are important links for the cadence java client:\n\n * github project: https://github.com/uber/cadence-java-client\n * samples: https://github.com/uber/cadence-java-samples\n * javadoc documentation: https://www.javadoc.io/doc/com.uber.cadence/cadence-client",charsets:{}},{title:"Error handling",frontmatter:{layout:"default",title:"Error handling",permalink:"/docs/go-client/error-handling",readingShow:"top"},regularPath:"/docs/05-go-client/07-error-handling.html",relativePath:"docs/05-go-client/07-error-handling.md",key:"v-103bbcbc",path:"/docs/go-client/error-handling/",headersStr:null,content:'# Error handling\nAn , or child , might fail and you could handle errors differently based on different error cases. If the returns an error as errors.New() or fmt.Errorf(), those errors will be converted to workflow.GenericError. If the returns an error ascadence.NewCustomError(“err-reason”, details), that error will be converted to *cadence.CustomError. There are other types of errors such as workflow.TimeoutError, workflow.CanceledError andworkflow.PanicError. Following is an example of what your error code might look like:\n\nerr := workflow.ExecuteActivity(ctx, YourActivityFunc).Get(ctx, nil)\nswitch err := err.(type) {\n    case *cadence.CustomError:\n        switch err.Reason() {\n            case "err-reason-a":\n                // Handle error-reason-a.\n                var details YourErrorDetailsType\n                err.Details(&details)\n                // Deal with details.\n            case "err-reason-b":\n                // Handle error-reason-b.\n            default:\n                // Handle all other error reasons.\n        }\n    case *workflow.GenericError:\n        switch err.Error() {\n            case "err-msg-1":\n                // Handle error with message "err-msg-1".\n            case "err-msg-2":\n                // Handle error with message "err-msg-2".\n            default:\n                // Handle all other generic errors.\n        }\n    case *workflow.TimeoutError:\n        switch err.TimeoutType() {\n            case shared.TimeoutTypeScheduleToStart:\n                // Handle ScheduleToStart timeout.\n            case shared.TimeoutTypeStartToClose:\n                // Handle StartToClose timeout.\n            case shared.TimeoutTypeHeartbeat:\n                // Handle heartbeat timeout.\n            default:\n        }\n    case *workflow.PanicError:\n        // Handle panic error.\n    case *cadence.CanceledError:\n        // Handle canceled error.\n    default:\n        // All other cases (ideally, this should not happen).\n}',normalizedContent:'# error handling\nan , or child , might fail and you could handle errors differently based on different error cases. if the returns an error as errors.new() or fmt.errorf(), those errors will be converted to workflow.genericerror. if the returns an error ascadence.newcustomerror(“err-reason”, details), that error will be converted to *cadence.customerror. there are other types of errors such as workflow.timeouterror, workflow.cancelederror andworkflow.panicerror. following is an example of what your error code might look like:\n\nerr := workflow.executeactivity(ctx, youractivityfunc).get(ctx, nil)\nswitch err := err.(type) {\n    case *cadence.customerror:\n        switch err.reason() {\n            case "err-reason-a":\n                // handle error-reason-a.\n                var details yourerrordetailstype\n                err.details(&details)\n                // deal with details.\n            case "err-reason-b":\n                // handle error-reason-b.\n            default:\n                // handle all other error reasons.\n        }\n    case *workflow.genericerror:\n        switch err.error() {\n            case "err-msg-1":\n                // handle error with message "err-msg-1".\n            case "err-msg-2":\n                // handle error with message "err-msg-2".\n            default:\n                // handle all other generic errors.\n        }\n    case *workflow.timeouterror:\n        switch err.timeouttype() {\n            case shared.timeouttypescheduletostart:\n                // handle scheduletostart timeout.\n            case shared.timeouttypestarttoclose:\n                // handle starttoclose timeout.\n            case shared.timeouttypeheartbeat:\n                // handle heartbeat timeout.\n            default:\n        }\n    case *workflow.panicerror:\n        // handle panic error.\n    case *cadence.cancelederror:\n        // handle canceled error.\n    default:\n        // all other cases (ideally, this should not happen).\n}',charsets:{}},{title:"Signals",frontmatter:{layout:"default",title:"Signals",permalink:"/docs/go-client/signals",readingShow:"top"},regularPath:"/docs/05-go-client/08-signals.html",relativePath:"docs/05-go-client/08-signals.md",key:"v-65ea467c",path:"/docs/go-client/signals/",headers:[{level:2,title:"SignalWithStart",slug:"signalwithstart",normalizedTitle:"signalwithstart",charIndex:1650}],headersStr:"SignalWithStart",content:'# Signals\n provide a mechanism to send data directly to a running . Previously, you had two options for passing data to the implementation:\n\n * Via start parameters\n * As return values from \n\nWith start parameters, we could only pass in values before began.\n\nReturn values from allowed us to pass information to a running , but this approach comes with its own complications. One major drawback is reliance on polling. This means that the data needs to be stored in a third-party location until it\'s ready to be picked up by the . Further, the lifecycle of this requires management, and the requires manual restart if it fails before acquiring the data.\n\n, on the other hand, provide a fully asynchronous and durable mechanism for providing data to a running . When a is received for a running , Cadence persists the and the payload in the history. The can then process the at any time afterwards without the risk of losing the information. The also has the option to stop execution by blocking on a channel.\n\nvar signalVal string\nsignalChan := workflow.GetSignalChannel(ctx, signalName)\n\ns := workflow.NewSelector(ctx)\ns.AddReceive(signalChan, func(c workflow.Channel, more bool) {\n    c.Receive(ctx, &signalVal)\n    workflow.GetLogger(ctx).Info("Received signal!", zap.String("signal", signalName), zap.String("value", signalVal))\n})\ns.Select(ctx)\n\nif len(signalVal) > 0 && signalVal != "SOME_VALUE" {\n    return errors.New("signalVal")\n}\n\n\nIn the example above, the code uses workflow.GetSignalChannel to open aworkflow.Channel for the named . We then use a workflow.Selector to wait on this channel and process the payload received with the .\n\n# SignalWithStart\nYou may not know if a is running and can accept a . Theclient.SignalWithStartWorkflow API allows you to send a to the current instance if one exists or to create a new run and then send the . SignalWithStartWorkflow therefore doesn\'t take a as a parameter.',normalizedContent:'# signals\n provide a mechanism to send data directly to a running . previously, you had two options for passing data to the implementation:\n\n * via start parameters\n * as return values from \n\nwith start parameters, we could only pass in values before began.\n\nreturn values from allowed us to pass information to a running , but this approach comes with its own complications. one major drawback is reliance on polling. this means that the data needs to be stored in a third-party location until it\'s ready to be picked up by the . further, the lifecycle of this requires management, and the requires manual restart if it fails before acquiring the data.\n\n, on the other hand, provide a fully asynchronous and durable mechanism for providing data to a running . when a is received for a running , cadence persists the and the payload in the history. the can then process the at any time afterwards without the risk of losing the information. the also has the option to stop execution by blocking on a channel.\n\nvar signalval string\nsignalchan := workflow.getsignalchannel(ctx, signalname)\n\ns := workflow.newselector(ctx)\ns.addreceive(signalchan, func(c workflow.channel, more bool) {\n    c.receive(ctx, &signalval)\n    workflow.getlogger(ctx).info("received signal!", zap.string("signal", signalname), zap.string("value", signalval))\n})\ns.select(ctx)\n\nif len(signalval) > 0 && signalval != "some_value" {\n    return errors.new("signalval")\n}\n\n\nin the example above, the code uses workflow.getsignalchannel to open aworkflow.channel for the named . we then use a workflow.selector to wait on this channel and process the payload received with the .\n\n# signalwithstart\nyou may not know if a is running and can accept a . theclient.signalwithstartworkflow api allows you to send a to the current instance if one exists or to create a new run and then send the . signalwithstartworkflow therefore doesn\'t take a as a parameter.',charsets:{}},{title:"Continue as new",frontmatter:{layout:"default",title:"Continue as new",permalink:"/docs/go-client/continue-as-new",readingShow:"top"},regularPath:"/docs/05-go-client/09-continue-as-new.html",relativePath:"docs/05-go-client/09-continue-as-new.md",key:"v-b60e670c",path:"/docs/go-client/continue-as-new/",headersStr:null,content:"# Continue as new\n that need to rerun periodically could naively be implemented as a big for loop with a sleep where the entire logic of the is inside the body of the for loop. The problem with this approach is that the history for that will keep growing to a point where it reaches the maximum size enforced by the service.\n\nContinueAsNew is the low level construct that enables implementing such without the risk of failures down the road. The operation atomically completes the current execution and starts a new execution of the with the same . The new execution will not carry over any history from the old execution. To trigger this behavior, the function should terminate by returning the special ContinueAsNewError error:\n\nfunc SimpleWorkflow(workflow.Context ctx, value string) error {\n    ...\n    return workflow.NewContinueAsNewError(ctx, SimpleWorkflow, value)\n}",normalizedContent:"# continue as new\n that need to rerun periodically could naively be implemented as a big for loop with a sleep where the entire logic of the is inside the body of the for loop. the problem with this approach is that the history for that will keep growing to a point where it reaches the maximum size enforced by the service.\n\ncontinueasnew is the low level construct that enables implementing such without the risk of failures down the road. the operation atomically completes the current execution and starts a new execution of the with the same . the new execution will not carry over any history from the old execution. to trigger this behavior, the function should terminate by returning the special continueasnewerror error:\n\nfunc simpleworkflow(workflow.context ctx, value string) error {\n    ...\n    return workflow.newcontinueasnewerror(ctx, simpleworkflow, value)\n}",charsets:{}},{title:"Side effect",frontmatter:{layout:"default",title:"Side effect",permalink:"/docs/go-client/side-effect",readingShow:"top"},regularPath:"/docs/05-go-client/10-side-effect.html",relativePath:"docs/05-go-client/10-side-effect.md",key:"v-3c7b0dd4",path:"/docs/go-client/side-effect/",headersStr:null,content:'# Side effect\nworkflow.SideEffect is useful for short, nondeterministic code snippets, such as getting a random value or generating a UUID. It executes the provided function once and records its result into the history. workflow.SideEffect does not re-execute upon replay, but instead returns the recorded result. It can be seen as an "inline" . Something to note about workflow.SideEffectis that, unlike the Cadence guarantee of at-most-once execution for , there is no such guarantee with workflow.SideEffect. Under certain failure conditions, workflow.SideEffect can end up executing a function more than once.\n\nThe only way to fail SideEffect is to panic, which causes a failure. After the timeout, Cadence reschedules and then re-executes the , giving SideEffect another chance to succeed. Do not return any data from SideEffect other than through its recorded return value.\n\nThe following sample demonstrates how to use SideEffect:\n\nencodedRandom := SideEffect(func(ctx cadence.Context) interface{} {\n    return rand.Intn(100)\n})\n\nvar random int\nencodedRandom.Get(&random)\nif random < 50 {\n    ...\n} else {\n    ...\n}',normalizedContent:'# side effect\nworkflow.sideeffect is useful for short, nondeterministic code snippets, such as getting a random value or generating a uuid. it executes the provided function once and records its result into the history. workflow.sideeffect does not re-execute upon replay, but instead returns the recorded result. it can be seen as an "inline" . something to note about workflow.sideeffectis that, unlike the cadence guarantee of at-most-once execution for , there is no such guarantee with workflow.sideeffect. under certain failure conditions, workflow.sideeffect can end up executing a function more than once.\n\nthe only way to fail sideeffect is to panic, which causes a failure. after the timeout, cadence reschedules and then re-executes the , giving sideeffect another chance to succeed. do not return any data from sideeffect other than through its recorded return value.\n\nthe following sample demonstrates how to use sideeffect:\n\nencodedrandom := sideeffect(func(ctx cadence.context) interface{} {\n    return rand.intn(100)\n})\n\nvar random int\nencodedrandom.get(&random)\nif random < 50 {\n    ...\n} else {\n    ...\n}',charsets:{}},{title:"Queries",frontmatter:{layout:"default",title:"Queries",permalink:"/docs/go-client/queries",readingShow:"top"},regularPath:"/docs/05-go-client/11-queries.html",relativePath:"docs/05-go-client/11-queries.md",key:"v-a558de54",path:"/docs/go-client/queries/",headers:[{level:2,title:"Consistent Query",slug:"consistent-query",normalizedTitle:"consistent query",charIndex:2006}],headersStr:"Consistent Query",content:'# Queries\nIf a has been stuck at a state for longer than an expected period of time, you might want to the current call stack. You can use the Cadence to perform this . For example:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt __stack_trace\n\nThis command uses __stack_trace, which is a built-in type supported by the Cadence client library. You can add custom types to handle such as the current state of a, or how many the has completed. To do this, you need to set up a handler using workflow.SetQueryHandler.\n\nThe handler must be a function that returns two values:\n\n 1. A serializable result\n 2. An error\n\nThe handler function can receive any number of input parameters, but all input parameters must be serializable. The following sample code sets up a handler that handles the type ofcurrent_state:\n\nfunc MyWorkflow(ctx workflow.Context, input string) error {\n    currentState := "started" // This could be any serializable struct.\n    err := workflow.SetQueryHandler(ctx, "current_state", func() (string, error) {\n        return currentState, nil\n    })\n    if err != nil {\n        currentState = "failed to register query handler"\n        return err\n    }\n    // Your normal workflow code begins here, and you update the currentState as the code makes progress.\n    currentState = "waiting timer"\n    err = NewTimer(ctx, time.Hour).Get(ctx, nil)\n    if err != nil {\n        currentState = "timer failed"\n        return err\n    }\n\n    currentState = "waiting activity"\n    ctx = WithActivityOptions(ctx, myActivityOptions)\n    err = ExecuteActivity(ctx, MyActivity, "my_input").Get(ctx, nil)\n    if err != nil {\n        currentState = "activity failed"\n        return err\n    }\n    currentState = "done"\n    return nil\n}\n\n\nYou can now current_state by using the \n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nYou can also issue a from code using the QueryWorkflow() API on a Cadence client object.\n\n# Consistent Query\n has two consistency levels, eventual and strong. Consider if you were to a and then immediately the \n\ncadence-cli --domain samples-domain workflow signal -w my_workflow_id -r my_run_id -n signal_name -if ./input.json\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nIn this example if were to change state, may or may not see that state update reflected in the result. This is what it means for to be eventually consistent.\n\n has another consistency level called strong consistency. A strongly consistent is guaranteed to be based on state which includes all that came before the was issued. An is considered to have come before a if the call creating the external returned success before the was issued. External which are created while the is outstanding may or may not be reflected in the state the result is based on.\n\nIn order to run consistent through the do the following:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state --qcl strong\n\nIn order to run a using the go client do the following:\n\nresp, err := cadenceClient.QueryWorkflowWithOptions(ctx, &client.QueryWorkflowWithOptionsRequest{\n    WorkflowID:            workflowID,\n    RunID:                 runID,\n    QueryType:             queryType,\n    QueryConsistencyLevel: shared.QueryConsistencyLevelStrong.Ptr(),\n})\n\n\nWhen using strongly consistent you should expect higher latency than eventually consistent .',normalizedContent:'# queries\nif a has been stuck at a state for longer than an expected period of time, you might want to the current call stack. you can use the cadence to perform this . for example:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt __stack_trace\n\nthis command uses __stack_trace, which is a built-in type supported by the cadence client library. you can add custom types to handle such as the current state of a, or how many the has completed. to do this, you need to set up a handler using workflow.setqueryhandler.\n\nthe handler must be a function that returns two values:\n\n 1. a serializable result\n 2. an error\n\nthe handler function can receive any number of input parameters, but all input parameters must be serializable. the following sample code sets up a handler that handles the type ofcurrent_state:\n\nfunc myworkflow(ctx workflow.context, input string) error {\n    currentstate := "started" // this could be any serializable struct.\n    err := workflow.setqueryhandler(ctx, "current_state", func() (string, error) {\n        return currentstate, nil\n    })\n    if err != nil {\n        currentstate = "failed to register query handler"\n        return err\n    }\n    // your normal workflow code begins here, and you update the currentstate as the code makes progress.\n    currentstate = "waiting timer"\n    err = newtimer(ctx, time.hour).get(ctx, nil)\n    if err != nil {\n        currentstate = "timer failed"\n        return err\n    }\n\n    currentstate = "waiting activity"\n    ctx = withactivityoptions(ctx, myactivityoptions)\n    err = executeactivity(ctx, myactivity, "my_input").get(ctx, nil)\n    if err != nil {\n        currentstate = "activity failed"\n        return err\n    }\n    currentstate = "done"\n    return nil\n}\n\n\nyou can now current_state by using the \n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nyou can also issue a from code using the queryworkflow() api on a cadence client object.\n\n# consistent query\n has two consistency levels, eventual and strong. consider if you were to a and then immediately the \n\ncadence-cli --domain samples-domain workflow signal -w my_workflow_id -r my_run_id -n signal_name -if ./input.json\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state\n\nin this example if were to change state, may or may not see that state update reflected in the result. this is what it means for to be eventually consistent.\n\n has another consistency level called strong consistency. a strongly consistent is guaranteed to be based on state which includes all that came before the was issued. an is considered to have come before a if the call creating the external returned success before the was issued. external which are created while the is outstanding may or may not be reflected in the state the result is based on.\n\nin order to run consistent through the do the following:\n\ncadence-cli --domain samples-domain workflow query -w my_workflow_id -r my_run_id -qt current_state --qcl strong\n\nin order to run a using the go client do the following:\n\nresp, err := cadenceclient.queryworkflowwithoptions(ctx, &client.queryworkflowwithoptionsrequest{\n    workflowid:            workflowid,\n    runid:                 runid,\n    querytype:             querytype,\n    queryconsistencylevel: shared.queryconsistencylevelstrong.ptr(),\n})\n\n\nwhen using strongly consistent you should expect higher latency than eventually consistent .',charsets:{}},{title:"Async activity completion",frontmatter:{layout:"default",title:"Async activity completion",permalink:"/docs/go-client/activity-async-completion",readingShow:"top"},regularPath:"/docs/05-go-client/12-activity-async-completion.html",relativePath:"docs/05-go-client/12-activity-async-completion.md",key:"v-5b7bae8a",path:"/docs/go-client/activity-async-completion/",headersStr:null,content:'# Asynchronous activity completion\nThere are certain scenarios when completing an upon completion of its function is not possible or desirable. For example, you might have an application that requires user input in order to complete the . You could implement the with a polling mechanism, but a simpler and less resource-intensive implementation is to asynchronously complete a Cadence .\n\nThere two parts to implementing an asynchronously completed activity:\n\n 1. The provides the information necessary for completion from an external system and notifies the Cadence service that it is waiting for that outside callback.\n 2. The external service calls the Cadence service to complete the .\n\nThe following example demonstrates the first part:\n\n// Retrieve the activity information needed to asynchronously complete the activity.\nactivityInfo := cadence.GetActivityInfo(ctx)\ntaskToken := activityInfo.TaskToken\n\n// Send the taskToken to the external service that will complete the activity.\n...\n\n// Return from the activity a function indicating that Cadence should wait for an async completion\n// message.\nreturn "", activity.ErrResultPending\n\n\nThe following code demonstrates how to complete the successfully:\n\n// Instantiate a Cadence service client.\n// The same client can be used to complete or fail any number of activities.\ncadence.Client client = cadence.NewClient(...)\n\n// Complete the activity.\nclient.CompleteActivity(taskToken, result, nil)\n\n\nTo fail the , you would do the following:\n\n// Fail the activity.\nclient.CompleteActivity(taskToken, nil, err)\n\n\nFollowing are the parameters of the CompleteActivity function:\n\n * taskToken: The value of the binary TaskToken field of the ActivityInfo struct retrieved inside the .\n * result: The return value to record for the . The type of this value must match the type of the return value declared by the function.\n * err: The error code to return if the terminates with an error.\n\nIf error is not null, the value of the result field is ignored.',normalizedContent:'# asynchronous activity completion\nthere are certain scenarios when completing an upon completion of its function is not possible or desirable. for example, you might have an application that requires user input in order to complete the . you could implement the with a polling mechanism, but a simpler and less resource-intensive implementation is to asynchronously complete a cadence .\n\nthere two parts to implementing an asynchronously completed activity:\n\n 1. the provides the information necessary for completion from an external system and notifies the cadence service that it is waiting for that outside callback.\n 2. the external service calls the cadence service to complete the .\n\nthe following example demonstrates the first part:\n\n// retrieve the activity information needed to asynchronously complete the activity.\nactivityinfo := cadence.getactivityinfo(ctx)\ntasktoken := activityinfo.tasktoken\n\n// send the tasktoken to the external service that will complete the activity.\n...\n\n// return from the activity a function indicating that cadence should wait for an async completion\n// message.\nreturn "", activity.errresultpending\n\n\nthe following code demonstrates how to complete the successfully:\n\n// instantiate a cadence service client.\n// the same client can be used to complete or fail any number of activities.\ncadence.client client = cadence.newclient(...)\n\n// complete the activity.\nclient.completeactivity(tasktoken, result, nil)\n\n\nto fail the , you would do the following:\n\n// fail the activity.\nclient.completeactivity(tasktoken, nil, err)\n\n\nfollowing are the parameters of the completeactivity function:\n\n * tasktoken: the value of the binary tasktoken field of the activityinfo struct retrieved inside the .\n * result: the return value to record for the . the type of this value must match the type of the return value declared by the function.\n * err: the error code to return if the terminates with an error.\n\nif error is not null, the value of the result field is ignored.',charsets:{}},{title:"Testing",frontmatter:{layout:"default",title:"Testing",permalink:"/docs/go-client/workflow-testing",readingShow:"top"},regularPath:"/docs/05-go-client/13-workflow-testing.html",relativePath:"docs/05-go-client/13-workflow-testing.md",key:"v-722c1fc2",path:"/docs/go-client/workflow-testing/",headers:[{level:2,title:"Setup",slug:"setup",normalizedTitle:"setup",charIndex:618},{level:2,title:"A Simple Test",slug:"a-simple-test",normalizedTitle:"a simple test",charIndex:2852},{level:2,title:"Activity mocking and overriding",slug:"activity-mocking-and-overriding",normalizedTitle:"activity mocking and overriding",charIndex:3527}],headersStr:"Setup A Simple Test Activity mocking and overriding",content:'# Testing\nThe Cadence Go client library provides a test framework to facilitate testing implementations. The framework is suited for implementing unit tests as well as functional tests of the logic.\n\nThe following code implements unit tests for the SimpleWorkflow sample:\n\npackage sample\n\nimport (\n    "errors"\n    "testing"\n\n    "github.com/stretchr/testify/mock"\n    "github.com/stretchr/testify/suite"\n\n    "go.uber.org/cadence"\n    "go.uber.org/cadence/testsuite"\n)\n\ntype UnitTestSuite struct {\n    suite.Suite\n    testsuite.WorkflowTestSuite\n\n    env *testsuite.TestWorkflowEnvironment\n}\n\nfunc (s *UnitTestSuite) SetupTest() {\n    s.env = s.NewTestWorkflowEnvironment()\n}\n\nfunc (s *UnitTestSuite) AfterTest(suiteName, testName string) {\n    s.env.AssertExpectations(s.T())\n}\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_Success() {\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityParamCorrect() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        func(ctx context.Context, value string) (string, error) {\n            s.Equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityFails() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        "", errors.New("SimpleActivityFailure"))\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_failure")\n\n    s.True(s.env.IsWorkflowCompleted())\n\n    s.NotNil(s.env.GetWorkflowError())\n    s.True(cadence.IsGenericError(s.env.GetWorkflowError()))\n    s.Equal("SimpleActivityFailure", s.env.GetWorkflowError().Error())\n}\n\nfunc TestUnitTestSuite(t *testing.T) {\n    suite.Run(t, new(UnitTestSuite))\n}\n\n\n# Setup\nTo run unit tests, we first define a "test suite" struct that absorbs both the basic suite functionality from testifyvia suite.Suite and the suite functionality from the Cadence test framework viacadence.WorkflowTestSuite. Because every test in this test suite will test our , we add a property to our struct to hold an instance of the test environment. This allows us to initialize the test environment in a setup method. For testing , we use a cadence.TestWorkflowEnvironment.\n\nNext, we implement a SetupTest method to setup a new test environment before each test. Doing so ensures that each test runs in its own isolated sandbox. We also implement an AfterTest function where we assert that all mocks we set up were indeed called by invoking s.env.AssertExpectations(s.T()).\n\nFinally, we create a regular test function recognized by "go test" and pass the struct to suite.Run.\n\n# A Simple Test\nThe most simple test case we can write is to have the test environment execute the and then evaluate the results.\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_Success() {\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\n\nCalling s.env.ExecuteWorkflow(...) executes the logic and any invoked inside the test process. The first parameter of s.env.ExecuteWorkflow(...) contains the functions, and any subsequent parameters contain values for custom input parameters declared by the function.\n\n> Note that unless the invocations are mocked or implementation replaced (see Activity mocking and overriding), the test environment will execute the actual code including any calls to outside services.\n\n\nAfter executing the in the above example, we assert that the ran through completion via the call to s.env.IsWorkflowComplete(). We also assert that no errors were returned by asserting on the return value of s.env.GetWorkflowError(). If our returned a value, we could have retrieved that value via a call to s.env.GetWorkflowResult(&value) and had additional asserts on that value.\n\n# Activity mocking and overriding\nWhen running unit tests on , we want to test the logic in isolation. Additionally, we want to inject errors during our test runs. The test framework provides two mechanisms that support these scenarios: mocking and overriding. Both of these mechanisms allow you to change the behavior of invoked by your without the need to modify the actual code.\n\nLet\'s take a look at a test that simulates a test that fails via the "activity mocking" mechanism.\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityFails() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        "", errors.New("SimpleActivityFailure"))\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_failure")\n\n    s.True(s.env.IsWorkflowCompleted())\n\n    s.NotNil(s.env.GetWorkflowError())\n    _, ok := s.env.GetWorkflowError().(*cadence.GenericError)\n    s.True(ok)\n    s.Equal("SimpleActivityFailure", s.env.GetWorkflowError().Error())\n}\n\n\nThis test simulates the execution of the SimpleActivity that is invoked by our SimpleWorkflow returning an error. We accomplish this by setting up a mock on the test environment for the SimpleActivity that returns an error.\n\ns.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n    "", errors.New("SimpleActivityFailure"))\n\n\nWith the mock set up we can now execute the via the s.env.ExecuteWorkflow(...) method and assert that the completed successfully and returned the expected error.\n\nSimply mocking the execution to return a desired value or error is a pretty powerful mechanism to isolate logic. However, sometimes we want to replace the with an alternate implementation to support a more complex test scenario. Let\'s assume we want to validate that the gets called with the correct parameters.\n\nfunc (s *UnitTestSuite) Test_SimpleWorkflow_ActivityParamCorrect() {\n    s.env.OnActivity(SimpleActivity, mock.Anything, mock.Anything).Return(\n        func(ctx context.Context, value string) (string, error) {\n            s.Equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.ExecuteWorkflow(SimpleWorkflow, "test_success")\n\n    s.True(s.env.IsWorkflowCompleted())\n    s.NoError(s.env.GetWorkflowError())\n}\n\n\nIn this example, we provide a function implementation as the parameter to Return. This allows us to provide an alternate implementation for the SimpleActivity. The framework will execute this function whenever the is invoked and pass on the return value from the function as the result of the invocation. Additionally, the framework will validate that the signature of the “mock” function matches the signature of the original function.\n\nSince this can be an entire function, there is no limitation as to what we can do here. In this example, we assert that the “value” param has the same content as the value param we passed to the .',normalizedContent:'# testing\nthe cadence go client library provides a test framework to facilitate testing implementations. the framework is suited for implementing unit tests as well as functional tests of the logic.\n\nthe following code implements unit tests for the simpleworkflow sample:\n\npackage sample\n\nimport (\n    "errors"\n    "testing"\n\n    "github.com/stretchr/testify/mock"\n    "github.com/stretchr/testify/suite"\n\n    "go.uber.org/cadence"\n    "go.uber.org/cadence/testsuite"\n)\n\ntype unittestsuite struct {\n    suite.suite\n    testsuite.workflowtestsuite\n\n    env *testsuite.testworkflowenvironment\n}\n\nfunc (s *unittestsuite) setuptest() {\n    s.env = s.newtestworkflowenvironment()\n}\n\nfunc (s *unittestsuite) aftertest(suitename, testname string) {\n    s.env.assertexpectations(s.t())\n}\n\nfunc (s *unittestsuite) test_simpleworkflow_success() {\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\nfunc (s *unittestsuite) test_simpleworkflow_activityparamcorrect() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        func(ctx context.context, value string) (string, error) {\n            s.equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\nfunc (s *unittestsuite) test_simpleworkflow_activityfails() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        "", errors.new("simpleactivityfailure"))\n    s.env.executeworkflow(simpleworkflow, "test_failure")\n\n    s.true(s.env.isworkflowcompleted())\n\n    s.notnil(s.env.getworkflowerror())\n    s.true(cadence.isgenericerror(s.env.getworkflowerror()))\n    s.equal("simpleactivityfailure", s.env.getworkflowerror().error())\n}\n\nfunc testunittestsuite(t *testing.t) {\n    suite.run(t, new(unittestsuite))\n}\n\n\n# setup\nto run unit tests, we first define a "test suite" struct that absorbs both the basic suite functionality from testifyvia suite.suite and the suite functionality from the cadence test framework viacadence.workflowtestsuite. because every test in this test suite will test our , we add a property to our struct to hold an instance of the test environment. this allows us to initialize the test environment in a setup method. for testing , we use a cadence.testworkflowenvironment.\n\nnext, we implement a setuptest method to setup a new test environment before each test. doing so ensures that each test runs in its own isolated sandbox. we also implement an aftertest function where we assert that all mocks we set up were indeed called by invoking s.env.assertexpectations(s.t()).\n\nfinally, we create a regular test function recognized by "go test" and pass the struct to suite.run.\n\n# a simple test\nthe most simple test case we can write is to have the test environment execute the and then evaluate the results.\n\nfunc (s *unittestsuite) test_simpleworkflow_success() {\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\n\ncalling s.env.executeworkflow(...) executes the logic and any invoked inside the test process. the first parameter of s.env.executeworkflow(...) contains the functions, and any subsequent parameters contain values for custom input parameters declared by the function.\n\n> note that unless the invocations are mocked or implementation replaced (see activity mocking and overriding), the test environment will execute the actual code including any calls to outside services.\n\n\nafter executing the in the above example, we assert that the ran through completion via the call to s.env.isworkflowcomplete(). we also assert that no errors were returned by asserting on the return value of s.env.getworkflowerror(). if our returned a value, we could have retrieved that value via a call to s.env.getworkflowresult(&value) and had additional asserts on that value.\n\n# activity mocking and overriding\nwhen running unit tests on , we want to test the logic in isolation. additionally, we want to inject errors during our test runs. the test framework provides two mechanisms that support these scenarios: mocking and overriding. both of these mechanisms allow you to change the behavior of invoked by your without the need to modify the actual code.\n\nlet\'s take a look at a test that simulates a test that fails via the "activity mocking" mechanism.\n\nfunc (s *unittestsuite) test_simpleworkflow_activityfails() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        "", errors.new("simpleactivityfailure"))\n    s.env.executeworkflow(simpleworkflow, "test_failure")\n\n    s.true(s.env.isworkflowcompleted())\n\n    s.notnil(s.env.getworkflowerror())\n    _, ok := s.env.getworkflowerror().(*cadence.genericerror)\n    s.true(ok)\n    s.equal("simpleactivityfailure", s.env.getworkflowerror().error())\n}\n\n\nthis test simulates the execution of the simpleactivity that is invoked by our simpleworkflow returning an error. we accomplish this by setting up a mock on the test environment for the simpleactivity that returns an error.\n\ns.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n    "", errors.new("simpleactivityfailure"))\n\n\nwith the mock set up we can now execute the via the s.env.executeworkflow(...) method and assert that the completed successfully and returned the expected error.\n\nsimply mocking the execution to return a desired value or error is a pretty powerful mechanism to isolate logic. however, sometimes we want to replace the with an alternate implementation to support a more complex test scenario. let\'s assume we want to validate that the gets called with the correct parameters.\n\nfunc (s *unittestsuite) test_simpleworkflow_activityparamcorrect() {\n    s.env.onactivity(simpleactivity, mock.anything, mock.anything).return(\n        func(ctx context.context, value string) (string, error) {\n            s.equal("test_success", value)\n            return value, nil\n        }\n    )\n    s.env.executeworkflow(simpleworkflow, "test_success")\n\n    s.true(s.env.isworkflowcompleted())\n    s.noerror(s.env.getworkflowerror())\n}\n\n\nin this example, we provide a function implementation as the parameter to return. this allows us to provide an alternate implementation for the simpleactivity. the framework will execute this function whenever the is invoked and pass on the return value from the function as the result of the invocation. additionally, the framework will validate that the signature of the “mock” function matches the signature of the original function.\n\nsince this can be an entire function, there is no limitation as to what we can do here. in this example, we assert that the “value” param has the same content as the value param we passed to the .',charsets:{}},{title:"Versioning",frontmatter:{layout:"default",title:"Versioning",permalink:"/docs/go-client/workflow-versioning",readingShow:"top"},regularPath:"/docs/05-go-client/14-workflow-versioning.html",relativePath:"docs/05-go-client/14-workflow-versioning.md",key:"v-957246a8",path:"/docs/go-client/workflow-versioning/",headers:[{level:2,title:"workflow.GetVersion()",slug:"workflow-getversion",normalizedTitle:"workflow.getversion()",charIndex:313},{level:2,title:"Sanity checking",slug:"sanity-checking",normalizedTitle:"sanity checking",charIndex:5611}],headersStr:"workflow.GetVersion() Sanity checking",content:'# Versioning\nThe definition code of a Cadence must be deterministic because Cadence uses sourcing to reconstruct the state by replaying the saved history data on the definition code. This means that any incompatible update to the definition code could cause a non-deterministic issue if not handled correctly.\n\n# workflow.GetVersion()\nConsider the following definition:\n\nfunc MyWorkflow(ctx workflow.Context, data string) (string, error) {\n    ao := workflow.ActivityOptions{\n        ScheduleToStartTimeout: time.Minute,\n        StartToCloseTimeout:    time.Minute,\n    }\n    ctx = workflow.WithActivityOptions(ctx, ao)\n    var result1 string\n    err := workflow.ExecuteActivity(ctx, ActivityA, data).Get(ctx, &result1)\n    if err != nil {\n        return "", err\n    }\n    var result2 string\n    err = workflow.ExecuteActivity(ctx, ActivityB, result1).Get(ctx, &result2)\n    return result2, err\n}\n\n\nNow let\'s say we have replaced ActivityA with ActivityC, and deployed the updated code. If there is an existing that was started by the original version of the code, where ActivityA had already completed and the result was recorded to history, the new version of the code will pick up that and try to resume from there. However, the will fail because the new code expects a result for ActivityC from the history data, but instead it gets the result for ActivityA. This causes the to fail on the non-deterministic error.\n\nThus we use workflow.GetVersion().\n\nvar err error\nv := workflow.GetVersion(ctx, "Step1", workflow.DefaultVersion, 1)\nif v == workflow.DefaultVersion {\n    err = workflow.ExecuteActivity(ctx, ActivityA, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityC, data).Get(ctx, &result1)\n}\nif err != nil {\n    return "", err\n}\n\nvar result2 string\nerr = workflow.ExecuteActivity(ctx, ActivityB, result1).Get(ctx, &result2)\nreturn result2, err\n\n\nWhen workflow.GetVersion() is run for the new , it records a marker in the history so that all future calls to GetVersion for this change ID--Step 1 in the example--on this will always return the given version number, which is 1 in the example.\n\nIf you make an additional change, such as replacing ActivityC with ActivityD, you need to add some additional code:\n\nv := workflow.GetVersion(ctx, "Step1", workflow.DefaultVersion, 2)\nif v == workflow.DefaultVersion {\n    err = workflow.ExecuteActivity(ctx, ActivityA, data).Get(ctx, &result1)\n} else if v == 1 {\n    err = workflow.ExecuteActivity(ctx, ActivityC, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n}\n\n\nNote that we have changed maxSupported from 1 to 2. A that had already passed thisGetVersion() call before it was introduced will return DefaultVersion. A that was run with maxSupported set to 1, will return 1. New will return 2.\n\nAfter you are sure that all of the prior to version 1 have completed, you can remove the code for that version. It should now look like the following:\n\nv := workflow.GetVersion(ctx, "Step1", 1, 2)\nif v == 1 {\n    err = workflow.ExecuteActivity(ctx, ActivityC, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n}\n\n\nYou\'ll note that minSupported has changed from DefaultVersion to 1. If an older version of the history is replayed on this code, it will fail because the minimum expected version is 1. After you are sure that all of the for version 1 have completed, then you can remove 1 so that your code would look like the following:\n\n_ := workflow.GetVersion(ctx, "Step1", 2, 2)\nerr = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n\n\nNote that we have preserved the call to GetVersion(). There are two reasons to preserve this call:\n\n 1. This ensures that if there is a still running for an older version, it will fail here and not proceed.\n 2. If you need to make additional changes for Step1, such as changing ActivityD to ActivityE, you only need to update maxVersion from 2 to 3 and branch from there.\n\nYou only need to preserve the first call to GetVersion() for each changeID. All subsequent calls toGetVersion() with the same change ID are safe to remove. If necessary, you can remove the firstGetVersion() call, but you need to ensure the following:\n\n * All executions with an older version are completed.\n * You can no longer use Step1 for the changeID. If you need to make changes to that same part in the future, such as change from ActivityD to ActivityE, you would need to use a different changeID like Step1-fix2, and start minVersion from DefaultVersion again. The code would look like the following:\n\nv := workflow.GetVersion(ctx, "Step1-fix2", workflow.DefaultVersion, 1)\nif v == workflow.DefaultVersion {\n    err = workflow.ExecuteActivity(ctx, ActivityD, data).Get(ctx, &result1)\n} else {\n    err = workflow.ExecuteActivity(ctx, ActivityE, data).Get(ctx, &result1)\n}\n\n\nUpgrading a is straightforward if you don\'t need to preserve your currently running. You can simply terminate all of the currently running and suspend new ones from being created while you deploy the new version of your code, which does not use GetVersion(), and then resume creation. However, that is often not the case, and you need to take care of the currently running , so using GetVersion() to update your code is the method to use.\n\nHowever, if you want your currently running to proceed based on the current logic, but you want to ensure new are running on new logic, you can define your as a new WorkflowType, and change your start path (calls to StartWorkflow()) to start the new type.\n\n# Sanity checking\nThe Cadence client SDK performs a sanity check to help prevent obvious incompatible changes. The sanity check verifies whether a made in replay matches the recorded in history, in the same order. The is generated by calling any of the following methods:\n\n * workflow.ExecuteActivity()\n * workflow.ExecuteChildWorkflow()\n * workflow.NewTimer()\n * workflow.Sleep()\n * workflow.SideEffect()\n * workflow.RequestCancelWorkflow()\n * workflow.SignalExternalWorkflow()\n\nAdding, removing, or reordering any of the above methods triggers the sanity check and results in a non-deterministic error.\n\nThe sanity check does not perform a thorough check. For example, it does not check on the \'s input arguments or the timer duration. If the check is enforced on every property, then it becomes too restricted and harder to maintain the code. For example, if you move your code from one package to another package, that changes the ActivityType, which technically becomes a different. But, we don\'t want to fail on that change, so we only check the function name part of theActivityType.',normalizedContent:'# versioning\nthe definition code of a cadence must be deterministic because cadence uses sourcing to reconstruct the state by replaying the saved history data on the definition code. this means that any incompatible update to the definition code could cause a non-deterministic issue if not handled correctly.\n\n# workflow.getversion()\nconsider the following definition:\n\nfunc myworkflow(ctx workflow.context, data string) (string, error) {\n    ao := workflow.activityoptions{\n        scheduletostarttimeout: time.minute,\n        starttoclosetimeout:    time.minute,\n    }\n    ctx = workflow.withactivityoptions(ctx, ao)\n    var result1 string\n    err := workflow.executeactivity(ctx, activitya, data).get(ctx, &result1)\n    if err != nil {\n        return "", err\n    }\n    var result2 string\n    err = workflow.executeactivity(ctx, activityb, result1).get(ctx, &result2)\n    return result2, err\n}\n\n\nnow let\'s say we have replaced activitya with activityc, and deployed the updated code. if there is an existing that was started by the original version of the code, where activitya had already completed and the result was recorded to history, the new version of the code will pick up that and try to resume from there. however, the will fail because the new code expects a result for activityc from the history data, but instead it gets the result for activitya. this causes the to fail on the non-deterministic error.\n\nthus we use workflow.getversion().\n\nvar err error\nv := workflow.getversion(ctx, "step1", workflow.defaultversion, 1)\nif v == workflow.defaultversion {\n    err = workflow.executeactivity(ctx, activitya, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activityc, data).get(ctx, &result1)\n}\nif err != nil {\n    return "", err\n}\n\nvar result2 string\nerr = workflow.executeactivity(ctx, activityb, result1).get(ctx, &result2)\nreturn result2, err\n\n\nwhen workflow.getversion() is run for the new , it records a marker in the history so that all future calls to getversion for this change id--step 1 in the example--on this will always return the given version number, which is 1 in the example.\n\nif you make an additional change, such as replacing activityc with activityd, you need to add some additional code:\n\nv := workflow.getversion(ctx, "step1", workflow.defaultversion, 2)\nif v == workflow.defaultversion {\n    err = workflow.executeactivity(ctx, activitya, data).get(ctx, &result1)\n} else if v == 1 {\n    err = workflow.executeactivity(ctx, activityc, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n}\n\n\nnote that we have changed maxsupported from 1 to 2. a that had already passed thisgetversion() call before it was introduced will return defaultversion. a that was run with maxsupported set to 1, will return 1. new will return 2.\n\nafter you are sure that all of the prior to version 1 have completed, you can remove the code for that version. it should now look like the following:\n\nv := workflow.getversion(ctx, "step1", 1, 2)\nif v == 1 {\n    err = workflow.executeactivity(ctx, activityc, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n}\n\n\nyou\'ll note that minsupported has changed from defaultversion to 1. if an older version of the history is replayed on this code, it will fail because the minimum expected version is 1. after you are sure that all of the for version 1 have completed, then you can remove 1 so that your code would look like the following:\n\n_ := workflow.getversion(ctx, "step1", 2, 2)\nerr = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n\n\nnote that we have preserved the call to getversion(). there are two reasons to preserve this call:\n\n 1. this ensures that if there is a still running for an older version, it will fail here and not proceed.\n 2. if you need to make additional changes for step1, such as changing activityd to activitye, you only need to update maxversion from 2 to 3 and branch from there.\n\nyou only need to preserve the first call to getversion() for each changeid. all subsequent calls togetversion() with the same change id are safe to remove. if necessary, you can remove the firstgetversion() call, but you need to ensure the following:\n\n * all executions with an older version are completed.\n * you can no longer use step1 for the changeid. if you need to make changes to that same part in the future, such as change from activityd to activitye, you would need to use a different changeid like step1-fix2, and start minversion from defaultversion again. the code would look like the following:\n\nv := workflow.getversion(ctx, "step1-fix2", workflow.defaultversion, 1)\nif v == workflow.defaultversion {\n    err = workflow.executeactivity(ctx, activityd, data).get(ctx, &result1)\n} else {\n    err = workflow.executeactivity(ctx, activitye, data).get(ctx, &result1)\n}\n\n\nupgrading a is straightforward if you don\'t need to preserve your currently running. you can simply terminate all of the currently running and suspend new ones from being created while you deploy the new version of your code, which does not use getversion(), and then resume creation. however, that is often not the case, and you need to take care of the currently running , so using getversion() to update your code is the method to use.\n\nhowever, if you want your currently running to proceed based on the current logic, but you want to ensure new are running on new logic, you can define your as a new workflowtype, and change your start path (calls to startworkflow()) to start the new type.\n\n# sanity checking\nthe cadence client sdk performs a sanity check to help prevent obvious incompatible changes. the sanity check verifies whether a made in replay matches the recorded in history, in the same order. the is generated by calling any of the following methods:\n\n * workflow.executeactivity()\n * workflow.executechildworkflow()\n * workflow.newtimer()\n * workflow.sleep()\n * workflow.sideeffect()\n * workflow.requestcancelworkflow()\n * workflow.signalexternalworkflow()\n\nadding, removing, or reordering any of the above methods triggers the sanity check and results in a non-deterministic error.\n\nthe sanity check does not perform a thorough check. for example, it does not check on the \'s input arguments or the timer duration. if the check is enforced on every property, then it becomes too restricted and harder to maintain the code. for example, if you move your code from one package to another package, that changes the activitytype, which technically becomes a different. but, we don\'t want to fail on that change, so we only check the function name part of theactivitytype.',charsets:{}},{title:"Sessions",frontmatter:{layout:"default",title:"Sessions",permalink:"/docs/go-client/sessions",readingShow:"top"},regularPath:"/docs/05-go-client/15-sessions.html",relativePath:"docs/05-go-client/15-sessions.md",key:"v-389752bc",path:"/docs/go-client/sessions/",headers:[{level:2,title:"Use Cases",slug:"use-cases",normalizedTitle:"use cases",charIndex:252},{level:2,title:"Basic Usage",slug:"basic-usage",normalizedTitle:"basic usage",charIndex:833},{level:3,title:"Sample Code",slug:"sample-code",normalizedTitle:"sample code",charIndex:3528},{level:2,title:"Session Metadata",slug:"session-metadata",normalizedTitle:"session metadata",charIndex:4555},{level:2,title:"Concurrent Session Limitation",slug:"concurrent-session-limitation",normalizedTitle:"concurrent session limitation",charIndex:3054},{level:2,title:"Recreate Session",slug:"recreate-session",normalizedTitle:"recreate session",charIndex:5568},{level:2,title:"Q & A",slug:"q-a",normalizedTitle:"q &amp; a",charIndex:null},{level:3,title:"Is there a complete example?",slug:"is-there-a-complete-example",normalizedTitle:"is there a complete example?",charIndex:6227},{level:3,title:"What happens to my activity if the worker dies?",slug:"what-happens-to-my-activity-if-the-worker-dies",normalizedTitle:"what happens to my activity if the worker dies?",charIndex:6366},{level:3,title:"Is the concurrent session limitation per process or per host?",slug:"is-the-concurrent-session-limitation-per-process-or-per-host",normalizedTitle:"is the concurrent session limitation per process or per host?",charIndex:6572},{level:2,title:"Future Work",slug:"future-work",normalizedTitle:"future work",charIndex:6746}],headersStr:"Use Cases Basic Usage Sample Code Session Metadata Concurrent Session Limitation Recreate Session Q & A Is there a complete example? What happens to my activity if the worker dies? Is the concurrent session limitation per process or per host? Future Work",content:"# Sessions\nThe session framework provides a straightforward interface for scheduling multiple on a single without requiring you to manually specify the name. It also includes features like concurrent session limitation and worker failure detection.\n\n# Use Cases\n * File Processing: You may want to implement a that can download a file, process it, and then upload the modified version. If these three steps are implemented as three different , all of them should be executed by the same .\n   \n   \n * Machine Learning Model Training: Training a machine learning model typically involves three stages: download the data set, optimize the model, and upload the trained parameter. Since the models may consume a large amount of resources (GPU memory for example), the number of models processed on a host needs to be limited.\n   \n   \n\n# Basic Usage\nBefore using the session framework to write your code, you need to configure your to process sessions. To do that, set the EnableSessionWorker field of worker.Options to true when starting your .\n\nThe most important APIs provided by the session framework are workflow.CreateSession() and workflow.CompleteSession(). The basic idea is that all the executed within a session will be processed by the same and these two APIs allow you to create new sessions and close them after all finish executing.\n\nHere's a more detailed description of these two APIs:\n\ntype SessionOptions struct {\n    // ExecutionTimeout: required, no default.\n    //     Specifies the maximum amount of time the session can run.\n    ExecutionTimeout time.Duration\n\n    // CreationTimeout: required, no default.\n    //     Specifies how long session creation can take before returning an error.\n    CreationTimeout  time.Duration\n}\n\nfunc CreateSession(ctx Context, sessionOptions *SessionOptions) (Context, error)\n\n\nCreateSession() takes in workflow.Context, sessionOptions and returns a new context which contains metadata information of the created session (referred to as the session context below). When it's called, it will check the name specified in the ActivityOptions (or in the StartWorkflowOptions if the name is not specified in ActivityOptions), and create the session on one of the which is polling that .\n\nThe returned session context should be used to execute all belonging to the session. The context will be cancelled if the executing this session dies or CompleteSession() is called. When using the returned session context to execute , a workflow.ErrSessionFailed error may be returned if the session framework detects that the executing this session has died. The failure of your won't affect the state of the session, so you still need to handle the errors returned from your and call CompleteSession() if necessary.\n\nCreateSession() will return an error if the context passed in already contains an open session. If all the are currently busy and unable to handle new sessions, the framework will keep retrying until the CreationTimeout you specified in SessionOptions has passed before returning an error (check the Concurrent Session Limitation section for more details).\n\nfunc CompleteSession(ctx Context)\n\n\nCompleteSession() releases the resources reserved on the , so it's important to call it as soon as you no longer need the session. It will cancel the session context and therefore all the using that session context. Note that it's safe to call CompleteSession() on a failed session, meaning that you can call it from a defer function after the session is successfully created.\n\n# Sample Code\nfunc FileProcessingWorkflow(ctx workflow.Context, fileID string) (err error) {\n    ao := workflow.ActivityOptions{\n        ScheduleToStartTimeout: time.Second * 5,\n        StartToCloseTimeout:    time.Minute,\n    }\n    ctx = workflow.WithActivityOptions(ctx, ao)\n\n    so := &workflow.SessionOptions{\n        CreationTimeout:  time.Minute,\n        ExecutionTimeout: time.Minute,\n    }\n    sessionCtx, err := workflow.CreateSession(ctx, so)\n    if err != nil {\n        return err\n    }\n    defer workflow.CompleteSession(sessionCtx)\n\n    var fInfo *fileInfo\n    err = workflow.ExecuteActivity(sessionCtx, downloadFileActivityName, fileID).Get(sessionCtx, &fInfo)\n    if err != nil {\n        return err\n    }\n\n    var fInfoProcessed *fileInfo\n    err = workflow.ExecuteActivity(sessionCtx, processFileActivityName, *fInfo).Get(sessionCtx, &fInfoProcessed)\n    if err != nil {\n        return err\n    }\n\n    return workflow.ExecuteActivity(sessionCtx, uploadFileActivityName, *fInfoProcessed).Get(sessionCtx, nil)\n}\n\n\n# Session Metadata\ntype SessionInfo struct {\n    // A unique ID for the session\n    SessionID         string\n\n    // The hostname of the worker that is executing the session\n    HostName          string\n\n    // ... other unexported fields\n}\n\nfunc GetSessionInfo(ctx Context) *SessionInfo\n\n\nThe session context also stores some session metadata, which can be retrieved by the GetSessionInfo() API. If the context passed in doesn't contain any session metadata, this API will return a nil pointer.\n\n# Concurrent Session Limitation\nTo limit the number of concurrent sessions running on a , set the MaxConcurrentSessionExecutionSize field of worker.Options to the desired value. By default this field is set to a very large value, so there's no need to manually set it if no limitation is needed.\n\nIf a hits this limitation, it won't accept any new CreateSession() requests until one of the existing sessions is completed. CreateSession() will return an error if the session can't be created within CreationTimeout.\n\n# Recreate Session\nFor long-running sessions, you may want to use the ContinueAsNew feature to split the into multiple runs when all need to be executed by the same . The RecreateSession() API is designed for such a use case.\n\nfunc RecreateSession(ctx Context, recreateToken []byte, sessionOptions *SessionOptions) (Context, error)\n\n\nIts usage is the same as CreateSession() except that it also takes in a recreateToken, which is needed to create a new session on the same as the previous one. You can get the token by calling the GetRecreateToken() method of the SessionInfo object.\n\ntoken := workflow.GetSessionInfo(sessionCtx).GetRecreateToken()\n\n\n# Q & A\n# Is there a complete example?\nYes, the file processing example in the cadence-sample repo has been updated to use the session framework.\n\n# What happens to my activity if the worker dies?\nIf your has already been scheduled, it will be cancelled. If not, you will get a workflow.ErrSessionFailed error when you call workflow.ExecuteActivity().\n\n# Is the concurrent session limitation per process or per host?\nIt's per process, so make sure there's only one process running on the host if you plan to use that feature.\n\n# Future Work\n * Support automatic session re-establishingRight now a session is considered failed if the process dies. However, for some use cases, you may only care whether host is alive or not. For these uses cases, the session should be automatically re-established if the process is restarted.\n   \n   \n * Support fine-grained concurrent session limitationThe current implementation assumes that all sessions are consuming the same type of resource and there's only one global limitation. Our plan is to allow you to specify what type of resource your session will consume and enforce different limitations on different types of resources.",normalizedContent:"# sessions\nthe session framework provides a straightforward interface for scheduling multiple on a single without requiring you to manually specify the name. it also includes features like concurrent session limitation and worker failure detection.\n\n# use cases\n * file processing: you may want to implement a that can download a file, process it, and then upload the modified version. if these three steps are implemented as three different , all of them should be executed by the same .\n   \n   \n * machine learning model training: training a machine learning model typically involves three stages: download the data set, optimize the model, and upload the trained parameter. since the models may consume a large amount of resources (gpu memory for example), the number of models processed on a host needs to be limited.\n   \n   \n\n# basic usage\nbefore using the session framework to write your code, you need to configure your to process sessions. to do that, set the enablesessionworker field of worker.options to true when starting your .\n\nthe most important apis provided by the session framework are workflow.createsession() and workflow.completesession(). the basic idea is that all the executed within a session will be processed by the same and these two apis allow you to create new sessions and close them after all finish executing.\n\nhere's a more detailed description of these two apis:\n\ntype sessionoptions struct {\n    // executiontimeout: required, no default.\n    //     specifies the maximum amount of time the session can run.\n    executiontimeout time.duration\n\n    // creationtimeout: required, no default.\n    //     specifies how long session creation can take before returning an error.\n    creationtimeout  time.duration\n}\n\nfunc createsession(ctx context, sessionoptions *sessionoptions) (context, error)\n\n\ncreatesession() takes in workflow.context, sessionoptions and returns a new context which contains metadata information of the created session (referred to as the session context below). when it's called, it will check the name specified in the activityoptions (or in the startworkflowoptions if the name is not specified in activityoptions), and create the session on one of the which is polling that .\n\nthe returned session context should be used to execute all belonging to the session. the context will be cancelled if the executing this session dies or completesession() is called. when using the returned session context to execute , a workflow.errsessionfailed error may be returned if the session framework detects that the executing this session has died. the failure of your won't affect the state of the session, so you still need to handle the errors returned from your and call completesession() if necessary.\n\ncreatesession() will return an error if the context passed in already contains an open session. if all the are currently busy and unable to handle new sessions, the framework will keep retrying until the creationtimeout you specified in sessionoptions has passed before returning an error (check the concurrent session limitation section for more details).\n\nfunc completesession(ctx context)\n\n\ncompletesession() releases the resources reserved on the , so it's important to call it as soon as you no longer need the session. it will cancel the session context and therefore all the using that session context. note that it's safe to call completesession() on a failed session, meaning that you can call it from a defer function after the session is successfully created.\n\n# sample code\nfunc fileprocessingworkflow(ctx workflow.context, fileid string) (err error) {\n    ao := workflow.activityoptions{\n        scheduletostarttimeout: time.second * 5,\n        starttoclosetimeout:    time.minute,\n    }\n    ctx = workflow.withactivityoptions(ctx, ao)\n\n    so := &workflow.sessionoptions{\n        creationtimeout:  time.minute,\n        executiontimeout: time.minute,\n    }\n    sessionctx, err := workflow.createsession(ctx, so)\n    if err != nil {\n        return err\n    }\n    defer workflow.completesession(sessionctx)\n\n    var finfo *fileinfo\n    err = workflow.executeactivity(sessionctx, downloadfileactivityname, fileid).get(sessionctx, &finfo)\n    if err != nil {\n        return err\n    }\n\n    var finfoprocessed *fileinfo\n    err = workflow.executeactivity(sessionctx, processfileactivityname, *finfo).get(sessionctx, &finfoprocessed)\n    if err != nil {\n        return err\n    }\n\n    return workflow.executeactivity(sessionctx, uploadfileactivityname, *finfoprocessed).get(sessionctx, nil)\n}\n\n\n# session metadata\ntype sessioninfo struct {\n    // a unique id for the session\n    sessionid         string\n\n    // the hostname of the worker that is executing the session\n    hostname          string\n\n    // ... other unexported fields\n}\n\nfunc getsessioninfo(ctx context) *sessioninfo\n\n\nthe session context also stores some session metadata, which can be retrieved by the getsessioninfo() api. if the context passed in doesn't contain any session metadata, this api will return a nil pointer.\n\n# concurrent session limitation\nto limit the number of concurrent sessions running on a , set the maxconcurrentsessionexecutionsize field of worker.options to the desired value. by default this field is set to a very large value, so there's no need to manually set it if no limitation is needed.\n\nif a hits this limitation, it won't accept any new createsession() requests until one of the existing sessions is completed. createsession() will return an error if the session can't be created within creationtimeout.\n\n# recreate session\nfor long-running sessions, you may want to use the continueasnew feature to split the into multiple runs when all need to be executed by the same . the recreatesession() api is designed for such a use case.\n\nfunc recreatesession(ctx context, recreatetoken []byte, sessionoptions *sessionoptions) (context, error)\n\n\nits usage is the same as createsession() except that it also takes in a recreatetoken, which is needed to create a new session on the same as the previous one. you can get the token by calling the getrecreatetoken() method of the sessioninfo object.\n\ntoken := workflow.getsessioninfo(sessionctx).getrecreatetoken()\n\n\n# q & a\n# is there a complete example?\nyes, the file processing example in the cadence-sample repo has been updated to use the session framework.\n\n# what happens to my activity if the worker dies?\nif your has already been scheduled, it will be cancelled. if not, you will get a workflow.errsessionfailed error when you call workflow.executeactivity().\n\n# is the concurrent session limitation per process or per host?\nit's per process, so make sure there's only one process running on the host if you plan to use that feature.\n\n# future work\n * support automatic session re-establishingright now a session is considered failed if the process dies. however, for some use cases, you may only care whether host is alive or not. for these uses cases, the session should be automatically re-established if the process is restarted.\n   \n   \n * support fine-grained concurrent session limitationthe current implementation assumes that all sessions are consuming the same type of resource and there's only one global limitation. our plan is to allow you to specify what type of resource your session will consume and enforce different limitations on different types of resources.",charsets:{}},{title:"Distributed CRON",frontmatter:{layout:"default",title:"Distributed CRON",permalink:"/docs/go-client/distributed-cron",readingShow:"top"},regularPath:"/docs/05-go-client/16-distributed-cron.html",relativePath:"docs/05-go-client/16-distributed-cron.md",key:"v-0c11d262",path:"/docs/go-client/distributed-cron/",headers:[{level:2,title:"Convert existing cron workflow",slug:"convert-existing-cron-workflow",normalizedTitle:"convert existing cron workflow",charIndex:1992},{level:2,title:"Retrieve last successful result",slug:"retrieve-last-successful-result",normalizedTitle:"retrieve last successful result",charIndex:2451}],headersStr:"Convert existing cron workflow Retrieve last successful result",content:"# Distributed CRON\nIt is relatively straightforward to turn any Cadence into a Cron . All you need is to supply a cron schedule when starting the using the CronSchedule parameter ofStartWorkflowOptions.\n\nYou can also start a using the Cadence with an optional cron schedule using the --cron argument.\n\nFor with CronSchedule:\n\n * Cron schedule is based on UTC time. For example cron schedule \"15 8 * * *\" will run daily at 8:15am UTC.\n * If a failed and a RetryPolicy is supplied to the StartWorkflowOptions as well, the will retry based on the RetryPolicy. While the is retrying, the server will not schedule the next cron run.\n * Cadence server only schedules the next cron run after the current run is completed. If the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * Cron will not stop until they are terminated or cancelled.\n\nCadence supports the standard cron spec:\n\n// CronSchedule - Optional cron schedule for workflow. If a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. The scheduling will be based on UTC time. The schedule for next run only happen\n// after the current run is completed/failed/timeout. If a RetryPolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. While the workflow is retrying, it won't\n// schedule its next run. If next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. Cron workflow will not stop until it is terminated or cancelled (by returning cadence.CanceledError).\n// The cron spec is as following:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\nCronSchedule string\n\n\nThe crontab guru site is useful for testing your cron expressions.\n\n# Convert existing cron workflow\nBefore CronSchedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then returnContinueAsNew. One problem with that implementation is that if the fails or times out, the cron would stop.\n\nTo convert those to make use of Cadence CronSchedule, all you need is to remove the delay timer and return without usingContinueAsNew. Then start the with the desired CronSchedule.\n\n# Retrieve last successful result\nSometimes it is useful to obtain the progress of previous successful runs. This is supported by two new APIs in the client library:HasLastCompletionResult and GetLastCompletionResult. Below is an example of how to use this in Go:\n\nfunc CronWorkflow(ctx workflow.Context) (CronResult, error) {\n    startTimestamp := time.Time{} // By default start from 0 time.\n    if workflow.HasLastCompletionResult(ctx) {\n        var progress CronResult\n        if err := workflow.GetLastCompletionResult(ctx, &progress); err == nil {\n            startTimestamp = progress.LastSyncTimestamp\n        }\n    }\n    endTimestamp := workflow.Now(ctx)\n\n    // Process work between startTimestamp (exclusive), endTimestamp (inclusive).\n    // Business logic implementation goes here.\n\n    result := CronResult{LastSyncTimestamp: endTimestamp}\n    return result, nil\n}\n\n\nNote that this works even if one of the cron schedule runs failed. The next schedule will still get the last successful result if it ever successfully completed at least once. For example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day's run using these APIs.",normalizedContent:"# distributed cron\nit is relatively straightforward to turn any cadence into a cron . all you need is to supply a cron schedule when starting the using the cronschedule parameter ofstartworkflowoptions.\n\nyou can also start a using the cadence with an optional cron schedule using the --cron argument.\n\nfor with cronschedule:\n\n * cron schedule is based on utc time. for example cron schedule \"15 8 * * *\" will run daily at 8:15am utc.\n * if a failed and a retrypolicy is supplied to the startworkflowoptions as well, the will retry based on the retrypolicy. while the is retrying, the server will not schedule the next cron run.\n * cadence server only schedules the next cron run after the current run is completed. if the next schedule is due while a is running (or retrying), then it will skip that schedule.\n * cron will not stop until they are terminated or cancelled.\n\ncadence supports the standard cron spec:\n\n// cronschedule - optional cron schedule for workflow. if a cron schedule is specified, the workflow will run\n// as a cron based on the schedule. the scheduling will be based on utc time. the schedule for next run only happen\n// after the current run is completed/failed/timeout. if a retrypolicy is also supplied, and the workflow failed\n// or timed out, the workflow will be retried based on the retry policy. while the workflow is retrying, it won't\n// schedule its next run. if next schedule is due while the workflow is running (or retrying), then it will skip that\n// schedule. cron workflow will not stop until it is terminated or cancelled (by returning cadence.cancelederror).\n// the cron spec is as following:\n// ┌───────────── minute (0 - 59)\n// │ ┌───────────── hour (0 - 23)\n// │ │ ┌───────────── day of the month (1 - 31)\n// │ │ │ ┌───────────── month (1 - 12)\n// │ │ │ │ ┌───────────── day of the week (0 - 6) (sunday to saturday)\n// │ │ │ │ │\n// │ │ │ │ │\n// * * * * *\ncronschedule string\n\n\nthe crontab guru site is useful for testing your cron expressions.\n\n# convert existing cron workflow\nbefore cronschedule was available, the previous approach to implementing cron was to use a delay timer as the last step and then returncontinueasnew. one problem with that implementation is that if the fails or times out, the cron would stop.\n\nto convert those to make use of cadence cronschedule, all you need is to remove the delay timer and return without usingcontinueasnew. then start the with the desired cronschedule.\n\n# retrieve last successful result\nsometimes it is useful to obtain the progress of previous successful runs. this is supported by two new apis in the client library:haslastcompletionresult and getlastcompletionresult. below is an example of how to use this in go:\n\nfunc cronworkflow(ctx workflow.context) (cronresult, error) {\n    starttimestamp := time.time{} // by default start from 0 time.\n    if workflow.haslastcompletionresult(ctx) {\n        var progress cronresult\n        if err := workflow.getlastcompletionresult(ctx, &progress); err == nil {\n            starttimestamp = progress.lastsynctimestamp\n        }\n    }\n    endtimestamp := workflow.now(ctx)\n\n    // process work between starttimestamp (exclusive), endtimestamp (inclusive).\n    // business logic implementation goes here.\n\n    result := cronresult{lastsynctimestamp: endtimestamp}\n    return result, nil\n}\n\n\nnote that this works even if one of the cron schedule runs failed. the next schedule will still get the last successful result if it ever successfully completed at least once. for example, for a daily cron , if the first day run succeeds and the second day fails, then the third day run will still get the result from first day's run using these apis.",charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/go-client",readingShow:"top"},regularPath:"/docs/05-go-client/",relativePath:"docs/05-go-client/index.md",key:"v-2d3e7cdb",path:"/docs/go-client/",headers:[{level:2,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:14},{level:2,title:"Links",slug:"links",normalizedTitle:"links",charIndex:708}],headersStr:"Overview Links",content:"# Go client\n# Overview\nGo client attempts to follow Go language conventions. The conversion of a Go program to the fault-oblivious function is expected to be pretty mechanical.\n\nCadence requires determinism of the code. It supports deterministic execution of the multithreaded code and constructs like select that are non-deterministic by Go design. The Cadence solution is to provide corresponding constructs in the form of interfaces that have similar capability but support deterministic execution.\n\nFor example, instead of native Go channels, code must use the workflow.Channel interface. Instead of select, the workflow.Selector interface must be used.\n\nFor more information, see Creating Workflows.\n\n# Links\n * GitHub project: https://github.com/uber-go/cadence-client\n * Samples: https://github.com/samarabbas/cadence-samples\n * GoDoc documentation: https://godoc.org/go.uber.org/cadence",normalizedContent:"# go client\n# overview\ngo client attempts to follow go language conventions. the conversion of a go program to the fault-oblivious function is expected to be pretty mechanical.\n\ncadence requires determinism of the code. it supports deterministic execution of the multithreaded code and constructs like select that are non-deterministic by go design. the cadence solution is to provide corresponding constructs in the form of interfaces that have similar capability but support deterministic execution.\n\nfor example, instead of native go channels, code must use the workflow.channel interface. instead of select, the workflow.selector interface must be used.\n\nfor more information, see creating workflows.\n\n# links\n * github project: https://github.com/uber-go/cadence-client\n * samples: https://github.com/samarabbas/cadence-samples\n * godoc documentation: https://godoc.org/go.uber.org/cadence",charsets:{}},{title:"Tracing and context propagation",frontmatter:{layout:"default",title:"Tracing and context propagation",permalink:"/docs/go-client/tracing",readingShow:"top"},regularPath:"/docs/05-go-client/17-tracing.html",relativePath:"docs/05-go-client/17-tracing.md",key:"v-a139e6dc",path:"/docs/go-client/tracing/",headers:[{level:2,title:"Tracing",slug:"tracing",normalizedTitle:"tracing",charIndex:2},{level:2,title:"Context Propagation",slug:"context-propagation",normalizedTitle:"context propagation",charIndex:645},{level:3,title:"Server-Side Headers Support",slug:"server-side-headers-support",normalizedTitle:"server-side headers support",charIndex:1147},{level:3,title:"Context Propagators",slug:"context-propagators",normalizedTitle:"context propagators",charIndex:2055},{level:2,title:"Q & A",slug:"q-a",normalizedTitle:"q &amp; a",charIndex:null},{level:3,title:"Is there a complete example?",slug:"is-there-a-complete-example",normalizedTitle:"is there a complete example?",charIndex:2995},{level:3,title:"Can I configure multiple context propagators?",slug:"can-i-configure-multiple-context-propagators",normalizedTitle:"can i configure multiple context propagators?",charIndex:3159}],headersStr:"Tracing Context Propagation Server-Side Headers Support Context Propagators Q & A Is there a complete example? Can I configure multiple context propagators?",content:"# Tracing and context propagation\n# Tracing\nThe Go client provides distributed tracing support through OpenTracing. Tracing can be configured by providing an opentracing.Tracerimplementation in ClientOptionsand WorkerOptions during client and instantiation, respectively. Tracing allows you to view the call graph of a along with its , child etc. For more details on how to configure and leverage tracing, see the OpenTracing documentation. The OpenTracing support has been validated using Jaeger, but other implementations mentioned here should also work. Tracing support utilizes generic context propagation support provided by the client.\n\n# Context Propagation\nWe provide a standard way to propagate custom context across a .ClientOptions and WorkerOptionsallow configuring a context propagator. The context propagator extracts and passes on information present in the context.Contextand workflow.Context objects across the . Once a context propagator is configured, you should be able to access the required values in the context objects as you would normally do in Go. For a sample, the Go client implements a tracing context propagator.\n\n# Server-Side Headers Support\nOn the server side, Cadence provides a mechanism to propagate what it calls headers across different transitions.\n\nstruct Header {\n    10: optional map<string, binary> fields\n}\n\n\nThe client leverages this to pass around selected context information. HeaderReaderand HeaderWriter are interfaces that allow reading and writing to the Cadence server headers. The client already provides implementationsfor these. HeaderWriter sets a field in the header. Headers is a map, so setting a value for the the same key multiple times will overwrite the previous values. HeaderReader iterates through the headers map and runs the provided handler function on each key/value pair, allowing you to deal with the fields you are interested in.\n\ntype HeaderWriter interface {\n    Set(string, []byte)\n}\n\ntype HeaderReader interface {\n    ForEachKey(handler func(string, []byte) error) error\n}\n\n\n# Context Propagators\nContext propagators require implementing the following four methods to propagate selected context across a workflow:\n\n * Inject is meant to pick out the context keys of interest from a Go context.Context object and write that into the headers using the HeaderWriter interface\n * InjectFromWorkflow is the same as above, but operates on a workflow.Context object\n * Extract reads the headers and places the information of interest back into the context.Context object\n * ExtractToWorkflow is the same as above, but operates on a workflow.Context object\n\nThe tracing context propagatorshows a sample implementation of context propagation.\n\ntype ContextPropagator interface {\n    Inject(context.Context, HeaderWriter) error\n\n    Extract(context.Context, HeaderReader) (context.Context, error)\n\n    InjectFromWorkflow(Context, HeaderWriter) error\n\n    ExtractToWorkflow(Context, HeaderReader) (Context, error)\n}\n\n\n# Q & A\n# Is there a complete example?\nThe context propagation sampleconfigures a custom context propagator and shows context propagation of custom keys across a and an .\n\n# Can I configure multiple context propagators?\nYes, we recommended that you configure multiple context propagators with each propagator meant to propagate a particular type of context.",normalizedContent:"# tracing and context propagation\n# tracing\nthe go client provides distributed tracing support through opentracing. tracing can be configured by providing an opentracing.tracerimplementation in clientoptionsand workeroptions during client and instantiation, respectively. tracing allows you to view the call graph of a along with its , child etc. for more details on how to configure and leverage tracing, see the opentracing documentation. the opentracing support has been validated using jaeger, but other implementations mentioned here should also work. tracing support utilizes generic context propagation support provided by the client.\n\n# context propagation\nwe provide a standard way to propagate custom context across a .clientoptions and workeroptionsallow configuring a context propagator. the context propagator extracts and passes on information present in the context.contextand workflow.context objects across the . once a context propagator is configured, you should be able to access the required values in the context objects as you would normally do in go. for a sample, the go client implements a tracing context propagator.\n\n# server-side headers support\non the server side, cadence provides a mechanism to propagate what it calls headers across different transitions.\n\nstruct header {\n    10: optional map<string, binary> fields\n}\n\n\nthe client leverages this to pass around selected context information. headerreaderand headerwriter are interfaces that allow reading and writing to the cadence server headers. the client already provides implementationsfor these. headerwriter sets a field in the header. headers is a map, so setting a value for the the same key multiple times will overwrite the previous values. headerreader iterates through the headers map and runs the provided handler function on each key/value pair, allowing you to deal with the fields you are interested in.\n\ntype headerwriter interface {\n    set(string, []byte)\n}\n\ntype headerreader interface {\n    foreachkey(handler func(string, []byte) error) error\n}\n\n\n# context propagators\ncontext propagators require implementing the following four methods to propagate selected context across a workflow:\n\n * inject is meant to pick out the context keys of interest from a go context.context object and write that into the headers using the headerwriter interface\n * injectfromworkflow is the same as above, but operates on a workflow.context object\n * extract reads the headers and places the information of interest back into the context.context object\n * extracttoworkflow is the same as above, but operates on a workflow.context object\n\nthe tracing context propagatorshows a sample implementation of context propagation.\n\ntype contextpropagator interface {\n    inject(context.context, headerwriter) error\n\n    extract(context.context, headerreader) (context.context, error)\n\n    injectfromworkflow(context, headerwriter) error\n\n    extracttoworkflow(context, headerreader) (context, error)\n}\n\n\n# q & a\n# is there a complete example?\nthe context propagation sampleconfigures a custom context propagator and shows context propagation of custom keys across a and an .\n\n# can i configure multiple context propagators?\nyes, we recommended that you configure multiple context propagators with each propagator meant to propagate a particular type of context.",charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",permalink:"/docs/cli",readingShow:"top"},regularPath:"/docs/06-cli/",relativePath:"docs/06-cli/index.md",key:"v-2dfd6d7b",path:"/docs/cli/",headers:[{level:2,title:"Using the CLI",slug:"using-the-cli",normalizedTitle:"using the cli",charIndex:234},{level:2,title:"Environment variables",slug:"environment-variables",normalizedTitle:"environment variables",charIndex:1088},{level:2,title:"Quick Start",slug:"quick-start",normalizedTitle:"quick start",charIndex:1367},{level:3,title:"Domain operation examples",slug:"domain-operation-examples",normalizedTitle:"domain operation examples",charIndex:1737},{level:3,title:"Workflow operation examples",slug:"workflow-operation-examples",normalizedTitle:"workflow operation examples",charIndex:2038}],headersStr:"Using the CLI Environment variables Quick Start Domain operation examples Workflow operation examples",content:'# Command Line Interface\nThe Cadence is a command-line tool you can use to perform various on a Cadence server. It can perform operations such as register, update, and describe as well as operations like start, show history, and .\n\n# Using the CLI\nThe Cadence can be used directly from the Docker Hub image ubercadence/cli or by building the tool locally.\n\nExample of using the docker image to describe a \n\ndocker run --rm ubercadence/cli:master --domain samples-domain domain describe\n\n\nOn Docker versions 18.03 and later, you may get a "connection refused" error. You can work around this by setting the host to "host.docker.internal" (see here for more info).\n\ndocker run --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain describe\n\n\nTo build the tool locally, clone the Cadence server repo and runmake bins. This produces an executable called cadence. With a local build, the same command to describe a would look like this:\n\n./cadence --domain samples-domain domain describe\n\n\nThe example commands below will use ./cadence for brevity.\n\n# Environment variables\nSetting environment variables for repeated parameters can shorten the commands.\n\n * CADENCE_CLI_ADDRESS - host:port for Cadence frontend service, the default is for the local server\n * CADENCE_CLI_DOMAIN - default , so you don\'t need to specify --domain\n\n# Quick Start\nRun ./cadence for help on top level commands and global options Run ./cadence domain for help on operations Run ./cadence workflow for help on operations Run ./cadence tasklist for help on tasklist operations (./cadence help, ./cadence help [domain|workflow] will also print help messages)\n\nNote: make sure you have a Cadence server running before using \n\n# Domain operation examples\n * Register a new named "samples-domain":\n\n./cadence --domain samples-domain domain register --global_domain false\n# OR using short alias\n./cadence --do samples-domain d re --gd false\n\n\n * View "samples-domain" details:\n\n./cadence --domain samples-domain domain describe\n\n\n# Workflow operation examples\nThe following examples assume the CADENCE_CLI_DOMAIN environment variable is set.\n\n# Run workflow\nStart a and see its progress. This command doesn\'t finish until completes.\n\n./cadence workflow run --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow run\n./cadence workflow run -h\n\n\nBrief explanation: To run a , the user must specify the following:\n\n 1. Tasklist name (--tl)\n 2. Workflow type (--wt)\n 3. Execution start to close timeout in seconds (--et)\n 4. Input in JSON format (--i) (optional)\n\ns example uses this cadence-samples workflowand takes a string as input with the -i \'"cadence"\' parameter. Single quotes (\'\') are used to wrap input as JSON.\n\nNote: You need to start the so that the can make progress. (Run make && ./bin/helloworld -m worker in cadence-samples to start the )\n\n# Show running workers of a tasklist\n./cadence tasklist desc --tl helloWorldGroup\n\n\n# Start workflow\n./cadence workflow start --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow start\n./cadence workflow start -h\n\n# for a workflow with multiple inputs, separate each json with space/newline like\n./cadence workflow start --tl helloWorldGroup --wt main.WorkflowWith3Args --et 60 -i \'"your_input_string" 123 {"Name":"my-string", "Age":12345}\'\n\n\nThe start command is similar to the run command, but immediately returns the workflow_id and run_id after starting the . Use the show command to view the \'s history/progress.\n\n# Reuse the same workflow id when starting/running a workflow\nUse option --workflowidreusepolicy or --wrp to configure the reuse policy.Option 0 AllowDuplicateFailedOnly: Allow starting a using the same when a with the same is not already running and the last execution close state is one of [terminated, cancelled, timedout, failed].Option 1 AllowDuplicate: Allow starting a using the same when a with the same is not already running.Option 2 RejectDuplicate: Do not allow starting a using the same as a previous .\n\n# use AllowDuplicateFailedOnly option to start a workflow\n./cadence workflow start --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 0\n\n# use AllowDuplicate option to run a workflow\n./cadence workflow run --tl helloWorldGroup --wt main.Workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 1\n\n\n# Start a workflow with a memo\nMemos are immutable key/value pairs that can be attached to a run when starting the . These are visible when listing . More information on memos can be foundhere.\n\ncadence wf start -tl helloWorldGroup -wt main.Workflow -et 60 -i \'"cadence"\' -memo_key ‘“Service” “Env” “Instance”’ -memo ‘“serverName1” “test” 5’\n\n\n# Show workflow history\n./cadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\n./cadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest run history of that workflow_id\n./cadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\n./cadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# Show workflow execution information\n./cadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\n./cadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest workflow execution of that workflow_id\n./cadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\n./cadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# List closed or open workflow executions\n./cadence workflow list\n\n# default will only show one page, to view more items, use --more flag\n./cadence workflow list -m\n\n\nUse --query to list with SQL like \n\n./cadence workflow list --query "WorkflowType=\'main.SampleParentWorkflow\' AND CloseTime = missing "\n\n\nThis will return all open with workflowType as "main.SampleParentWorkflow".\n\n# Query workflow execution\n# use custom query type\n./cadence workflow query -w <wid> -r <rid> --qt <query-type>\n\n# use build-in query type "__stack_trace" which is supported by Cadence client library\n./cadence workflow query -w <wid> -r <rid> --qt __stack_trace\n# a shortcut to query using __stack_trace is (without --qt flag)\n./cadence workflow stack -w <wid> -r <rid>\n\n\n# Signal, cancel, terminate workflow\n# signal\n./cadence workflow signal -w <wid> -r <rid> -n <signal-name> -i \'"signal-value"\'\n\n# cancel\n./cadence workflow cancel -w <wid> -r <rid>\n\n# terminate\n./cadence workflow terminate -w <wid> -r <rid> --reason\n\n\nTerminating a running will record a WorkflowExecutionTerminated as the closing in the history. No more will be scheduled for a terminated . Canceling a running will record a WorkflowExecutionCancelRequested in the history, and a new will be scheduled. The has a chance to do some clean up work after cancellation.\n\n# Signal, cancel, terminate workflows as a batch job\nBatch job is based on List Workflow Query(--query). It supports , cancel and terminate as batch job type. For terminating as batch job, it will terminte the children recursively.\n\nStart a batch job(using as batch type):\n\ncadence --do samples-domain wf batch start --query "WorkflowType=\'main.SampleParentWorkflow\' AND CloseTime=missing" --reason "test" --bt signal --sig testname\nThis batch job will be operating on 5 workflows.\nPlease confirm[Yes/No]:yes\n{\n    "jobID": "<batch-job-id>",\n    "msg": "batch job is started"\n}\n\n\n\nYou need to remember the JobID or use List command to get all your batch jobs:\n\ncadence --do samples-domain wf batch list\n\n\nDescribe the progress of a batch job:\n\ncadence --do samples-domain wf batch desc -jid <batch-job-id>\n\n\nTerminate a batch job:\n\ncadence --do samples-domain wf batch terminate -jid <batch-job-id>\n\n\nNote that the operation performed by a batch will not be rolled back by terminating the batch. However, you can use reset to rollback your .\n\n# Restart, reset workflow\nThe Reset command allows resetting a to a particular point and continue running from there. There are a lot of use cases:\n\n * Rerun a failed from the beginning with the same start parameters.\n * Rerun a failed from the failing point without losing the achieved progress(history).\n * After deploying new code, reset an open to let the run to different flows.\n\nYou can reset to some predefined types:\n\n./cadence workflow reset -w <wid> -r <rid> --reset_type <reset_type> --reason "some_reason"\n\n\n * FirstDecisionCompleted: reset to the beginning of the history.\n * LastDecisionCompleted: reset to the end of the history.\n * LastContinuedAsNew: reset to the end of the history for the previous run.\n\nIf you are familiar with the Cadence history , You can also reset to any finish by using:\n\n./cadence workflow reset -w <wid> -r <rid> --event_id <decision_finish_event_id> --reason "some_reason"\n\n\nSome things to note:\n\n * When reset, a new run will be kicked off with the same workflowID. But if there is a running execution for the workflow(workflowID), the current run will be terminated.\n * decision_finish_event_id is the ID of of the type: DecisionTaskComplete/DecisionTaskFailed/DecisionTaskTimeout.\n * To restart a from the beginning, reset to the first finish .\n\nTo reset multiple , you can use batch reset command:\n\n./cadence workflow reset-batch --input_file <file_of_workflows_to_reset> --reset_type <reset_type> --reason "some_reason"\n\n\n# Recovery from bad deployment -- auto-reset workflow\nIf a bad deployment lets a run into a wrong state, you might want to reset the to the point that the bad deployment started to run. But usually it is not easy to find out all the impacted, and every reset point for each . In this case, auto-reset will automatically reset all the given a bad deployment identifier.\n\nLet\'s get familiar with some concepts. Each deployment will have an identifier, we call it "Binary Checksum" as it is usually generated by the md5sum of a binary file. For a , each binary checksum will be associated with an auto-reset point, which contains a runID, an eventID, and the created_time that binary/deployment made the first for the .\n\nTo find out which binary checksum of the bad deployment to reset, you should be aware of at least one running into a bad state. Use the describe command with --reset_points_only option to show all the reset points:\n\n./cadence wf desc -w <WorkflowID>  --reset_points_only\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n|         BINARY CHECKSUM          |          CREATE TIME           |                RUNID                 | EVENTID |\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n| c84c5afa552613a83294793f4e664a7f | 2019-05-24 10:01:00.398455019  | 2dd29ab7-2dd8-4668-83e0-89cae261cfb1 |       4 |\n| aae748fdc557a3f873adbe1dd066713f | 2019-05-24 11:01:00.067691445  | d42d21b8-2adb-4313-b069-3837d44d6ce6 |       4 |\n...\n...\n\n\nThen use this command to tell Cadence to auto-reset all impacted by the bad deployment. The command will store the bad binary checksum into info and trigger a process to reset all your .\n\n./cadence --do <YourDomainName> domain update --add_bad_binary aae748fdc557a3f873adbe1dd066713f  --reason "rollback bad deployment"\n\n\nAs you add the bad binary checksum to your , Cadence will not dispatch any to the bad binary. So make sure that you have rolled back to a good deployment(or roll out new bits with bug fixes). Otherwise your can\'t make any progress after auto-reset.',normalizedContent:'# command line interface\nthe cadence is a command-line tool you can use to perform various on a cadence server. it can perform operations such as register, update, and describe as well as operations like start, show history, and .\n\n# using the cli\nthe cadence can be used directly from the docker hub image ubercadence/cli or by building the tool locally.\n\nexample of using the docker image to describe a \n\ndocker run --rm ubercadence/cli:master --domain samples-domain domain describe\n\n\non docker versions 18.03 and later, you may get a "connection refused" error. you can work around this by setting the host to "host.docker.internal" (see here for more info).\n\ndocker run --rm ubercadence/cli:master --address host.docker.internal:7933 --domain samples-domain domain describe\n\n\nto build the tool locally, clone the cadence server repo and runmake bins. this produces an executable called cadence. with a local build, the same command to describe a would look like this:\n\n./cadence --domain samples-domain domain describe\n\n\nthe example commands below will use ./cadence for brevity.\n\n# environment variables\nsetting environment variables for repeated parameters can shorten the commands.\n\n * cadence_cli_address - host:port for cadence frontend service, the default is for the local server\n * cadence_cli_domain - default , so you don\'t need to specify --domain\n\n# quick start\nrun ./cadence for help on top level commands and global options run ./cadence domain for help on operations run ./cadence workflow for help on operations run ./cadence tasklist for help on tasklist operations (./cadence help, ./cadence help [domain|workflow] will also print help messages)\n\nnote: make sure you have a cadence server running before using \n\n# domain operation examples\n * register a new named "samples-domain":\n\n./cadence --domain samples-domain domain register --global_domain false\n# or using short alias\n./cadence --do samples-domain d re --gd false\n\n\n * view "samples-domain" details:\n\n./cadence --domain samples-domain domain describe\n\n\n# workflow operation examples\nthe following examples assume the cadence_cli_domain environment variable is set.\n\n# run workflow\nstart a and see its progress. this command doesn\'t finish until completes.\n\n./cadence workflow run --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow run\n./cadence workflow run -h\n\n\nbrief explanation: to run a , the user must specify the following:\n\n 1. tasklist name (--tl)\n 2. workflow type (--wt)\n 3. execution start to close timeout in seconds (--et)\n 4. input in json format (--i) (optional)\n\ns example uses this cadence-samples workflowand takes a string as input with the -i \'"cadence"\' parameter. single quotes (\'\') are used to wrap input as json.\n\nnote: you need to start the so that the can make progress. (run make && ./bin/helloworld -m worker in cadence-samples to start the )\n\n# show running workers of a tasklist\n./cadence tasklist desc --tl helloworldgroup\n\n\n# start workflow\n./cadence workflow start --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\'\n\n# view help messages for workflow start\n./cadence workflow start -h\n\n# for a workflow with multiple inputs, separate each json with space/newline like\n./cadence workflow start --tl helloworldgroup --wt main.workflowwith3args --et 60 -i \'"your_input_string" 123 {"name":"my-string", "age":12345}\'\n\n\nthe start command is similar to the run command, but immediately returns the workflow_id and run_id after starting the . use the show command to view the \'s history/progress.\n\n# reuse the same workflow id when starting/running a workflow\nuse option --workflowidreusepolicy or --wrp to configure the reuse policy.option 0 allowduplicatefailedonly: allow starting a using the same when a with the same is not already running and the last execution close state is one of [terminated, cancelled, timedout, failed].option 1 allowduplicate: allow starting a using the same when a with the same is not already running.option 2 rejectduplicate: do not allow starting a using the same as a previous .\n\n# use allowduplicatefailedonly option to start a workflow\n./cadence workflow start --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 0\n\n# use allowduplicate option to run a workflow\n./cadence workflow run --tl helloworldgroup --wt main.workflow --et 60 -i \'"cadence"\' --wid "<duplicated workflow id>" --wrp 1\n\n\n# start a workflow with a memo\nmemos are immutable key/value pairs that can be attached to a run when starting the . these are visible when listing . more information on memos can be foundhere.\n\ncadence wf start -tl helloworldgroup -wt main.workflow -et 60 -i \'"cadence"\' -memo_key ‘“service” “env” “instance”’ -memo ‘“servername1” “test” 5’\n\n\n# show workflow history\n./cadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\n./cadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest run history of that workflow_id\n./cadence workflow show -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\n./cadence workflow showid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# show workflow execution information\n./cadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717 -r 866ae14c-88cf-4f1e-980f-571e031d71b0\n# a shortcut of this is (without -w -r flag)\n./cadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717 866ae14c-88cf-4f1e-980f-571e031d71b0\n\n# if run_id is not provided, it will show the latest workflow execution of that workflow_id\n./cadence workflow describe -w 3ea6b242-b23c-4279-bb13-f215661b4717\n# a shortcut of this is\n./cadence workflow describeid 3ea6b242-b23c-4279-bb13-f215661b4717\n\n\n# list closed or open workflow executions\n./cadence workflow list\n\n# default will only show one page, to view more items, use --more flag\n./cadence workflow list -m\n\n\nuse --query to list with sql like \n\n./cadence workflow list --query "workflowtype=\'main.sampleparentworkflow\' and closetime = missing "\n\n\nthis will return all open with workflowtype as "main.sampleparentworkflow".\n\n# query workflow execution\n# use custom query type\n./cadence workflow query -w <wid> -r <rid> --qt <query-type>\n\n# use build-in query type "__stack_trace" which is supported by cadence client library\n./cadence workflow query -w <wid> -r <rid> --qt __stack_trace\n# a shortcut to query using __stack_trace is (without --qt flag)\n./cadence workflow stack -w <wid> -r <rid>\n\n\n# signal, cancel, terminate workflow\n# signal\n./cadence workflow signal -w <wid> -r <rid> -n <signal-name> -i \'"signal-value"\'\n\n# cancel\n./cadence workflow cancel -w <wid> -r <rid>\n\n# terminate\n./cadence workflow terminate -w <wid> -r <rid> --reason\n\n\nterminating a running will record a workflowexecutionterminated as the closing in the history. no more will be scheduled for a terminated . canceling a running will record a workflowexecutioncancelrequested in the history, and a new will be scheduled. the has a chance to do some clean up work after cancellation.\n\n# signal, cancel, terminate workflows as a batch job\nbatch job is based on list workflow query(--query). it supports , cancel and terminate as batch job type. for terminating as batch job, it will terminte the children recursively.\n\nstart a batch job(using as batch type):\n\ncadence --do samples-domain wf batch start --query "workflowtype=\'main.sampleparentworkflow\' and closetime=missing" --reason "test" --bt signal --sig testname\nthis batch job will be operating on 5 workflows.\nplease confirm[yes/no]:yes\n{\n    "jobid": "<batch-job-id>",\n    "msg": "batch job is started"\n}\n\n\n\nyou need to remember the jobid or use list command to get all your batch jobs:\n\ncadence --do samples-domain wf batch list\n\n\ndescribe the progress of a batch job:\n\ncadence --do samples-domain wf batch desc -jid <batch-job-id>\n\n\nterminate a batch job:\n\ncadence --do samples-domain wf batch terminate -jid <batch-job-id>\n\n\nnote that the operation performed by a batch will not be rolled back by terminating the batch. however, you can use reset to rollback your .\n\n# restart, reset workflow\nthe reset command allows resetting a to a particular point and continue running from there. there are a lot of use cases:\n\n * rerun a failed from the beginning with the same start parameters.\n * rerun a failed from the failing point without losing the achieved progress(history).\n * after deploying new code, reset an open to let the run to different flows.\n\nyou can reset to some predefined types:\n\n./cadence workflow reset -w <wid> -r <rid> --reset_type <reset_type> --reason "some_reason"\n\n\n * firstdecisioncompleted: reset to the beginning of the history.\n * lastdecisioncompleted: reset to the end of the history.\n * lastcontinuedasnew: reset to the end of the history for the previous run.\n\nif you are familiar with the cadence history , you can also reset to any finish by using:\n\n./cadence workflow reset -w <wid> -r <rid> --event_id <decision_finish_event_id> --reason "some_reason"\n\n\nsome things to note:\n\n * when reset, a new run will be kicked off with the same workflowid. but if there is a running execution for the workflow(workflowid), the current run will be terminated.\n * decision_finish_event_id is the id of of the type: decisiontaskcomplete/decisiontaskfailed/decisiontasktimeout.\n * to restart a from the beginning, reset to the first finish .\n\nto reset multiple , you can use batch reset command:\n\n./cadence workflow reset-batch --input_file <file_of_workflows_to_reset> --reset_type <reset_type> --reason "some_reason"\n\n\n# recovery from bad deployment -- auto-reset workflow\nif a bad deployment lets a run into a wrong state, you might want to reset the to the point that the bad deployment started to run. but usually it is not easy to find out all the impacted, and every reset point for each . in this case, auto-reset will automatically reset all the given a bad deployment identifier.\n\nlet\'s get familiar with some concepts. each deployment will have an identifier, we call it "binary checksum" as it is usually generated by the md5sum of a binary file. for a , each binary checksum will be associated with an auto-reset point, which contains a runid, an eventid, and the created_time that binary/deployment made the first for the .\n\nto find out which binary checksum of the bad deployment to reset, you should be aware of at least one running into a bad state. use the describe command with --reset_points_only option to show all the reset points:\n\n./cadence wf desc -w <workflowid>  --reset_points_only\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n|         binary checksum          |          create time           |                runid                 | eventid |\n+----------------------------------+--------------------------------+--------------------------------------+---------+\n| c84c5afa552613a83294793f4e664a7f | 2019-05-24 10:01:00.398455019  | 2dd29ab7-2dd8-4668-83e0-89cae261cfb1 |       4 |\n| aae748fdc557a3f873adbe1dd066713f | 2019-05-24 11:01:00.067691445  | d42d21b8-2adb-4313-b069-3837d44d6ce6 |       4 |\n...\n...\n\n\nthen use this command to tell cadence to auto-reset all impacted by the bad deployment. the command will store the bad binary checksum into info and trigger a process to reset all your .\n\n./cadence --do <yourdomainname> domain update --add_bad_binary aae748fdc557a3f873adbe1dd066713f  --reason "rollback bad deployment"\n\n\nas you add the bad binary checksum to your , cadence will not dispatch any to the bad binary. so make sure that you have rolled back to a good deployment(or roll out new bits with bug fixes). otherwise your can\'t make any progress after auto-reset.',charsets:{cjk:!0}},{title:"MIT License",frontmatter:{layout:"default",title:"MIT License",permalink:"/docs/about/license",readingShow:"top"},regularPath:"/docs/07-about/01-license.html",relativePath:"docs/07-about/01-license.md",key:"v-884a5d48",path:"/docs/about/license/",headersStr:null,content:'# MIT License\nCopyright (c) 2017 Uber Technologies, Inc.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the "Software"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.',normalizedContent:'# mit license\ncopyright (c) 2017 uber technologies, inc.\n\npermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the "software"), to deal\nin the software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the software, and to permit persons to whom the software is\nfurnished to do so, subject to the following conditions:\n\nthe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the software.\n\nthe software is provided "as is", without warranty of any kind, express or\nimplied, including but not limited to the warranties of merchantability,\nfitness for a particular purpose and noninfringement. in no event shall the\nauthors or copyright holders be liable for any claim, damages or other\nliability, whether in an action of contract, tort or otherwise, arising from,\nout of or in connection with the software or the use or other dealings in\nthe software.',charsets:{}},{title:"Contact us",frontmatter:{layout:"default",title:"Contact us",permalink:"/docs/about",readingShow:"top"},regularPath:"/docs/07-about/",relativePath:"docs/07-about/index.md",key:"v-0747733b",path:"/docs/about/",headersStr:null,content:"# Contact us\nIf you have a question, check whether it is already answered at stackoverflow under cadence-workflow tag.\n\nIf you still need help, visit .\n\nIf you have a feature request or a bug to report file an issue against one of the Cadence github repositories:\n\n * Cadence Service and CLI\n * Cadence Go Client\n * Cadence Go Client Samples\n * Cadence Java Client\n * Cadence Java Client Samples\n * Cadence Web UI",normalizedContent:"# contact us\nif you have a question, check whether it is already answered at stackoverflow under cadence-workflow tag.\n\nif you still need help, visit .\n\nif you have a feature request or a bug to report file an issue against one of the cadence github repositories:\n\n * cadence service and cli\n * cadence go client\n * cadence go client samples\n * cadence java client\n * cadence java client samples\n * cadence web ui",charsets:{}},{title:"Introduction",frontmatter:{layout:"default",title:"Introduction",description:"A large number of use cases span beyond a single request-reply, require tracking of a complex state, respond to asynchronous events, and communicate to external unreliable dependencies.",permalink:"/docs/cadence/",readingShow:"top"},regularPath:"/docs/cadence.html",relativePath:"docs/cadence.md",key:"v-54cca634",path:"/docs/cadence/",headersStr:null,content:"# Overview\nA large number of use cases span beyond a single request-reply, require tracking of a complex state, respond to asynchronous , and communicate to external unreliable dependencies. The usual approach to building such applications is a hodgepodge of stateless services, databases, cron jobs, and queuing systems. This negatively impacts the developer productivity as most of the code is dedicated to plumbing, obscuring the actual business logic behind a myriad of low-level details. Such systems frequently have availability problems as it is hard to keep all the components healthy.\n\nThe Cadence solution is a fault-oblivious stateful programming model that obscures most of the complexities of building scalable distributed applications. In essence, Cadence provides a durable virtual memory that is not linked to a specific process, and preserves the full application state, including function stacks, with local variables across all sorts of host and software failures. This allows you to write code using the full power of a programming language while Cadence takes care of durability, availability, and scalability of the application.\n\nCadence consists of a programming framework (or client library) and a managed service (or backend). The framework enables developers to author and coordinate in familiar languages (Go and Javaare supported today with some projects in Python andC#via a proxyin development).\n\nThe framework enables developers to author fault-oblivious code in familiar languages. (Go and Javaare in production. Python andC# are under development).\n\nThe backend service is stateless and relies on a persistent store. Currently, Cassandra and MySQL stores are supported. An adapter to any other database that provides multi-row single shard transactions can be added. There are different service deployment models. At Uber, our team operates multitenant clusters that are shared by hundreds of applications.\n\nWatch Maxim's talk from the Uber Open Summit for an introduction to the Cadence programming model and value proposition.\n\nThe GitHub repo for the Cadence server is uber/cadence. The docker image for the Cadence server is available on Docker Hub atubercadence/server.",normalizedContent:"# overview\na large number of use cases span beyond a single request-reply, require tracking of a complex state, respond to asynchronous , and communicate to external unreliable dependencies. the usual approach to building such applications is a hodgepodge of stateless services, databases, cron jobs, and queuing systems. this negatively impacts the developer productivity as most of the code is dedicated to plumbing, obscuring the actual business logic behind a myriad of low-level details. such systems frequently have availability problems as it is hard to keep all the components healthy.\n\nthe cadence solution is a fault-oblivious stateful programming model that obscures most of the complexities of building scalable distributed applications. in essence, cadence provides a durable virtual memory that is not linked to a specific process, and preserves the full application state, including function stacks, with local variables across all sorts of host and software failures. this allows you to write code using the full power of a programming language while cadence takes care of durability, availability, and scalability of the application.\n\ncadence consists of a programming framework (or client library) and a managed service (or backend). the framework enables developers to author and coordinate in familiar languages (go and javaare supported today with some projects in python andc#via a proxyin development).\n\nthe framework enables developers to author fault-oblivious code in familiar languages. (go and javaare in production. python andc# are under development).\n\nthe backend service is stateless and relies on a persistent store. currently, cassandra and mysql stores are supported. an adapter to any other database that provides multi-row single shard transactions can be added. there are different service deployment models. at uber, our team operates multitenant clusters that are shared by hundreds of applications.\n\nwatch maxim's talk from the uber open summit for an introduction to the cadence programming model and value proposition.\n\nthe github repo for the cadence server is uber/cadence. the docker image for the cadence server is available on docker hub atubercadence/server.",charsets:{}},{title:"Home",frontmatter:{home:!0,heroText:"Fault-Tolerant Stateful Code Platform",tagline:"Focus on your business logic and let Cadence take care of the complexity of distributed systems",actionText:"Get Started →",actionLink:"/docs/java-client/quick-start/",footer:"© 2020 Uber Technologies, Inc.",readingShow:"top"},regularPath:"/",relativePath:"index.md",key:"v-0615a98a",path:"/",headersStr:null,content:" Easy to use\nWorkflows provide primitives to allow application developers to express complex business logic as code.\n\nThe underlying platform abstracts scalability, reliability and availability concerns from individual developers/teams.\n\nFault tolerant\nCadence enables writing stateful applications without worrying about the complexity of handling process failures.\n\nCadence preserves complete multithreaded application state including thread stacks with local variables across hardware and software failures.\n\nScalable & Reliable\nCadence is designed to scale out horizontally to handle millions of concurrent workflows.\n\nCadence provides out-of-the-box asynchronous history event replication that can help you recover from zone failures.",normalizedContent:" easy to use\nworkflows provide primitives to allow application developers to express complex business logic as code.\n\nthe underlying platform abstracts scalability, reliability and availability concerns from individual developers/teams.\n\nfault tolerant\ncadence enables writing stateful applications without worrying about the complexity of handling process failures.\n\ncadence preserves complete multithreaded application state including thread stacks with local variables across hardware and software failures.\n\nscalable & reliable\ncadence is designed to scale out horizontally to handle millions of concurrent workflows.\n\ncadence provides out-of-the-box asynchronous history event replication that can help you recover from zone failures.",charsets:{}}],themeConfig:{docsDir:"src",logo:"/img/logo-white.svg",docsRepo:"uber/cadence-docs",editLinks:!0,nav:[{text:"Docs",items:[{text:"Cadence",link:"/docs/cadence/"},{text:"Use cases",link:"/docs/use-cases/"},{text:"Concepts",link:"/docs/concepts/"},{text:"Tutorials",link:"/docs/tutorials/"},{text:"Java client",link:"/docs/java-client/"},{text:"Go client",link:"/docs/go-client/"},{text:"Command line interface",link:"/docs/cli/"},{text:"Glossary",link:"/GLOSSARY"},{text:"About",link:"/docs/about/"}]},{text:"Client",items:[{text:"Java Docs",link:"https://www.javadoc.io/doc/com.uber.cadence/cadence-client"},{text:"Java Client",link:"https://mvnrepository.com/artifact/com.uber.cadence/cadence-client"},{text:"Go Docs",link:"https://godoc.org/go.uber.org/cadence"},{text:"Go Client",link:"https://github.com/uber-go/cadence-client/releases/latest"}]},{text:"Community",items:[{text:"Slack",link:"http://t.uber.com/cadence-slack"},{text:"StackOverflow",link:"https://stackoverflow.com/questions/tagged/cadence-workflow"}]},{text:"GitHub",items:[{text:"Cadence Service and CLI",link:"https://github.com/uber/cadence"},{text:"Cadence Go Client",link:"https://github.com/uber-go/cadence-client"},{text:"Cadence Go Client Samples",link:"https://github.com/uber-common/cadence-samples"},{text:"Cadence Java Client",link:"https://github.com/uber-java/cadence-client"},{text:"Cadence Java Client Samples",link:"https://github.com/uber/cadence-java-samples"},{text:"Cadence Web UI",link:"https://github.com/uber/cadence-web"}]},{text:"Docker",items:[{text:"Cadence Service",link:"https://hub.docker.com/r/ubercadence/server/tags"},{text:"Cadence CLI",link:"https://hub.docker.com/r/ubercadence/cli/tags"},{text:"Cadence Web UI",link:"https://hub.docker.com/r/ubercadence/web/tags"}]}],sidebar:{"/docs/":[{title:"Cadence",path:"/docs/cadence"},{title:"Use cases",path:"/docs/01-use-cases",children:["01-use-cases/","01-use-cases/01-periodic-execution","01-use-cases/02-orchestration","01-use-cases/03-polling","01-use-cases/04-event-driven","01-use-cases/05-partitioned-scan","01-use-cases/06-batch-job","01-use-cases/07-provisioning","01-use-cases/08-deployment","01-use-cases/09-operational-management","01-use-cases/10-interactive","01-use-cases/11-dsl","01-use-cases/12-big-ml"]},{title:"Concepts",path:"/docs/02-concepts",children:["02-concepts/","02-concepts/01-workflows","02-concepts/02-activities","02-concepts/03-events","02-concepts/04-queries","02-concepts/05-topology","02-concepts/06-task-lists","02-concepts/07-archival","02-concepts/08-cross-dc-replication","02-concepts/09-search-workflows"]},{title:"Tutorials",path:"/docs/03-video-tutorials",children:["03-video-tutorials/","03-video-tutorials/01-java-hello-world"]},{title:"Java client",path:"/docs/04-java-client",children:["04-java-client/","04-java-client/01-quick-start","04-java-client/02-workflow-interface","04-java-client/03-implementing-workflows","04-java-client/04-starting-workflow-executions","04-java-client/05-activity-interface","04-java-client/06-implementing-activities","04-java-client/07-versioning","04-java-client/08-distributed-cron"]},{title:"Go client",path:"/docs/05-go-client",children:["05-go-client/","05-go-client/01-workers","05-go-client/02-create-workflows","05-go-client/03-activities","05-go-client/04-execute-activity","05-go-client/05-child-workflows","05-go-client/06-retries","05-go-client/07-error-handling","05-go-client/08-signals","05-go-client/09-continue-as-new","05-go-client/10-side-effect","05-go-client/11-queries","05-go-client/12-activity-async-completion","05-go-client/13-workflow-testing","05-go-client/14-workflow-versioning","05-go-client/15-sessions","05-go-client/16-distributed-cron","05-go-client/17-tracing"]},{title:"Command line interface",path:"/docs/06-cli/"},{title:"Glossary",path:"../GLOSSARY"},{title:"About",path:"/docs/07-about",children:["07-about/","07-about/01-license"]}]}}};n(316);Wi.component("slack-link",(function(){return n.e(6).then(n.bind(null,389))})),Wi.component("Badge",(function(){return Promise.all([n.e(0),n.e(3)]).then(n.bind(null,451))})),Wi.component("CodeBlock",(function(){return Promise.all([n.e(0),n.e(4)]).then(n.bind(null,390))})),Wi.component("CodeGroup",(function(){return Promise.all([n.e(0),n.e(5)]).then(n.bind(null,391))}));n(317),n(318);var gs={name:"BackToTop",props:{threshold:{type:Number,default:300}},data:function(){return{scrollTop:null}},computed:{show:function(){return this.scrollTop>this.threshold}},mounted:function(){var e=this;this.scrollTop=this.getScrollTop(),window.addEventListener("scroll",ns()((function(){e.scrollTop=e.getScrollTop()}),100))},methods:{getScrollTop:function(){return window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0},scrollToTop:function(){window.scrollTo({top:0,behavior:"smooth"}),this.scrollTop=0}}},ws=(n(319),Object(cs.a)(gs,(function(){var e=this.$createElement,t=this._self._c||e;return t("transition",{attrs:{name:"fade"}},[this.show?t("svg",{staticClass:"go-to-top",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 49.484 28.284"},on:{click:this.scrollToTop}},[t("g",{attrs:{transform:"translate(-229 -126.358)"}},[t("rect",{attrs:{fill:"currentColor",width:"35",height:"5",rx:"2",transform:"translate(229 151.107) rotate(-45)"}}),this._v(" "),t("rect",{attrs:{fill:"currentColor",width:"35",height:"5",rx:"2",transform:"translate(274.949 154.642) rotate(-135)"}})])]):this._e()])}),[],!1,null,"5fd4ef0c",null).exports);n(320);Wi.component("CodeSwitcher",(function(){return n.e(8).then(n.bind(null,392))}));n(111);var vs={name:"ReadingProgress",data:function(){return{readingTop:0,readingHeight:1,progressStyle:null,transform:void 0,running:!1}},watch:{$readingShow:function(){this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)}},mounted:function(){this.transform=this.getTransform(),this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)},beforeDestroy:function(){this.$readingShow&&window.removeEventListener("scroll",this.base)},methods:{base:function(){this.running||(this.running=!0,requestAnimationFrame(this.getReadingBase))},getReadingBase:function(){this.readingHeight=this.getReadingHeight()-this.getScreenHeight(),this.readingTop=this.getReadingTop(),this.progressStyle=this.getProgressStyle(),this.running=!1},getReadingHeight:function(){return Math.max(document.body.scrollHeight,document.body.offsetHeight,0)},getScreenHeight:function(){return Math.max(window.innerHeight,document.documentElement.clientHeight,0)},getReadingTop:function(){return Math.max(window.pageYOffset,document.documentElement.scrollTop,0)},getTransform:function(){var e=document.createElement("div");return["transform","-webkit-transform","-moz-transform","-o-transform","-ms-transform"].find((function(t){return t in e.style}))||void 0},getProgressStyle:function(){var e=this.readingTop/this.readingHeight;switch(this.$readingShow){case"top":case"bottom":return this.transform?"".concat(this.transform,": scaleX(").concat(e,")"):"width: ".concat(100*e,"%");case"left":case"right":return this.transform?"".concat(this.transform,": scaleY(").concat(e,")"):"height: ".concat(100*e,"%");default:return null}}}},ys=(n(321),Object(cs.a)(vs,(function(){var e=this.$createElement,t=this._self._c||e;return t("ClientOnly",[this.$readingShow?t("div",{staticClass:"reading-progress",class:this.$readingShow},[t("div",{staticClass:"progress",style:this.progressStyle})]):this._e()])}),[],!1,null,"3640397f",null).exports);n(104);function bs(e,t){var n=!0;void 0===e?(e="Term not found in the glossary",n=!1):e=ks(e);var o=n?"":" term-not-found";return t=xs(t),'<a title="'.concat(e,'" class="term').concat(o,'">').concat(t,"</a>")}function ks(e){return e.replace(/:[\w+]*:([\w+]*):/g,(function(e,t){return t})).replace(/:([\w+]*):/g,(function(e,t){return t}))}function xs(e){return e.split("_").join(" ")}function Ss(e){return e.split("_").join(" ")}var Ts={name:"Term",props:{term:{type:String,required:!0},show:{type:String,required:!1,default:""}},data:function(){return{termNotFound:!1}},computed:{terms:function(){return this.$site.pages.find((function(e){return"/GLOSSARY.html"===e.path})).frontmatter.terms},definition:function(){var e=Ss(this.term),t=this.terms[e];return t?ks(t):(this.termNotFound=!0,"Term not found in the glossary")},displayText:function(){return Ss(this.show?this.show:this.term)}}},Cs=Object(cs.a)(Ts,(function(){var e=this.$createElement;return(this._self._c||e)("a",{class:{"term-not-found":this.termNotFound,term:!0},attrs:{title:this.definition}},[this._v(this._s(this.displayText))])}),[],!1,null,null,null).exports,Is={props:{terms:{type:Object,required:!0}},methods:{definition:function(e){return t=e,n=this.terms,n[xs(t)].replace(/:([\w+]*):([\w+]*):/g,(function(e,t,o){return bs(n[xs(t)],o)})).replace(/:([\w+]*):/g,(function(e,t,o){return bs(n[xs(t)],t)}));var t,n}}},_s=(n(322),Object(cs.a)(Is,(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("dl",e._l(Object.keys(e.terms),(function(t){return n("div",[n("dt",{staticClass:"defined-term"},[e._v(e._s(t))]),e._v(" "),n("dd",{staticClass:"term-definition",domProps:{innerHTML:e._s(e.definition(t,e.terms))}})])})),0)}),[],!1,null,null,null).exports),As=[function(e){e.router.addRoutes([{path:"/docs/",redirect:"/docs/cadence"}])},{},function(e){e.Vue.mixin({computed:{$dataBlock:function(){return this.$options.__data__block__}}})},{},{},function(e){e.Vue.component("BackToTop",ws)},{},{},function(e){var t=e.Vue;t.component(ys.name,ys),t.mixin({computed:{$readingShow:function(){return this.$page.frontmatter.readingShow}}})},function(e){e.Vue.component("CodeCopy",us)},function(e){var t=e.Vue;e.options,e.router,e.siteData;t.component("Term",Cs),t.component("Glossary",_s)}],Es=["BackToTop","ReadingProgress"];n(187);function Os(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}n(102);function js(e,t){for(var n=0;n<t.length;n++){var o=t[n];o.enumerable=o.enumerable||!1,o.configurable=!0,"value"in o&&(o.writable=!0),Object.defineProperty(e,o.key,o)}}function Ps(e,t,n){return t&&js(e.prototype,t),n&&js(e,n),e}n(181);function Ws(e,t){return(Ws=Object.setPrototypeOf||function(e,t){return e.__proto__=t,e})(e,t)}n(182);function qs(e){return(qs=Object.setPrototypeOf?Object.getPrototypeOf:function(e){return e.__proto__||Object.getPrototypeOf(e)})(e)}n(120),n(110);function Ds(e,t){return!t||"object"!==Ca(t)&&"function"!=typeof t?function(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}(e):t}function Ns(e){var t=function(){if("undefined"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"==typeof Proxy)return!0;try{return Date.prototype.toString.call(Reflect.construct(Date,[],(function(){}))),!0}catch(e){return!1}}();return function(){var n,o=qs(e);if(t){var i=qs(this).constructor;n=Reflect.construct(o,arguments,i)}else n=o.apply(this,arguments);return Ds(this,n)}}var Rs=function(e){!function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),t&&Ws(e,t)}(n,e);var t=Ns(n);function n(){return Os(this,n),t.apply(this,arguments)}return n}(function(){function e(){Os(this,e),this.store=new Wi({data:{state:{}}})}return Ps(e,[{key:"$get",value:function(e){return this.store.state[e]}},{key:"$set",value:function(e,t){Wi.set(this.store.state,e,t)}},{key:"$emit",value:function(){var e;(e=this.store).$emit.apply(e,arguments)}},{key:"$on",value:function(){var e;(e=this.store).$on.apply(e,arguments)}}]),e}());Object.assign(Rs.prototype,{getPageAsyncComponent:Ha,getLayoutAsyncComponent:$a,getAsyncComponent:Ma,getVueComponent:Ga});var Ls={install:function(e){var t=new Rs;e.$vuepress=t,e.prototype.$vuepress=t}};function Fs(e){e.beforeEach((function(t,n,o){if(zs(e,t.path))o();else if(/(\/|\.html)$/.test(t.path))if(/\/$/.test(t.path)){var i=t.path.replace(/\/$/,"")+".html";zs(e,i)?o(i):o()}else o();else{var r=t.path+"/",a=t.path+".html";zs(e,a)?o(a):zs(e,r)?o(r):o()}}))}function zs(e,t){return e.options.routes.filter((function(e){return e.path.toLowerCase()===t.toLowerCase()})).length>0}var Hs={props:{pageKey:String,slotKey:{type:String,default:"default"}},render:function(e){var t=this.pageKey||this.$parent.$page.key;return Ba("pageKey",t),Wi.component(t)||Wi.component(t,Ha(t)),Wi.component(t)?e(t):e("")}},$s={functional:!0,props:{slotKey:String,required:!0},render:function(e,t){var n=t.props,o=t.slots;return e("div",{class:["content__".concat(n.slotKey)]},o()[n.slotKey])}},Ms={computed:{openInNewWindowTitle:function(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Gs=(n(324),n(325),Object(cs.a)(Ms,(function(){var e=this.$createElement,t=this._self._c||e;return t("span",[t("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[t("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),t("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),t("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports);function Us(){return(Us=Object(o.a)(regeneratorRuntime.mark((function e(t){var n,o,i,r;return regeneratorRuntime.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return n="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:ms.routerBase||ms.base,Fs(o=new Sa({base:n,mode:"history",fallback:!1,routes:ps,scrollBehavior:function(e,t,n){return n||(e.hash?!Wi.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(e.hash)}:{x:0,y:0})}})),i={},e.prev=4,e.next=7,Promise.all(As.filter((function(e){return"function"==typeof e})).map((function(e){return e({Vue:Wi,options:i,router:o,siteData:ms,isServer:t})})));case 7:e.next=12;break;case 9:e.prev=9,e.t0=e.catch(4),console.error(e.t0);case 12:return r=new Wi(Object.assign(i,{router:o,render:function(e){return e("div",{attrs:{id:"app"}},[e("RouterView",{ref:"layout"}),e("div",{class:"global-ui"},Es.map((function(t){return e(t)})))])}})),e.abrupt("return",{app:r,router:o});case 14:case"end":return e.stop()}}),e,null,[[4,9]])})))).apply(this,arguments)}Wi.config.productionTip=!1,Wi.use(Sa),Wi.use(Ls),Wi.mixin(function(e,t){var n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:Wi;Ta(t),n.$vuepress.$set("siteData",t);var o=e(n.$vuepress.$get("siteData")),i=new o,r=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(i)),a={};return Object.keys(r).reduce((function(e,t){return t.startsWith("$")&&(e[t]=r[t].get),e}),a),{computed:a}}((function(e){return function(){function t(){Os(this,t)}return Ps(t,[{key:"setPage",value:function(e){this.__page=e}},{key:"$site",get:function(){return e}},{key:"$themeConfig",get:function(){return this.$site.themeConfig}},{key:"$frontmatter",get:function(){return this.$page.frontmatter}},{key:"$localeConfig",get:function(){var e,t,n=this.$site.locales,o=void 0===n?{}:n;for(var i in o)"/"===i?t=o[i]:0===this.$page.path.indexOf(i)&&(e=o[i]);return e||t||{}}},{key:"$siteTitle",get:function(){return this.$localeConfig.title||this.$site.title||""}},{key:"$canonicalUrl",get:function(){var e=this.$page.frontmatter.canonicalUrl;return"string"==typeof e&&e}},{key:"$title",get:function(){var e=this.$page,t=this.$page.frontmatter.metaTitle;if("string"==typeof t)return t;var n=this.$siteTitle,o=e.frontmatter.home?null:e.frontmatter.title||e.title;return n?o?o+" | "+n:n:o||"VuePress"}},{key:"$description",get:function(){var e=function(e){if(e){var t=e.filter((function(e){return"description"===e.name}))[0];if(t)return t.content}}(this.$page.frontmatter.meta);return e||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}},{key:"$lang",get:function(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}},{key:"$localePath",get:function(){return this.$localeConfig.path||"/"}},{key:"$themeLocaleConfig",get:function(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}},{key:"$page",get:function(){return this.__page?this.__page:function(e,t){for(var n=0;n<e.length;n++){var o=e[n];if(o.path.toLowerCase()===t.toLowerCase())return o}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}}]),t}()}),ms)),Wi.component("Content",Hs),Wi.component("ContentSlotsDistributor",$s),Wi.component("OutboundLink",Gs),Wi.component("ClientOnly",{functional:!0,render:function(e,t){var n=t.parent,o=t.children;if(n._isMounted)return o;n.$once("hook:mounted",(function(){n.$forceUpdate()}))}}),Wi.component("Layout",$a("Layout")),Wi.component("NotFound",$a("NotFound")),Wi.prototype.$withBase=function(e){var t=this.$site.base;return"/"===e.charAt(0)?t+e.slice(1):e},window.__VUEPRESS__={version:"1.7.1",hash:"09ebd13"},function(e){return Us.apply(this,arguments)}(!1).then((function(e){var t=e.app;e.router.onReady((function(){t.$mount("#app")}))}))}]);